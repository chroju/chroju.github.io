<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[the world as code]]></title>
  <link href="http://chroju.github.io/atom.xml" rel="self"/>
  <link href="http://chroju.github.io/"/>
  <updated>2016-01-24T23:00:42+09:00</updated>
  <id>http://chroju.github.io/</id>
  <author>
    <name><![CDATA[chroju]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Personal Knowledge Base]]></title>
    <link href="http://chroju.github.io/blog/2016/01/24/personal-knowledge-base/"/>
    <updated>2016-01-24T22:57:39+09:00</updated>
    <id>http://chroju.github.io/blog/2016/01/24/personal-knowledge-base</id>
    <content type="html"><![CDATA[<p>昨年は転職のゴタゴタがあったりしてメモを取る習慣というものがどこかに消え失せてしまっていたので、年始にあたり生涯幾度目かわからないがメモ環境について再考している。本当に何度目だよ、と思うのだが、これはもう生涯模索しながらいくしかないし、最適解なんてのは時と場合によって変わるものだとは思う。</p>

<p>しかしオライリーから『エンジニアのための時間管理術』は出ているのに、『情報整理術』が出ていないのはなぜなのか。むしろそっちが職種的に重要じゃないのか。ブログやQiitaでもあまり見かけない。</p>

<h2>Evernoteの呪縛</h2>

<p>現代においてメモ、ノートというと真っ先に挙がってくるのがEvernoteであり、自分も確かに使ってはいる。使ってはいるが、正直に言って愛憎は入り混じっている。基本的には使いたくない。でも使わずにはいられなくて、ついついいろいろとぶち込んでしまう。</p>

<p>Evernoteの肝は、ありとあらゆるフォーマットの資料を何でも入れることができて、それがsearchableになることにあると思っている。昨日読んだブログのエントリー。1年前に契約したサービスの証明書。3ヶ月前に読んだ本の感想。そういったものをすべて並列に保存することができ、検索すればすぐに出てくる。放っておけば消えて無くなるような情報が「死蔵」されなくなる。だから取りあえず「いいな」と思ったものがあればEvernoteに入れてしまう。特に開発終了が発表されたClearlyが自分にとってはクリーンヒットで、良いなと思った文章があれば迷わずClearlyを使っていた。ググればまた出ると言われればその通りだが、同じ検索キーワードをまた思い出せるとも限らないし、ページが消滅することだってままある。</p>

<p>しかし実際に突っ込んだ情報をもう一度掘り出せるのかどうか。文字情報であれば確かに検索できるのだが、画像はどうか。音声は。またpdfは。それを防ぐためか、ノートブックやタグ付けという能動的な整理手法も用意されているわけだが、次々と投げ込んだ資料を1つずつ分類していくのは骨が折れるし、メールクライアントにあるようなオートフィルタリングはいまだにできない（サードパーティーのアプリならあるけど）。また実際に検索をかけたときも、ノートの読み込み速度はそれほど速いものではなく、特にモバイルアプリに関してはどうにもストレスフルだ。</p>

<p>結果的に何でも入れられるがサルベージが難しいゴミ箱、あれば安心感があるので離れられないけど、積極的に何か活用していこうとは思えない存在と化してきている。</p>

<h2>何をメモするのか</h2>

<p>そもそも何をそんなに悩むほどメモしたいのか。改めて考えるとよくわからないなぁで思考が停まりそうになったが、いくつか挙げてみる。</p>

<ul>
<li>Tech関連でも日常の中の疑問でもそうだが、ググるのは簡単だがその知識はすぐ忘れてしまう。どこからどんな情報を得て、どんな結論に至ったのかは書き留めておきたい。</li>
<li>スニペットやチートシート。頭悪いのでコマンドや文法をすぐ参照できるようにしておきたい。</li>
<li>読書メモ。簡単な本の概要、感想、それを受けて何を実践するのか。</li>
<li>ポエム。客観的な事実や資料より感情より、主観よりのもの。課題に関する考えとか哲学とか。</li>
<li>チェックリスト。日常の指針になるような。定例作業の手順もそうだし、持ち物リスト、忘れがちなポリシー的なものとか。</li>
</ul>


<p>こうして挙げてみると参照頻度、パブリックorプライベートといった軸で分類できそうな気がしてくる。またそれによって選ぶべきツールも変わりそうだ。例えばEvernoteは先に書いた通り遅い、分類が面倒という特徴を自分は見出しているが、逆にそれほど素早く引き出す必要のないもの、つまり参照頻度が低い「もしものためのメモ」などであればEvernoteでも構わないことになる。</p>

<p>スニペットやチートシートは本当に秒で出てきて欲しいし、シンタックスハイライトが効いてないと辛いみたいなところがあったりもするので、Evernoteには向かないことになる。この目的だと自分の中ではGistやKobitoが最近のヒットではある。</p>

<p>思うに、Evernoteや梅棹忠夫先生が掲げるような「すべてのメモを一箇所に集める」というのはちょっと厳しいのではないか。目的の違うメモであれば、適切なフォーマットも自ずと変わってくる。もちろん分散していろんなところにメモがある状況というのはわかりにくくはあるが、目的がはっきり定まっていればツールの選択に迷うことはない。自分はEvernoteにスニペットを格納したことはないし、日常生活で使うチェックリストをGistのPublicで保存したこともない。</p>

<h2>Personal Knowledge Base</h2>

<p>ここでようやくタイトル回収するのだけど、海外ではこの手のツールをPersonal Knowledge Base(PKB)と呼ぶらしい。<a href="https://en.wikipedia.org/wiki/Personal_knowledge_base">Wikipediaの記述</a>の細かさを見ると、国内よりはだいぶホットな話題っぽく思われる。いろいろこのワードでググッてみたのだが、今のところうなずけたのは以下のあたり。</p>

<ul>
<li><a href="http://www.acuriousmix.com/2014/09/03/designing-a-personal-knowledgebase/">Designing a Personal Knowledgebase – A Curious Mix</a></li>
<li><a href="https://news.ycombinator.com/item?id=8270759">Designing a Personal Knowledgebase | Hacker News</a></li>
<li><a href="http://programmers.stackexchange.com/questions/729/how-do-you-manage-your-knowledge-base">How do you manage your knowledge base? - Programmers Stack Exchange</a></li>
</ul>


<p>特に一番上の記事はだいぶ熱い。俺の理想とするPKBはこんなのだ！！！ってめっちゃ細かく書いているが、わりと同意できる内容ではあった。下2つのフォーラム系の記事を見ると、案外多いのが個人Wikiを使っている人。確かにフレキシブルな編集が可能という点では、2016年現在に至ってもWikiの優位性はかなり高い気がする。でもさすがに今更感あるなーということで手を出す気にはなれない。あるいはorg-modeが結構評判よくて、Vimmerじゃなければ手を出していたようには思う。</p>

<p>PKBの定義に関してはWikipediaの記事にあるが、情報の一次ソースそのものではなくて、そこから得られた知識をまとめるものということ。</p>

<blockquote><p>Its purpose is not simply to aggregate all the information sources one has seen, but to preserve the knowledge that one has learned from those sources.</p></blockquote>

<p>これについては深く同意するところで、情報そのものなら別に本自体とかウェブページを直接見たりとかすればいいんだけど、それら複数の資料から自分なりに導いた知識、学習結果というものをまとめておきたいのだ。そう考えてみると、Qiitaに特にそういう内容は多く書いているし、一次ソースに関してはウェブクリップなり、本のページを撮影したものなりをEvernoteに入れているので、やっぱりツールの棲み分けになってくるのかなぁと思えてくる。ちなみに一次ソースにあたる情報をまとめたものはPIM(Personal Information Management)と言うらしい。</p>

<h2>結論？</h2>

<p>書いていけば結論見えるかなと思ってここまで書いてみたが、なかなか見えてこない。結局のところ自分の中ではGistが一番近くはある。Gistboxを使えばタグ分類ができるし、<a href="https://github.com/lambdalisue/vim-gista">vim-gista</a>を使うことでVimキーバインドでの編集もできる。コードハイライトもMarkdownのプレビューも出来て至れり尽くせり。引っかかるのは非techなメモを入れるのがGitHubである故に心理的に憚られるなぁというのと、モバイル端末からの閲覧にあまりいいツールがないこと。</p>

<p>んで一方で公開したい情報はこうやってブログにまとめたり、Qiitaにまとめたりもしているので、そこの分断も若干もどかしい。さっきツールは分けるしかないかもと言っておいてアレだが。ちなみにブログはこういう文章過多な場合、いわばポエムだとかツール、技術に関する考察をまとめる場、Qiitaはよりtechそのものに寄ったものを書く場と使い分けている。こういったところで公開共有するほどでもねーやってものはGistかなと。あんまりにも初歩的な内容とかQiitaに流すの憚られるじゃないですか。タグで追ってる人には必ず見られるわけだから。</p>

<p>Evernoteに関しては、結局一次ソースにあたる情報を端からブチ込んで安心感を得るツールとしては今後も使い続けそう。しかしClearlyがなくなるのが本当につらい。Web Clipperのあの鈍重な動きは「何も考えずとりあえずクリップ」するにはちょっと抵抗ある。仕方ないか。しかしウェブクリップというのもどこまで意味のあるものやら。。その後情報が更新されても追えなくなるわけだし。</p>

<p>何はともあれ、とりあえず「記録残せ」から始めなくてはと思う。悩んで結論出ないから記録しないみたいな状態が続くのが一番よろしくない。悩みながらも進めていくしかないんだろうな。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[東京Node学園付属小学校1限目に行ってきた]]></title>
    <link href="http://chroju.github.io/blog/2016/01/20/node-js-elementary-school-1/"/>
    <updated>2016-01-20T00:48:28+09:00</updated>
    <id>http://chroju.github.io/blog/2016/01/20/node-js-elementary-school-1</id>
    <content type="html"><![CDATA[<p><a href="http://connpass.com/event/23463/">【増枠！】東京Node学園付属小学校 1時限目 - connpass</a></p>

<p>東京node学園というNode.jsのユーザーコミュニティがありますが、その入門者向けバージョンが立ち上がったので行ってきました。</p>

<p>自分がNode.jsを扱った経験はAWS Lambdaとhubotで遊ぶために既存のスクリプトを少し触ったぐらいで、おそらくは小学校というより幼稚園レベルだったと思いますが、それ以前にやはりフロントエンドの集まりにインフラのエンジニアが行くというのはちょっと自分でも場違い感を覚えずにはいられず、さすがに提供できる話もないやろなってことで懇親会は出ずに帰ってしまいました（）。しかし刺激になったのは確かというか、フロントエンドの世界にちょっとだけ触れられる良い機会ではあったかなと。</p>

<p>そもそもにして自分にとって「言語」は最近手足になってきていて、Ansible使いたいからPythonやっておこうとか、Docker理解したいからgolangかなとかそういう選択ばかりするようになっていたのだが、フロントエンドにとって新しい言語というのは可能性の広がりなのだなーと当たり前のようなことに気付いた。例えば最近Kobitoの実装などで話題のElectronはNode.jsなわけで、サーバーサイドスクリプトであるNode.jsを学ぶことで、デスクトップアプリケーションを従前よりは容易に構築できる可能性になる。作れるものの幅が増える、やれることが膨らんでいくことはエンジニアにとってとても楽しい。</p>

<p>くっだらないものでもなんでも構わんから、とりあえず手を動かして「作る」ことが楽しいって経験をもっとしてもいいのかもなと思った。インフラのデリバリー、運用の効率化、そういうのも大切ではあるけれど、我々がそもそもビジネスとして提供しているサービス、システムとはなんぞやって部分をもう一度見返してみたい気がした。言語は単なるツール、ではないはず。だからこういう勉強会もいいけど、ハンズオンとかもっと行ってみるべきかなと。具体的に今回の勉強会で見かけた中ではMEANスタックが気になるのでやっておきたい。ちょうどMongoに手を付けたかったし。</p>

<p>以上、取り留めのない感想でした。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2016年の行動規範]]></title>
    <link href="http://chroju.github.io/blog/2016/01/03/manifesto-2016/"/>
    <updated>2016-01-03T14:02:07+09:00</updated>
    <id>http://chroju.github.io/blog/2016/01/03/manifesto-2016</id>
    <content type="html"><![CDATA[<p>うまいことまとまらないのでつらつら。</p>

<h2>問題意識</h2>

<ul>
<li>時間、お金の使い方がいまだに下手。

<ul>
<li>きちんと考えず浪費している機会が多い。</li>
<li>時間ならタスクシュート、お金ならZaimを使ったりした経験はあるが結局とまったりしている。</li>
<li>昨年は10年以上続いていた日記すらもとめてしまった。</li>
<li>何か忙しい課題が仕事なりプライベートなりに鎮座すると、他に回す手が一切なくなったりしてバランス悪い。</li>
</ul>
</li>
<li>メモ環境の再考。

<ul>
<li>インプットが「ググって終わり」の場合が多く、次にその情報が必要になったときも結局ググってる。</li>
<li>読んだ本が本当に身になっている気がしない。</li>
<li>Evernoteがメモの死蔵場になっている。</li>
<li>デジタルメモはVimと<a href="https://github.com/glidenote/memolist.vim">memolist.vim</a>を基本にしているけど、書き散らして終わってる感。</li>
</ul>
</li>
<li>技術探求の不足

<ul>
<li>やってるけどやりきれてないというか。</li>
<li>Qiitaで話題になっているのを見て、ザッと読んでなんとなく無理そうと思うと閉じちゃったり。</li>
<li>いつか使うかな？と思ってPocketにつっこんでそのまんまの積読があまりに多い。</li>
<li>流行ってる→やろうとか、こういうツールほしい→作ろうの瞬発力上げたい。</li>
<li>本読みたい。というか去年文化資本にあまりに触らなすぎた。</li>
</ul>
</li>
<li>仲間がほしい

<ul>
<li>懇親会とか行ってもその場限りの話しかできなかったりでエンジニア仲間社外にあんまいない。</li>
<li>社内の技術課題解決するのに社外で話すってのも大切そう。</li>
<li>ていうかエンジニアとしてもうちょい知名度上げてみたい。</li>
</ul>
</li>
</ul>


<h2>解消していくために</h2>

<ul>
<li>時間とお金の定量評価

<ul>
<li>お金は娯楽費にx万までみたいな予算持ってるので、時間も定量評価したい。コード書く時間を週に必ずx時間とか。</li>
<li>タイムロギングしたいけどTogglとか使うの面倒。とりあえずやってみるか。難しけりゃ1日の最後にノートに記憶から書き出すんでもいいかなと。</li>
<li>週ごとのノートにしたい。PDCA回すのにちょうど良いスパンだと思う。今週ダメなら来週帳尻合わせるとか出来るわけで。

<ul>
<li>そういう用途だと紙ノートよりEvernoteの方が良さそう。1ノートに対して1週間という形が取れるので。</li>
<li>じゃあ日記もここに載ってくる形でいっか。</li>
</ul>
</li>
</ul>
</li>
<li>メモをもっかいちゃんとする

<ul>
<li>技術テーマごとにちゃんとノート取る。ブログに上げるといった方がいいか。</li>
<li>ブログ記事にならないレベルのものはQiita。二番煎じ三番煎じでQiitaレベルに値しないものはGist。

<ul>
<li>でもGistあんまり使いやすくない……。</li>
</ul>
</li>
<li>メモを見返す時間をちゃんと作る。週次レビュー的なあれ。金曜夜が第一候補。無理なら土曜。

<ul>
<li>というかそれぐらいの時間は取れるようなスケジューリングをする。去年はそれすら難しいぐらいアホほど予定入れてた。</li>
<li>頭のなかちゃんと棚卸するの大事。</li>
</ul>
</li>
<li>手元のモレスキンはタイムライン的なリアルタイムメモ用にする。アナログは見返すの無理。ざざっと時系列で追う目的でしか使えない。</li>
</ul>
</li>
<li>散逸的な勉強をしない

<ul>
<li>とりあえずおもしろそうなもの、役に立つはずのものに片っ端から手をつけるのやめる。</li>
<li>Pocketに記事を置いとくのはいいけど、1週間ぐらい経ったら躊躇なく消す（自動化できないかな）。</li>
<li>上述の通りブログに上げることを目的としてノートを取っていく。参照する記事はノート上で繰り回す。</li>
<li>スーパーマンになろうとしない（選択と集中、less is more）</li>
</ul>
</li>
<li>技術的な瞬発力の向上

<ul>
<li>手足のように使える言語がほしい。Rubyかじったんだからちゃんとやり切る。</li>
<li>もう1個。デフォルトで入ってる言語だと楽なんだが。Pythonかなー。

<ul>
<li><a href="http://orangain.hatenablog.com/entry/python3-as-default">LinuxディストリビューションにおけるPython 3デフォルト化の流れ - orangain flavor</a></li>
</ul>
</li>
<li>実際の開発経験を積む。API叩くとかやる。動かす。</li>
<li>原則としてCLIで操作する。GUIに頼らない。コマンドでなんとかならないかとまず考える。</li>
</ul>
</li>
<li>文化資本に触れたい

<ul>
<li>1クール3本のアニメ</li>
<li>1か月2冊の小説</li>
<li>1か月2本の映画</li>
</ul>
</li>
<li>エンジニアとしての活動

<ul>
<li>なんかユーザーグループ入ってみたい。職種的に考えるとJAWS-UG？</li>
<li>これだけはという技術分野ほしい。Ansibleが今自分の中でキテるのでもっと。</li>
<li>GitHubをソーシャルにちゃんと使う。横断的な検索とかフォローとかプルリク出してみるとか。</li>
</ul>
</li>
</ul>


<h2>挑むべき技術分野</h2>

<ul>
<li>上述の通り武器言語としてのRuby、Python。</li>
<li>hubotいじる上でnode.jsを少しだけ。</li>
<li>DB経験がさらっさらと言っていいほどないのでMySQL（Mariaでいいか）とRedis。</li>
<li>インフラ関連技術は継続。Ansible、Serverspec、AWS。</li>
<li>最近流行ってるOSSツール類。Elasticsearch、HashiCorp周り、Docker、Sensu、Rundeck、</li>
<li>総合するとこれやってみるといいかも→ <a href="http://syou6162.hatenablog.com/entry/2015/12/21/000843">今年よかった習慣: ライフログ収集および可視化 - syou6162&rsquo;s blog</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2015年総括]]></title>
    <link href="http://chroju.github.io/blog/2015/12/31/looking-back-2015/"/>
    <updated>2015-12-31T19:23:47+09:00</updated>
    <id>http://chroju.github.io/blog/2015/12/31/looking-back-2015</id>
    <content type="html"><![CDATA[<p>いろいろとチャレンジングに動いてみただけに、難しい年だった。</p>

<p>今年初めの<a href="http://chroju.github.io/blog/2015/01/12/post/">「行動規範」</a>で書いた通り、就職は、した。大手SIerからいわゆるベンチャー気質な企業に転職して、働き方はだいぶ変わった。毎日Excelとにらめっこしていた生活ではなく、業務上初めてsshを実行し、いまでは毎日実行するような生活になった。</p>

<p>承認と判子と指示が行動の軸だった状態から、個々人のスキルと瞬発力と経験が物を言うような状態になり、率直に言ってついていけてない感はある。どこまでを許可無くやっちゃっていいのかわからない（いわゆるDon’t ask for permission, beg for forgiveness的文化）し、技術検証に手をつけ始めると基礎スキルが低いのでやたら時間を食ってしまい、その間に他の人にタスクを取られたりする。</p>

<p>でもまったく手応えがないわけではなくて、個人開発で使っていたスキルで食い込んでいけるところも大きいし、自分に足りない、学ぶべきことは山のように社内に転がっているので、ひたすら旺盛に吸収していきたいと思う。というかそうしない限り、エンジニアとして生きる道がない。</p>

<p>興味領域としてはDevOps方面にかなりアンテナが伸びてきている。大企業でわりとカッチリ運用設計を認めていた自分が、創業からそれなりの年数が経ち、技術的負債の増えてきたベンチャーに入ったことによる必然とも言えるのだろうが、運用上の穴や非効率な部分がとても目についていて、ルールで縛るのではなく、システム的に運用の統括を図ろうというのが目下の課題となっている。それこそInfrastructure as Codeを使うなりDockerを使うなり、もっと低レイヤーにシェルスクリプトをガリガリ書くなり。だから技術的に磨いて実践していくことが本当に多いのだけど、一方で運用方法の改変ということは社内への浸透が必要になり、政治的な問題にもなってくるので、コミュニケーション力結局必要やんけってところで非コミュな自分は悩んでいる。社内政治ほんとやだ。</p>

<p>まぁ、総じて言えば楽しく仕事はできている。だけど大きな変化は副作用的に予期しない変化を別のところでもたらしたりするものでもあって、そのバランスを取ることがなんとも難しい。貪欲であることと、単に我欲を押し通すこととはまた違うわけで、もう少しコントールが必要だと思っている。リスクテイクしたのだからその分の負担の大きさを覚悟してはいたが、わりと想定以上なところはあってストレスは大きい。年齢も年齢なので、自分が「何をすべきか」という論調よりも、周囲、世の中にとって自分は「何であるのか」という視点で動いた方が良いのかもなという気がしてきた。もう少し、置かれた場所というものも大事にしたい。</p>

<p>抽象論についつい流れてしまったけど、具体的な技術的成果はQiitaを中心に流していこうと思っているので、ブログはポエミーにこんな感じで締めてみる。また来年。</p>

<h2>おまけ：2015年定量評価</h2>

<h3>技術</h3>

<ul>
<li>Linuxのサーバー運用に従事開始。初歩的なコマンドからさらい直せてる。</li>
<li>CentOS7の業務利用開始。</li>
<li>AWSの利用を個人でも業務でも開始。ただしほぼEC2。</li>
<li>Ansible利用開始。</li>
<li>Serverspec検証開始。</li>
<li>Docker検証開始。</li>
</ul>


<h3>イベント</h3>

<ul>
<li>JAWS DAYS 2015</li>
<li>JAWS UG 初心者支部</li>
<li>デブサミ2015</li>
<li>Ansible入門イベント</li>
<li>他社の障害対応気にならNight</li>
<li>手羽の会（ハンズラボ）</li>
<li>Serverworks Sonic!</li>
<li>OSC東京 2015秋</li>
<li>Rakuten Tech 2015</li>
<li>RubyKaigi 2015</li>
<li>他</li>
</ul>


<h3>書籍</h3>

<ul>
<li>リーダブルコード</li>
<li>プログラマが知るべき97のこと</li>
<li>それがぼくには楽しかったから</li>
<li>ハッカーと画家</li>
<li>UNIXという考え方</li>
<li>インターネットのカタチ</li>
<li>Amazon Web Services パターン別構築・運用ガイド</li>
<li>シェルプログラミング実用テクニック</li>
<li>はじめてUNIXで仕事をする人が読む本</li>
<li>大規模サービス技術入門</li>
<li>Serverspec</li>
<li>CentOS7実践ガイド</li>
<li>Team Geak</li>
<li>オペレーティングシステムの基礎</li>
<li>たのしいインフラの歩き方</li>
<li>他</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Serverspecファーストインプレッション]]></title>
    <link href="http://chroju.github.io/blog/2015/12/31/serverspec-first-impression/"/>
    <updated>2015-12-31T19:22:54+09:00</updated>
    <id>http://chroju.github.io/blog/2015/12/31/serverspec-first-impression</id>
    <content type="html"><![CDATA[<p>秋ぐらいから個人開発で試してみて、最近業務でも使えないかとServerspecで試行錯誤している。はじめに言っておくと使用感もコンセプトもとてもしっくりきていて満足している一方で、技術的なハードルはAnsible等より上かもなと思っている。</p>

<h2>サーバー構成の「仕様書」代わりとして</h2>

<p>自分は当初Ansibleで構築したサーバーのあくまでテストツールとして使っていて、「こういう設定にしたい」という頭の中の設計書をAnsible playbooksとServerspecに同時に落とし込み、テストが通ることを確認していた。が、実際にじゃあこれを業務内でどう使おうかとワークフローを考えてみると、仕様書的な使い方がメインになりそうな気がしている。</p>

<p>Serverspecによるテストを実行するのはどういったタイミングか。構築完了時点での確認に用いるのは然り。その後サーバー設定を変更したときには、その内容をServerspecにも反映して再度テストを行うはず。つまりサーバーの仕様、設定の変更にServerspecは追従していく。逆に言えば任意のタイミングで仕掛けたServerspecがエラーを吐くことで、不意のサーバー設定変更を検知できる。サーバーの「正」とされる状態を管理する仕様書の代替として、Serverspecが活用できる気がしている。</p>

<p>中には<a href="http://blog.kenjiskywalker.org/blog/2013/09/20/serverspec-with-cron/">cronで監視チックに実行させている例</a>もあるようだが、それもアリかなと思う。</p>

<h2>導入は簡単だが探求にはRubyスキル必須</h2>

<p>Ansibleが実質的にはYAMLを書くだけで使えてしまい、内部実装に用いられているPythonの知識をほとんど必要としないのに対し、Serverspecは徐ろにRubyスキルを必要とする。</p>

<p>例えば私が初めて書いた<code>spec_helper.rb</code>はこんな感じで、公式のtipsを反映したものとはいえ、デフォルト通りでは使っていない。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="nb">require</span> <span class="s1">&#39;serverspec&#39;</span>
</span><span class='line'><span class="nb">require</span> <span class="s1">&#39;yaml&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="n">properties</span> <span class="o">=</span> <span class="no">YAML</span><span class="o">.</span><span class="n">load_file</span><span class="p">(</span><span class="s1">&#39;properties.yml&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">host</span> <span class="o">=</span> <span class="no">ENV</span><span class="o">[</span><span class="s1">&#39;TARGET_HOST&#39;</span><span class="o">]</span>
</span><span class='line'><span class="n">set_property</span> <span class="n">properties</span><span class="o">[</span><span class="n">host</span><span class="o">]</span>
</span><span class='line'>
</span><span class='line'><span class="n">set</span> <span class="ss">:backend</span><span class="p">,</span> <span class="ss">:exec</span>
</span></code></pre></td></tr></table></div></figure>


<p>実際のテスト用のタスクを生成するのもRakefileである。もちろんデフォルトのままでも使えるには使えるのだが、ちょっと凝ったことをしようと思うとRubyが読み書きできていなくては難しい。これは「Rubyにより実装されたインフラテストツール」と理解するより、「RSpecをインフラテストに使えるよう拡張したもの」と捉えた方が正しいように思う。</p>

<p>自分は元々Rubyがある程度書けるものの、RSpecが理解しきれていないので、もう少し勉強しなくてはならなさそう。</p>

<h2>国産OSSであるアドバンテージ</h2>

<p>Serverspecの何より大きなアドバンテージはここではないのか。開発者も国内にいらっしゃるので、Rebuild.fmで直接声が聴けるし、解説本もいち早くO&#8217;Reilly Japanから発行されている。特にオライリー本発刊時のRebuild.fmは本自体の補完にもなる内容で、開発コンセプトなどがよく理解できるので聴いておきたい。</p>

<p><a href="http://rebuild.fm/75/">Rebuild: 75: Book Driven Development (gosukenator)</a></p>

<div class="amazlet-box" style="margin-bottom:0px;"><div class="amazlet-image" style="float:left;margin:0px 12px 1px 0px;"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873117097/diary081213-22/ref=nosim/" name="amazletlink" target="_blank"><img src="http://ecx.images-amazon.com/images/I/51P6qVOPALL._SL160_.jpg" alt="Serverspec" style="border: none;" /></a></div><div class="amazlet-info" style="line-height:120%; margin-bottom: 10px"><div class="amazlet-name" style="margin-bottom:10px;line-height:120%"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873117097/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Serverspec</a><div class="amazlet-powered-date" style="font-size:80%;margin-top:5px;line-height:120%">posted with <a href="http://www.amazlet.com/" title="amazlet" target="_blank">amazlet</a> at 15.12.31</div></div><div class="amazlet-detail">宮下 剛輔 <br />オライリージャパン <br />売り上げランキング: 213,793<br /></div><div class="amazlet-sub-info" style="float: left;"><div class="amazlet-link" style="margin-top: 5px"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873117097/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Amazon.co.jpで詳細を見る</a></div></div></div><div class="amazlet-footer" style="clear: left"></div></div>


<p>結論として先述のようにRSpecの拡張的な位置付けであり、その他Infra as Code関連のツールと比べても実装が薄いことから、取り回しがしやすく、今後も継続して使いやすいのではないかと思う。<a href="https://github.com/ryotarai/infrataster">Infrataster</a>とも組み合わせられれば、よりテストの質は増しそう。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[『Team Geek』読了]]></title>
    <link href="http://chroju.github.io/blog/2015/12/14/review-team-geek/"/>
    <updated>2015-12-14T22:14:29+09:00</updated>
    <id>http://chroju.github.io/blog/2015/12/14/review-team-geek</id>
    <content type="html"><![CDATA[<div class="amazlet-box" style="margin-bottom:0px;"><div class="amazlet-image" style="float:left;margin:0px 12px 1px 0px;"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873116309/diary081213-22/ref=nosim/" name="amazletlink" target="_blank"><img src="http://ecx.images-amazon.com/images/I/41SlY0zvpKL._SL160_.jpg" alt="Team Geek ―Googleのギークたちはいかにしてチームを作るのか" style="border: none;" /></a></div><div class="amazlet-info" style="line-height:120%; margin-bottom: 10px"><div class="amazlet-name" style="margin-bottom:10px;line-height:120%"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873116309/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Team Geek ―Googleのギークたちはいかにしてチームを作るのか</a><div class="amazlet-powered-date" style="font-size:80%;margin-top:5px;line-height:120%">posted with <a href="http://www.amazlet.com/" title="amazlet" target="_blank">amazlet</a> at 15.12.14</div></div><div class="amazlet-detail">Brian W. Fitzpatrick Ben Collins-Sussman <br />オライリージャパン <br />売り上げランキング: 18,890<br /></div><div class="amazlet-sub-info" style="float: left;"><div class="amazlet-link" style="margin-top: 5px"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873116309/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Amazon.co.jpで詳細を見る</a></div></div></div><div class="amazlet-footer" style="clear: left"></div></div>


<p>ひたすら技術ドリブンに仕事できるのであればそれはそれで良いような気はするが、現実にはちゃんとコミュニケーション取る必要はあって、何かやりたいことがあればいわゆる政治的な課題に悩まされることになったりもする。本を読むときはつい技術系のものや個人のハッカーマインドに関するものを読みがちだけど、歳も歳だし組織論もかじろうかということで読んだ。元々読むつもりはあったが、紀伊國屋書店新宿本店でオライリーカレンダーのプレゼントやってたので背中押された。</p>

<p>とても元も子もないまとめ方をしてしまうと、<a href="http://blog.glidenote.com/blog/2015/08/17/move-to-akamai/">KAIZEN Platform, Inc. のエンジニア行動指針</a>がだいぶ本書に影響を受けたと思われるものになっていて、これに全社員がコミットできている状態というのは理想的なのだろうなと思ったりした。本書の内容にはとても賛同できるのだが、「組織論」である以上は自分だけが納得していても仕方なくて、社内でこの内容を文化として定着させなくてはならない。そこのハードルがなかなかに高い。</p>

<p>本書でもそのあたりの話には「組織的操作の技法」として第5章をまるまる当てて触れられていて、例えば「道がないなら道を作る」＝草の根からツールの導入などを始めていく、「許可を求めるより寛容を求めるほうが簡単」、「安全なポジションまで昇進する」といったことが書かれている。結局はできることからやっていく、しかなくなってしまうのかもしれない。</p>

<p>個人のマインドに関する話は大変参考になって、HRT（謙虚、尊敬、信頼）を軸として、「コードの価値を自分の価値と同一視するな」というあたりもだいぶクるものがあった。技術職としては技術的価値の優劣が極めて大きな価値をもっていて、ともすれば「モヒカン」だとか「マサカリ」といった言葉が表すような事態になりかねないのだが、チームが円滑に動くためにはそういったものは障壁となりかねない。技術的に未熟であるメンバーについても、謙虚に対応していくべきだし、また自分の技術は粛々と磨いていくことが必要なんだろうなと。</p>

<p>こういう本は一人で読んでもやっぱり仕方がないところがあるので、チームで買ってシェアしたりもアリかもしれません。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dockerファーストインプレッション]]></title>
    <link href="http://chroju.github.io/blog/2015/12/04/docker-first-impression/"/>
    <updated>2015-12-04T20:48:49+09:00</updated>
    <id>http://chroju.github.io/blog/2015/12/04/docker-first-impression</id>
    <content type="html"><![CDATA[<p>前回上げたインフラCIを試みた際、CircleCIを利用する中で初めてDockerに触れたので、今更ながらのファーストインプレッション。</p>

<h2>「仮想マシン」と考えるとDockerは理解しづらい</h2>

<p>Dockerを「仮想マシン」と称する文章も随所で見かけていたが、これを仮想マシンとして捉えると理解からは遠のく。自分自身、Dockerの概念的な理解にはかなり手こずっていて、OSがないのにどうやって「マシン」が動くのかわからなかったし、 <code>chroot</code> のようにファイルシステム上に仮想的なディレクトリツリーを設けるものなのかと思っていた。</p>

<p>Dockerは隔絶された名前空間上で展開されるプロセスに過ぎない。確かにコンテナはOSのような振る舞いを見せるが、そこにいわゆるVMwareやXenのような仮想「マシン」はない。あくまでホストOSの一部リソースを切り出して、仮想的に扱う技術に過ぎない。</p>

<h2>Vagrantの代替？</h2>

<p>一度理解して、 <code>docker run</code> を叩けるようになると利便性は即座に理解できる。OSをブートさせるわけではないのでコンテナの起動は従来の「仮想マシン」と比べて格段に速く、CircleCIで使われている用途同様、テスト用にまっさらな環境が即席で欲しいときには大変重宝する。こういう用途にはもともとVagrantが適していたのだと思うが、本当にすぐ使い捨ててしまいたいようなOS環境であれば、Dockerを使ったほうが遥かに手軽に起動も破棄もこなせる。</p>

<p>ただあまりに簡単に起動、破棄ができるものの、作成したコンテナのイメージはコンテナ終了後も基本的に残存するので、調子に乗っているうちにいつの間にかディスクがかなり消費されていることが何度かあった。コンテナライフサイクルの把握と運用整備はマスト。</p>

<h2>ポータブルなインフラストラクチャー</h2>

<p>Dockerを実用できる一例として、先日Traildashを採用する機会があった。</p>

<p><a href="https://github.com/AppliedTrust/traildash">AppliedTrust/traildash</a></p>

<p>CloudTrailという、AWS APIへのアクセスログをjsonで吐いてくれるAWSサービスがあるのだが、それをElasticsearchで集計してKibanaでブラウザ表示してくれるツール。このツールはDockerイメージで配布されていて、自分のサーバー上にpullしてきて、AWS APIへアクセスするための環境変数をいくつか設定するだけで使えるようになる。自分はElasticsearchの運用経験はないのだが、実質的に <code>docker run</code> コマンド一発だけでそれが使えてしまう。（そのことの是非は置いておくとして）Dockerがアプリケーションサイドで実現することってこういうことなんだろうと。herokuが出たとき、ローカルからインターネットへのサービスのポータビリティが劇的に向上したわけだが、Dockerは稼働先を問わないわけで、ポータビリティはさらに拡大する。</p>

<p>これはインフラ側としても嬉しいところで、今までnginxやらDBやらというミドル的な部分はアプリとしての要求もあり、インフラとしての要求もあり、双方の要件がガッシリ絡んでしまっていて、設定を後から見返すと「これなにゆえにこうなったんだっけ？」ってことが少なくなかったり、構築分担が面倒だったりというのがあって。コンテナとしてアプリをデプロイするとなると、サーバーとコンテナが明確に分離される。疎結合になる。ミドルの調整はコンテナ内だけを気にして行えばよいので、サーバーはとりあえずDocker動いてくれればいいやみたいな状態になる。雑だけど楽だろうなという気がぼんやりしている。</p>

<h2>Dockerの運用</h2>

<p>とりあえず前述のTraildashはDockerによる本番運用（外に出すものではないので本番といえるか微妙ではあるが）の発端にはなりそうなものの、いわゆるアプリ、サービスを本番稼働させるのがどんなもんなのかってところは自分自身見えてない。これをきちんと本番で扱うには可用性やら信頼性やらを担保しなくてはならないわけで、クラスタ構成に用いる<a href="https://docs.docker.com/swarm/">Docker Swarm</a>を導入するだとか、いわゆるインフラとしてのお仕事はやっぱり必要になる。そのへんどこかで試せればなぁとは思うので、ひとまずは自分の http;//chroju.net をDocker化しようかなどと。この前OSCでさくらのクラウド2万円クーポンもらったし、Dockerによる個人PaaS的なものでも作ってみようか。</p>

<p>テストとしての利用には申し分のないところで、先日記事で上げたが<a href="http://chroju.github.io/blog/2015/11/18/ansible-serverspec-circle-ci/">AnsibleとServerspecのテスト</a>に使えるまっさらなOS環境としてDockerは重宝している。Infra as Codeと大変相性がよくて、よくこのタイミングで出てきてくれたなという感じがする。時代の要請なのだろうか。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansible + Serverspec + Docker + circle ci によるインフラCI]]></title>
    <link href="http://chroju.github.io/blog/2015/11/18/ansible-serverspec-circle-ci/"/>
    <updated>2015-11-18T22:13:25+09:00</updated>
    <id>http://chroju.github.io/blog/2015/11/18/ansible-serverspec-circle-ci</id>
    <content type="html"><![CDATA[<p><a href="http://blog.kenjiskywalker.org/blog/2014/11/13/circleci-docker-ansible-serverspec/">CircleCIでDockerコンテナに対してansibleを実行しserverspecでテストをする - さよならインターネット</a></p>

<p>この記事に書かれている内容を実際にやってみた。Ansibleを一旦は触ってみたところから、Circle.CIどころかCI経験が一切ない、ServerspecとDockerも使ったことがないという出発点だったので、得られるものはだいぶ大きい経験だった。完了したレポジトリは以下。</p>

<p><a href="https://github.com/chroju/ansible-ruby-devs">chroju/ansible-ruby-devs</a></p>

<h1>Ansibleにテストは必要か？</h1>

<p>AnsibleはPlaybookに書かれた設定通りにサーバーをセッティングしてくれるツールなのだから、傍証としてのテストは必要ないし、そもそもそれはAnsibleに対する信頼の問題だという話がある。（かのオライリーのServerspec本でも「Serverspecの必要性」を状況に応じて説明した章がある）が、自分は以下の理由からAnsible実行後のテストは必要と考えている。</p>

<h2>1. Playbookの書き方が間違っている</h2>

<p>確かにPlaybookに書いた内容通りにサーバーは組まれるのだが、そもそもPlaybookの書き方がおかしくて、想定通りの実行結果にならない可能性はある。そのレベルであればコードレビューで気付くべきではないかという話もあるが、こういう趣味の個人開発では難しかったり、レビューで漏れがあったりというのも有り得るわけで、自動テストに任せられるならその方が確かかとは思う。</p>

<h2>2. 冪等性の問題</h2>

<p>特にshellモジュールを用いたときなどは冪等性が維持されない可能性があり、複数回の実行で想定外のサーバー状態になる可能性はある。</p>

<h1>テストツールの選定</h1>

<p>普通にServerspec。Ansibleで定義したインベントリファイルやrolesをServerspecと共有してくれる<a href="http://qiita.com/volanja/items/5e97432d6b231dbb31c1">ansible_spec</a>というツールもあり、当初はこちらを使おうとしていた。が、前述した「Ansibleの書き方自体が間違っている可能性」をテストするとなると、できるだけAnsibleとテストツールは疎結合とするべきと考え、ファイルや設定は一切共有しない形でServerspecを使っている。</p>

<h1>Circle CIの利用</h1>

<p>繰り返しになるが初である。インフラエンジニアがCIをすることはまぁない（なかった）。そんな頻繁に設定を変えるわけでもなし。インフラCIが可能かつ必要となったのは、Infrastructure as Codeの台頭と、クラウドネイティブ化によりImmutableかつ極めて速いライフサイクルでサーバーインフラが更新されるようになったことによるもの。</p>

<p>で、Circle CIでググってもそんなに使い方みたいな初歩的な記事は出ない。どうもCIツールの使い方なんてのはJenkins登場の頃に身につけてて当然だろって感じの扱いっぽい。実際使いながら自分なりに理解したのは「レポジトリをpushすると、それを使って自動的にテストやデプロイを回してくれる」ツールということで、Circle CIについてはこんな感じに認識してるんだがあってんのかなぁ。</p>

<ul>
<li>レポジトリの使用言語やファイル構成を見て良きに計らって勝手にテストしてくれる。</li>
<li>もちろん自分でテストコマンドを書いてもOKで、Circle CIにやってほしいことは <code>circle.yml</code> というYAMLファイルに書いてレポジトリの第一階層に置いておく。</li>
<li>GitHub連携を前提としており、連携したレポジトリの <code>push</code> をトリガーとして動作する。</li>
<li>動作としてはCircle CI上でDockerコンテナ（ubuntuベース）を起動→レポジトリを <code>git clone</code> →circle.ymlを読んで実行</li>
</ul>


<h1>実装</h1>

<p>実際のcircle.ymlはこうなった（といってもほぼ丸のまま冒頭記事のものを使っているが）。Dockerイメージのキャッシュには以下の記事も参考にした。</p>

<p><a href="http://stormcat.hatenablog.com/entry/2015/02/04/004227">CircleCIでDockerイメージをキャッシュするのに、実はちょっとした工夫が必要な件 - tehepero note(・ω&lt;)</a></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">machine</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">timezone</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">Asia/Tokyo</span>
</span><span class='line'>  <span class="l-Scalar-Plain">services</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">docker</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">dependencies</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">pre</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">if [[ -e ~/docker/docker_ansible_image.tar ]]; then docker load --input ~/docker/docker_ansible_image.tar ; else docker build -t centos_ansible ~/ansible-ruby-devs/ ; mkdir -p ~/docker ; docker save -o ~/docker/docker_ansible_image.tar centos_ansible ; fi</span>
</span><span class='line'>
</span><span class='line'>  <span class="l-Scalar-Plain">cache_directories</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="s">&quot;~/docker&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">test</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">override</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">docker run -v `pwd`/ansible:/ansible centos_ansible /bin/sh -c &#39;ansible-playbook /ansible/ci_site.yml -i /ansible/ci_hosts -c local &amp;&amp; cd /ansible/spec &amp;&amp; /home/develop/.rbenv/bin/rbenv exec bundle install &amp;&amp; /home/develop/.rbenv/bin/rbenv exec bundle exec rake spec&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>この方法の肝はAnsibleとServerspecのフォルダを<code>docker run</code>の<code>-v</code>オプションでコンテナにマウントさせてしまって、ローカルでいずれも実行させている点だと思う。Dockerコンテナに対してSSHで外から処理を行うことももちろん可能ではあるが、ちょこちょこと小細工は必要だし、CI上の処理であればミニマムに済ませたいところ。</p>

<p>テストにおいてはインベントリファイルも<code>site.yml</code>もテスト用の設定値となるので、CI用のファイルを置いている。ただ、これらはレポジトリにとっては余分なファイルでしかないので、本来であれば取り除きたいような気もする。妙案は浮かばない。Dockerコンテナは2回目以降の実行だと<code>load</code>するだけで済むし、AnsibleとServerspecはローカル実行なので、処理時間はだいぶ速い。</p>

<p>実行結果はslackの個人チャンネルに流している。GtiHubに上げるだけで勝手にテストして結果も自動通知されるというのはとても楽しい。やれることの自由度が広すぎて夢が広がる。</p>

<h1>つまずいた点</h1>

<ul>
<li>Dockerfile初挑戦につき、結構戸惑った。Ansibleでsshd_configを編集させていたのだが、コンテナにそもそもsshが入ってなくてコケたりした。</li>
<li>Circle CIでのカレントディレクトリの扱いがわからず、しばらく <code>circle.yml</code> で指定するファイルパスに悩まされた。クローンしたレポジトリの中にいる状態で始まるっぽい？</li>
<li><code>docker run</code> に <code>&amp;&amp;</code> 付きでコマンド渡すときに <code>/bin/sh -c</code> が必要だとしばらく気付かなかった。</li>
<li>Dockerコンテナを <code>save</code> して <code>load</code> してるので、Dockerfile書き換えたら当然ながらCircle CIを「without cache」で実行しないとダメです。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[オープンソースカンファレンス2015 Tokyo/Fall行ってきた]]></title>
    <link href="http://chroju.github.io/blog/2015/10/25/osc-2015-tokyo-fall/"/>
    <updated>2015-10-25T21:42:59+09:00</updated>
    <id>http://chroju.github.io/blog/2015/10/25/osc-2015-tokyo-fall</id>
    <content type="html"><![CDATA[<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/chroju/22273557670/in/dateposted-public/" title="このはちゃんかわいい"><img src="https://farm1.staticflickr.com/630/22273557670_c7c51c391b_z.jpg" width="640" height="640" alt="このはちゃんかわいい"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>戦利品、ConoHaちゃんかわええ。</p>

<p>オープンソースカンファレンスに初めて行ってみた。2015 Tokyo/Fallです。だいぶ奥地の方でやってるなぁという印象があってなかなか行きづらかったのだが、実際行ってみると自然に囲まれて静かで建物綺麗で過ごしやすそうないい大学ですね。ちょっぴり休憩でもくもくしたりしてみたけどだいぶ捗ったし、もう少し近所なら作業環境に使いたい感じが（）</p>

<p>ぼっち参戦かつ初参戦かつコミュ障な故、ブースがんがん回ってがんがん自分から話しかけるみたいな度胸はなく、だいたいセッション聴いてました。ので、セッションごとにちょっとまとめる。</p>

<h1>はじめてのオープンソース・ライセンス</h1>

<p>オープンソース自体の考え方だとかは知ってはいたのだが、ライセンスがMITとかApacheとかそういういろいろがあるのがよくわかってなかったので。話の中で教えていただいた<a href="http://www.catch.jp/oss-license/2013/09/10/github/">Githubによる、オープンソースライセンスの選び方 | オープンソース・ライセンスの談話室</a>というページが確かに詳しそうなので後で読まなければなと思った。ギッハブ使ってるのに全然これ理解してなかった。</p>

<h1>実録！Hinemos導入経験者が語る、実運用でのあるある話</h1>

<p>最近実務でHinemosを使っているもので。監視設定をグループ（スコープ）単位で作ってしまうと静観するときに設定変更がしんどいだとかっていう本当にあるあるな話と、<a href="http://www.hinemos.info/option/utility">Hinemos Utility</a>が便利だという話など。Hinemos Utility、設定のインポートエクスポートがあるので、GUIポチポチの面倒臭さから救われそうな気はした。あるある話の方は他の監視ツールでもわりと似たところあるので、結局アーキテクチャーってどんなツールでも大して変わらんのかなぁ、そのへんどうにかしたツールないかなぁとか思った。</p>

<p>そういえばセッションはTISの主催だったのだが、同社といえば<a href="http://thinkit.co.jp/author/3519">Zabbixの池田氏</a>の印象が強いので、Zabbixと比較して同社としてどう考えてるのかってあたりも聞きたかった。</p>

<h1>[飲食OK]（発表者募集中！）1日目-ライトニングトーク（by OSCスポンサー）</h1>

<p>なかなかカオスにライトニングトーク。飲食OKでしたけど学食せっかくなので使いたかったので無飲食で。言及してるとキリがないので割愛。</p>

<h1>Ubuntuの最新情報</h1>

<p>Ubuntu使ってない。てかDebian系ほとんど触った経験ないんで触らなきゃなと思いました。</p>

<h1>ZabbixでDockerも監視してみよう</h1>

<p>最後の質疑で出た話で、新陳代謝の高いコンテナの監視に既存ツールの分単位での監視感覚が役に立つのか？っていうのがあったのだけど、わりとそれに同意した。自分はコンテナを実サービスで運用した経験がないのでアレなのだが、その性質からして既存サーバーより速いスピードで起動停止を繰り返すことは有り得ると思うし、むしろアーキテクチャーの考え方がスピーディーなものに変わるためには監視ツールの在り方も変わんなきゃならないんじゃないかなぁと思った。答えは出てないけど。</p>

<h1>コンテナ(Docker)時代のインフラ技術・運用管理に迫る！</h1>

<p>Docker最新事情という感じで、Dockerの概要もそこそこに周辺ツールや開発状況をいろいろ舐めていく感じのセッション。Docker触り始めたばかりの自分にはとてもありがたかった。Docker machine、Docker Swarm、docker-composeだとかなかなかにワクワクする話。</p>

<h1>aozorahackの今までとこれから ～インターネット電子図書館「青空文庫」をエンジニアリングで支える～</h1>

<p>ここから2日目。春に<a href="https://atnd.org/events/66230">青空文庫アイディアソン</a>が開かれて話題になりましたが、そのときから興味があったので話を聞いてみた。青空文庫の誕生が1997年、オープンソースという言葉が生まれたのが1998年ということで、オープンソースより古い歴史を持つ青空文庫がOSSライクな発想をしていたはずもない！という出発点だったようなのだが、それを変えていこうという試み。もともとサードパーティ的にビューアやコンバータを作る動きは周辺にあったわけで、それをまとめて今風の開発をしていくとなると面白そうだなと思う。自分は業務エンジニア＋趣味エンジニアでしかないけど、こういうボランティアというか、自らの意志で参画していくエンジニアリング活動というのがOSSの在り方なんだとここで初めて腑に落ちた気がした。</p>

<h1>Solaris ZoneとPuppet、Serverspecでインフラ CI</h1>

<p>Solarisわからないけどインフラ周りの知識手広くしたいなということで行ってはみたがやっぱりわからなかった。知識って広くて浅いか狭くて深いかの二択だと勝手に思ってたけど、実際それなりに出来るエンジニアってそこそこ手広く平均点取れる人が多い気がしていて、例えばこのセッションであればUNIX（Solaris）の知識にコンテナ（Zone）の知識、んでPuppetはRubyだし、ServerspecもRubyというかRSpecなんですよね。エンジニアとしての幅、ちょっと見直したいなと思わされたセッション。</p>

<h1>【パネルディスカッション】今こそ語るエンジニアの幸せな未来 ～OSC東京編～</h1>

<p>春に行ったJAWS DAYSでも同様のパネディスを聴いてはいたので実質第二回というか。こういう話題が定期的に持ち上がるようになったのって、さくらインターネットが15周年迎えたこともあるようにエンジニアの高齢化（家庭環境の変化）があるような気はする。働き方はライフステージによっても、世の中の技術動向やビジネス動向によっても変わるので、結局時間と金銭的余裕のあるうちに勉強して、常に自分が働きやすい場所にいられるようバリューを磨いておくしかないのだろうなと思う。そういう話でした。</p>

<p>以上、9セッション。知識のザッピングとしてこういうセッション形式のイベントはやはり良いなと。いわゆる勉強会だとだいたいが自分の興味関心のあることだけに集中してしまうのだが、こういう機会だとせっかくなのでってことで脇道に逸れたりしやすいので、知識の幅増やす機会にはなりやすいですね。OSS、TISのようにビジネスとして取り扱っている人たちもいれば、aozorahackのような草の根の動きもあったり、有り様はいろいろであって、んでGitHubで取りあえずソース読むところからいつでも手を付けられる時代にあるので、何かしらやってみると面白いのかもしれない。尻込みしてるのではなく。</p>

<blockquote class="twitter-tweet" lang="ja"><p lang="ja" dir="ltr">テロ <a href="https://twitter.com/hashtag/osc15tk?src=hash">#osc15tk</a> <a href="https://t.co/OEa2JYMezY">pic.twitter.com/OEa2JYMezY</a></p>&mdash; T.Kabu (@disco_v8) <a href="https://twitter.com/disco_v8/status/657855359357337600">2015, 10月 24</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>懇親会、<a href="https://twitter.com/chroju/status/657852424502276096">TRIGGER ANIMATION EXPO</a>に行けるチャンスがここしかなかったのと、200人という大所帯にぼっち参戦する勇気がないのと（あと、さすがに薄い話しかできなさそうであまり意味はないかなと思った）で行かなかったんだけど、生ハム原木はうらやましかった。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[インフラエンジニアの幸福論]]></title>
    <link href="http://chroju.github.io/blog/2015/10/20/eudaemonics-of-infrastructure-engineer/"/>
    <updated>2015-10-20T23:35:46+09:00</updated>
    <id>http://chroju.github.io/blog/2015/10/20/eudaemonics-of-infrastructure-engineer</id>
    <content type="html"><![CDATA[<p>1年前、<a href="http://yapcasia.org/2014/talk/show/df196eac-fb65-11e3-b7e8-e4a96aeab6a4">インフラエンジニアは死んだ</a>。</p>

<p>遅れにも遅れをとって今年からAWSに触れているけど、これは触れれば触れるほどインフラエンジニアとしての自分の価値に疑問を抱かせてくれるサービスで、インフラエンジニアとして今後自分はどのように幸せになれるのかなんて考えたくなってくる。</p>

<p>どうもLambdaが出たあたりから<a href="http://blog.takuros.net/entry/2015/10/19/081349">サーバーレスアーキテクチャ</a>という言葉が取り沙汰されてきているようで、アプリやDBを動かすための基盤としてサーバーが必要だという前提はすでに崩れている。AWSを触れる前はVPSを触っていたので、どうもAWS＝EC2というイメージから抜け出せずにいたが、実際には<a href="http://i-think-it.net/how-to-aws">「EC2を使ったら負け」</a>なんて言葉も目にする時代にある。ここ最近Circle CIを触ってみていても、テストの実行基盤となるサーバーなんて考え方をする必要はなくて、テスト用の環境はyamlで書けてしまうし、別のインスタンスが欲しければDockerで済ませられる。まぁherokuあたりからすでにそういう風潮だったよなという気もするが、単純にアプリをデプロイしてしまって実行基盤は全部お任せという状態から、LambdaとS3とCognitoを組み合わせて云々みたいな柔軟なアーキテクチャを採用できる状態にまで変化してきている。</p>

<p>AWSを管理する人間が旧来のインフラエンジニアである必要性を当人としてはあまり感じていないし、実際に昨今のWeb企業あたりだとアプリエンジニアがAWSエンジニアを兼ねている場合も少なくないとは思う。規模が大きくなれば構成設計にインフラエンジニアの視点が必要になったりもするのかもしれないが、そこで必要とされるスキルは必ずしも旧来のインフラスキルとは直結していない。1000万円のLBとCiscoのスイッチとDELLのサーバーを買ってきて配線して起動して設定していくスキルと、ブラウザ上でELBやEC2のセキュリティグループを設定するスキルは明らかに異なるもので、故に2015年におけるインフラ＝AWSの領域においては、旧来のインフラエンジニアと非インフラエンジニアが同じ土俵で戦えなくもなかったりする（さすがに言い過ぎ感あるか）。これまで培ってきたインフラスキルというものは、必ずしも2015年に戦える武器にはなっていない。</p>

<p>もちろん一方でEC2もオンプレの環境もまだ健在ではあるし、これが10年後に撤廃されるかというと、現状のMFのように残り続けるとは思う。特に金融のような特殊領域ではどうしてもクラウド移行が難しいということもある。だから旧来のインフラエンジニアが死に絶えることはないのだろうが、それでもパイが小さくなることは事実だし、物理環境の障害だとか5年ごとのリプレースだとか、テンションの上がらない類の仕事に携わり続けることを余儀なくされる。</p>

<p>テンションの上がる仕事がしたいと言うと軽薄になってしまうが、誰だって夜中にタクシーでデータセンターに駆け付ける機会は極力少なくしたいと思うわけで、これまで注力していたいわゆる「オープン系」の需要が狭まる中で、インフラエンジニアの「幸福論」のようなものは求められつつある気がする。より少なくなる、かつ結構しんどい椅子に座り続けるのは個人的に嫌なので、Docker、ServerSpec、Ansibleあたりの領域でガッツリ存在感を示せるようになるか、あるいはそれらを生み出す側、より下のレイヤーで技術的に研ぎ澄まされていくかの二択なのかなと最近は思いつつある。とはいえ後者はどう考えても狭き門であり、現実的には前者を日常的な業務としつつ、要はRubyエンジニアがgem書くような感覚でツール作ったりOSSにイッチョカミしたりもたまにやれるぐらいの力があるといいのだろうなと思う。</p>

<p>何はともあれやはり「勉強する」以外に道がないことは今も昔も変わってないし、ある意味で過渡期にある技術として、いまインフラは面白いところにあるとは思っている。これについていけるかついていけないかっていうシンプルな問いでもあって、自分の希望としてはついていきたい。今からアプリに鞍替えする気はなく、カーネル書けるかって言えば書けないだろうし、かといって今のまま障害対応で夜に起こされるのを続けるわけにもいかない。だったら2015年におけるインフラというものを学んでいくしかないわけで、幸いなことに、学べば「物理ハードウェアからの開放」というある程度の報酬が待ち受けていることは確実になっている。どれだけ頑張ってもサーバーのファームウェアのバグで泣かされるような時代ではなく、ある意味でインフラエンジニアが「インフラを学び直す」ことは美味しい選択肢ではある。また場合によっては、インフラエンジニアとしてより良い環境へ適時シフトしていく（惰性でずっとオンプレ使う方針の会社との喧嘩は早々に諦める）こともまた必要になるのだと思っている。</p>

<p>とかなんとか書きながら考えていたら、<a href="http://blog.hifumi.info/2015/02/23/wakateinfra/">若手インフラエンジニア現状確認会</a>とやらで似たような話が上がっていた。個人的な実感としてはITエンジニア100人の企業であれば5～9人ぐらいがインフラかなと思うので、若手インフラが少ないというよりは全体的にインフラエンジニアが少ないのだと思っているが、その分情報交換とか大切にしなきゃなと思う。エンジニア仲間増やしたい。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[個人開発環境にGithub Flowを適用する]]></title>
    <link href="http://chroju.github.io/blog/2015/10/04/individual-github-flow/"/>
    <updated>2015-10-04T14:00:05+09:00</updated>
    <id>http://chroju.github.io/blog/2015/10/04/individual-github-flow</id>
    <content type="html"><![CDATA[<p>Github、<a href="https://github.com/chroju">joinしたのは2013年</a>で作ったものは軒並みちゃんと突っ込んではいるんだけど、単に一区切りついたらadd => commit => pushしているだけでちゃんと使っていなかったので、個人開発ではあるがGithub Flowを取り入れてみた。</p>

<h1>What is Github flow ?</h1>

<p>Githubを用いた開発作業を進めるにあたっての指針みたいなものです。基本的にはmasterブランチ上では作業せず、作業工程ごとにブランチ作って、終わったらプルリクしてmasterにマージしてもらうことでデプロイとしましょうね、というものだと理解している。至ってシンプルではあるけど、これを取り入れるだけで従来やっちゃってた「masterで作業してるのでデプロイしても動かないレポジトリがGithub上にある」みたいな状態が防げて良さそうだと思った。</p>

<p>ちなみにGit-flowというのもあるようだけど、こちらは全然別個のツールらしく理解していない。Git-flowの問題解決としてGithub Flowが提唱されたようだが、そもそも開発工程の制御のためだけにツールを追加したくはないなと思ったのでGithub Flowを採用した。</p>

<p>Github Flowの理解にはこの文章が良さそう。なお、dotfilesのような大した更新のないレポジトリにはさすがに適用していない。</p>

<p><a href="https://gist.github.com/Gab-km/3705015">GitHub Flow (Japanese translation)</a></p>

<h1>実際の開発工程</h1>

<p>あくまでGithub Flowに沿う形という程度なので、そのままそっくり適用できてはないとは思うが。</p>

<h2>開発開始</h2>

<p>ブランチを切る。ブランチ名は機能追加等の開発要件であれば<code>dev_hoge</code>、バグフィックスであれば<code>hotfix_hoge</code>とする。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>git checkout -b dev_hoge
</span></code></pre></td></tr></table></div></figure>


<h2>開発中</h2>

<p>普通であればレビューを依頼するタイミングなど、開発の切りがついたところで<code>push</code>していくのだろうが、分散して開発しているわけではないので、1日の開発が終わる段階で<code>push</code>している。そもそも開発に使っている環境が複数あるので、Github上のdevelopブランチも常に最新化していつどこでも<code>fetch</code>可能にしたいなという思いがある。従来はDropboxで各環境間の同期を取っていたが、プラグインの有無やbundleなどで度々不具合もあったので改めた。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>git add -A
</span><span class='line'><span class="nv">$ </span>git commit -m <span class="err">&quot;</span>
</span><span class='line'>...
</span><span class='line'><span class="nv">$ </span>git push origin dev_hoge
</span></code></pre></td></tr></table></div></figure>


<p><code>git add .</code>ではなく<code>-A</code>なのは、そちらじゃないと<code>git rm</code>したファイル等が含まれないと<a href="http://qiita.com/otukutun/items/9feb513c596418e94fc6">こちらの記事</a>に書いてあったゆえ。</p>

<h2>開発終了</h2>

<p>開発が終わり、masterへのマージを必要とする段階に来たらプルリクを出す。プルリクって別のコミッターからしか不可なのかと思っていたが、自分のレポジトリに自分で出すことも可能だったのでそうしている。本来であればテストツール等走らせるべきではあるのだろうが、今のところはプルリクに対して特にレビュー等なく（自分のコードだし）そのままマージしている。</p>

<p>後述するがバグや開発課題の管理にはGithub issueを用いているので、マージの際はissueのナンバーをコメントに入れている。これでGithub上のリンクとして働いてくれるので便利。</p>

<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/chroju/21903884486/" title="スクリーンショット 2015-10-04 14.19.25"><img src="https://farm1.staticflickr.com/735/21903884486_cae2057f70_z.jpg" width="640" height="576" alt="スクリーンショット 2015-10-04 14.19.25"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>参考：<a href="http://rochefort.hatenablog.com/entry/2015/09/05/090000">Gitコミットメッセージの7大原則 - rochefort&rsquo;s blog</a></p>

<h2>マージ後</h2>

<p>作業ブランチを消して、ローカルのmasterを最新化する。</p>

<p>マージには<code>git merge</code>を使用し、<code>git rebase</code>は使わないことにしている。そもそも<code>rebase</code>完全に理解してないというのもあるが、要するに歴史改変にあたるような操作があまり好めないというのが強い。個人の開発においては作業ブランチの変更中にmasterに更新が入ることは少ないので、このやり方でおそらく不都合はしないと思っている。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>git checkout master
</span><span class='line'><span class="nv">$ </span>git branch -a
</span><span class='line'><span class="nv">$ </span>git branch -d dev_hoge
</span><span class='line'><span class="nv">$ </span>git push --delete origin dev_hoge
</span><span class='line'><span class="nv">$ </span>git fetch
</span><span class='line'><span class="nv">$ </span>git marge origin/master
</span></code></pre></td></tr></table></div></figure>


<p>参考
<a href="http://dev.classmethod.jp/tool/git/development-flow-with-branch-and-rebase-by-git/">GitのRebaseによるBranchの運用 ｜ Developers.IO</a>
<a href="http://kray.jp/blog/git-pull-rebase/">git pull と git pull –rebase の違いって？図を交えて説明します！ | KRAY Inc</a></p>

<h2>コンフリクトした場合</h2>

<p><code>git ls-files -u</code>でコンフリクトしたファイルが一覧化されるとのことなので、確認の上で開いて直す。もしローカルかリモートのいずれかを全面採用するのであれば、<code>git checkout</code>の<code>--ours</code>と<code>--theirs</code>オプションを使う。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git ls-files -u
</span><span class='line'>git checkout --ours hoge
</span><span class='line'>git checkout --theris hoge
</span></code></pre></td></tr></table></div></figure>


<p>参考：<a href="http://d.hatena.ne.jp/sinsoku/20110831/1314720280">Gitでコンフリクトした時のための備忘録 - アジャイルSEを目指すブログ</a></p>

<h2>リモートのmasterがローカルより先に行っている場合</h2>

<p>ローカル環境が複数あるので、このような場合は多々ありえる。そういうときは基本的にはmergeすればいいだけではあるが。masterはリモートレポジトリの最新化が原則となるので、コンフリクトした場合は99%リモートを優先させる。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git show-branch --all --color
</span><span class='line'>git fetch origin
</span><span class='line'>git diff origin/master
</span><span class='line'>git merge origin/master
</span></code></pre></td></tr></table></div></figure>


<p>参考：<a href="http://qiita.com/yuyuchu3333/items/a30387bdd6a0afc1185c">gitのリモートリポジトリの更新を確認する - Qiita</a></p>

<h2>バグ、開発課題の発生</h2>

<p>先に少し触れたが、開発すべきTODOはすべてGithub issueで管理することにした。今までどうしていたかというと特に管理はしておらず、思いつくままに開発してしまっていたのだが、これでGithubに開発に必要なものはすべて集約できるのではないかと思う。個人でのGithub issue運営には下記の記事を参考にさせてもらっているが、特に難しいことはせず、タスク管理ツールのような形で使っている。</p>

<p>参考：<a href="http://azu.github.io/slide/udonjs/github-issue.html#3">一人で使えるGithub Issue</a></p>

<h1>覚えられない</h1>

<p>Github Flowは便利なのだが、Gitのコマンド体系がどうにも覚えづらくて仕方がない。どうにもならんのでaliasを駆使してなるべく覚える内容を少なくしようと努めているが、あとは慣れるしかないのかなぁと。Githubのコマンドは本当に多い。体系自体を学ぶのであれば<a href="https://progit-ja.github.io/">Pro Git</a>がわかりやすく、epubの配布もあるのでKindleでいつでも読めて最高なのだが、数多あるコマンドを網羅しようとか思うとこれだけではつらい。Qiitaでまとめ記事が上がるたびに覗いてみて、今の自分のキャパで使えそうなのをつまみ食いしていく形で覚えればいいのかなと思っている。</p>

<p>今のalias設定はこんなの。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="o">[</span><span class="nb">alias</span><span class="o">]</span>
</span><span class='line'>  <span class="nv">a</span>  <span class="o">=</span> add
</span><span class='line'>  <span class="nv">aa</span> <span class="o">=</span> add --all
</span><span class='line'>  <span class="nv">br</span> <span class="o">=</span> branch
</span><span class='line'>  <span class="nv">bra</span> <span class="o">=</span> branch -a
</span><span class='line'>  <span class="nv">brd</span> <span class="o">=</span> branch -d
</span><span class='line'>  <span class="nv">co</span> <span class="o">=</span> checkout
</span><span class='line'>  <span class="nv">cob</span> <span class="o">=</span> checkout -b
</span><span class='line'>  <span class="nv">coo</span> <span class="o">=</span> checkout --ours
</span><span class='line'>  <span class="nv">cot</span> <span class="o">=</span> checkout --theirs
</span><span class='line'>  <span class="nv">cl</span> <span class="o">=</span> clone
</span><span class='line'>  <span class="nv">clr</span> <span class="o">=</span> clone --recursive
</span><span class='line'>  <span class="nv">cm</span> <span class="o">=</span> commit
</span><span class='line'>  <span class="nv">cmm</span> <span class="o">=</span> commit -m
</span><span class='line'>  <span class="nv">d</span>  <span class="o">=</span> diff
</span><span class='line'>  <span class="nv">f</span>  <span class="o">=</span> fetch
</span><span class='line'>  <span class="nv">lg</span> <span class="o">=</span> log
</span><span class='line'>  <span class="nv">lga</span> <span class="o">=</span> log --graph --decorate --online
</span><span class='line'>  <span class="nv">lgp</span> <span class="o">=</span> log -p
</span><span class='line'>  <span class="nv">mg</span> <span class="o">=</span> merge
</span><span class='line'>  <span class="nv">mgn</span> <span class="o">=</span> merge --no-ff
</span><span class='line'>  <span class="nv">ps</span> <span class="o">=</span> push
</span><span class='line'>  <span class="nv">psd</span> <span class="o">=</span> push --delete origin
</span><span class='line'>  <span class="nv">pso</span> <span class="o">=</span> push origin
</span><span class='line'>  <span class="nv">psm</span> <span class="o">=</span> push origin master
</span><span class='line'>  <span class="nv">pl</span> <span class="o">=</span> pull
</span><span class='line'>  <span class="nv">s</span>  <span class="o">=</span> status -s
</span><span class='line'>  <span class="nv">sb</span> <span class="o">=</span> status -s --branch
</span><span class='line'>  <span class="nv">ss</span> <span class="o">=</span> status
</span><span class='line'>  <span class="nv">sh</span> <span class="o">=</span> show
</span><span class='line'>  <span class="nv">sba</span> <span class="o">=</span> show-branch --all
</span></code></pre></td></tr></table></div></figure>


<h1>今後</h1>

<p>やりたいこととしてはCI。Circle CIとかと連動させて自動テストしたりというところまで組み込めたら、個人開発としてだいぶ理想的な状態かなと思う。そのままデプロイまで自動化できれば最高か。またGitの理解がやはりどうにも覚束ない部分があり、まだまだ使いこなせているとは言いがたいので、aliasをカンペ代わりに育てつつ、ガンガン覚えていきたい。特にミスったときの<code>reset</code>系コマンドがあまりに多くてなぁ……。</p>

<h1>その他参考記事</h1>

<ul>
<li><a href="http://keijinsonyaban.blogspot.jp/2011/05/git.html?m=1">見えないチカラ: 【翻訳】Gitをボトムアップから理解する</a></li>
<li><a href="http://postd.cc/git-command-line-shortcuts/">Gitコマンドラインショートカット | プログラミング | POSTD</a></li>
<li><a href="http://yuroyoro.hatenablog.com/entry/20101008/1286531851">.gitconfigに設定してるaliasなどのまとめ - ( ꒪⌓꒪) ゆるよろ日記</a></li>
<li><a href="http://d.hatena.ne.jp/sinsoku/20111025/1319497900">図で分かるgit-mergeの&ndash;ff, &ndash;no-ff, &ndash;squashの違い - アジャイルSEを目指すブログ</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[開発環境のためのansibleを出来るだけベストプラクティスでまとめた]]></title>
    <link href="http://chroju.github.io/blog/2015/09/24/ansible-in-nearly-best-practice/"/>
    <updated>2015-09-24T19:37:08+09:00</updated>
    <id>http://chroju.github.io/blog/2015/09/24/ansible-in-nearly-best-practice</id>
    <content type="html"><![CDATA[<p>自分は今まで開発に使うマシンとして家では据え置きのiMac Mid 2010（古い）を、出先ではVAIO Proに入れたArch Linuxを使っていて、レポジトリの同期にはあろうことかDropboxを使っていたのだが、インストールされているツールが微妙に違っていたり、Dropboxで<code>bundle</code>とかまで同期してしまうのはあまりよろしくなさそうだなというのもあったりして、EC2上に開発環境を置いて各端末からはSSHでつなぐことにしてみた。で、せっかくなのでと思いansbileで環境構築を行っている。</p>

<h2>なぜEC2？</h2>

<p>少し前に<a href="http://chroju.github.io/blog/2015/07/20/ansible-digitalocean-vps-dev-env/">開発環境としてDigitalOceanを使うことを勧める記事</a>を書いたことがあったが、仮想マシンを停止しても課金が発生してしまうのが少々つらいのと、リージョンがすべて国外で、開発に使うにはさすがにレイテンシーが厳しいので断念した。EC2であれば停止中は課金されないので、常時起動が必要ない開発環境として使う分には課金額は少なくなりそうかなと考えている。今は自分のアカウントだとまだ無料期間にあたるので、t2.microを無料で使える状態にあり、実際の課金額がどうなるかは確かめていない。</p>

<h2>ベストプラクティス構成の意識</h2>

<p>出来上がったplaybooks（という言い方でいいのか？）はGitHubに上げてある。</p>

<p><a href="https://github.com/chroju/ansible">chroju/ansible</a></p>

<p>あらゆるサーバーで共通の<code>common</code>というロールと、開発環境用の<code>develop</code>というロールを用意している。現状、開発言語がRubyでシェルにはzshを使っているので、完全に自分仕様のplaybookにはなっている。dotfilesも自分のレポジトリから<code>git clone</code>しているし。</p>

<p>ansibleには公式ドキュメントに<a href="http://docs.ansible.com/ansible/playbooks_best_practices.html">ディレクトリ構成のベストプラクティス</a>が上がっていて、なるべくこれに沿うようには作っている。が、完全に当てはめてしまうには開発環境1サーバーだけのためのansibleには荷が重すぎるので、あくまで部分適用ではある。自分の解釈ではベストプラクティスの考え方はこんなところかと。</p>

<ul>
<li>playbooksは同時に実行すべきtaskをroleとして分割する</li>
<li>ansibleの適用対象サーバーはWeb、DB等の役割ごとにグループで分割する</li>
<li>グループごとに実行するroleと変数（group_vars）を紐つける</li>
</ul>


<p>taskはroleに分割され、それらroleをwebservers.ymlやdbservers.ymlがincludeし、さらにsite.ymlがすべての*servers.ymlをincludeするというのが公式の勧めです。確かにこれなら全体に適用したい場合は<code>ansible-playbook site.yml</code>でよいし、一部グループだけに適用したいなら<code>ansible-playbook *servers.yml</code>とすれば良いのだから合理的。さらにインベントリファイルもstagingとproductionに分けて、それぞれにwebserversとdbserversのグループを作っているのだから、stagingとproductonで別々に適用することも可能になると。またtagをtaskにつけておけば特定のtask群だけ実行することも容易になる。。。とまぁ、とにかくいろんな手段を使って分割実行できるようにしているわけですな。</p>

<p>なのでそこまで大規模な構成管理をしないのであれば、このあたりどこまで取り入れるのは自由ではないかと。自分の場合はサーバー1台が今のところは相手ということもあり、*servers.ymlにあたるインベントリファイルは作っていないし、tagも個々のtaskに対しては設定していない。今後さらに範囲を広げるようであれば、後付で設定していけばよいかと思っている。</p>

<p>ただ、少なくともroleに関しては分けておくべきと個人的には推しておきたい。普通にアプリケーション用のコード書くときにも関数やメソッドは分割しますよね？ってことで、全体の見通しを良くする意味でもroleへの分割は必須と思う。</p>

<p>ansible、ファーストインプレッションはとにかく<a href="http://chroju.github.io/blog/2015/06/25/hika-labo-ansible/">「楽そう」</a>だったんだけど、複雑なことをやろうとすればするほどドツボにはまっていきそうな気もする。ある程度早い段階でベストプラクティスに目を通したうえで、自分が使うときにはどういったディレクトリ構成が最も有効であるかを模索した方がよい。自分も理解できるまでは少し苦労したけど、一度やり方をハメてしまうと今後長く使えそうで満足感がある。</p>

<h2>このレポジトリでやっていること</h2>

<p>ソース読んでもらえればわかる話ではありますが。</p>

<ul>
<li>common

<ul>
<li>hostname設定</li>
<li>localeとtimezone設定</li>
<li>sshd_config設定</li>
<li>authorized keys設定</li>
<li>/etc/aliasesの設定</li>
<li>DenyHostsインストール</li>
<li>logwatchインストール</li>
<li>iptables設定</li>
</ul>
</li>
<li>develop

<ul>
<li>development tools、zsh、git、vim、jqのインストール</li>
<li>dotfilesの配置</li>
<li>デフォルトシェルをzshに変更</li>
<li>rbenvの設定</li>
</ul>
</li>
</ul>


<p>もっとも苦労したのはrbenv周りで、<code>git clone</code>直後はpathが通ってない<code>~/.rbenv/bin</code>配下のコマンドをどう実行すべきかとか、それなりに悩んだ。当初インベントリファイルで<code>sudo: yes</code>としてしまっていたので、rbenv関連のタスクも全部root権限で実行されて、軒並みフォルダやファイルがrootの所有になってしまうという事故があったのだが、<code>sudo:</code>ないし<code>become:</code>の設定はタスク単位で考えたほうが良いと思う。また本来であれば<code>~/.bash_profile</code>あたりにrbenvのpath追加等の設定を書き込むところまでタスク化すべきかと思うが、自分の場合はdotfilesにすでに設定が入っているので、そのタスクは作っていない。</p>

<p>もうひとつの悩みとしては、いずれのroleもsudo権限のある開発用ユーザーでの実行を前提に考えているのだが、EC2の場合は<code>ec2_user</code>、その他VPSの場合は<code>root</code>がデフォルトのユーザーなので、デフォルトユーザーで一度入って開発用のユーザーを作るところもタスク化すべきかなと言うこと。その場合はそのroleだけ別ユーザーで実行する形になるわけで、そういった構成がそもそも可能なのか？というところからわかってないのだけど。</p>

<h2>その他技術的な話</h2>

<p>細かい技術的なtipsは後ほどQiitaに上げるつもり。現状の疑問中心に一旦取りまとめます。</p>

<ul>
<li>変数名の命名規約。代入は<code>group_vars</code>で行うことになるが、ここに一挙に集めたときにどれがどこで使われているのかわかりにくいので、roleに紐ついた名前とすべきであろうか。。</li>
<li>ntp.confの設定。templatesでいい気はするのだが、どんなサーバーでも共通の設定で問題ないのか勉強不足でわかっていない。</li>
<li>EC2には開発ツールがないので<code>Development tools</code>でまとめてインストールしてしまったが、本当は個々に切り出したい。</li>
<li>ファイルの一部上書きではなく、追記に良い方法がないものか。下手にやると何度も追記してしまって冪等性がなくなる（現状は一度grepかけて、その内容でtaskの実施要否を分岐してるが汎用性がない）。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ハッカーマインドと3冊のエッセイ]]></title>
    <link href="http://chroju.github.io/blog/2015/08/16/hackers-mind-and-their-essay/"/>
    <updated>2015-08-16T16:02:51+09:00</updated>
    <id>http://chroju.github.io/blog/2015/08/16/hackers-mind-and-their-essay</id>
    <content type="html"><![CDATA[<p>ハッカー3大エッセイとは自分が勝手に呼んでいるだけなのだが、『ハッカーと画家』『UNIXという考え方』『それが僕には楽しかったから』の3冊のことである。しかし『それがぼくには』は重要な一冊だと思うんだけど、なんでまた絶版なんですかね。そんな古い本でもないのに。仕方なく図書館で借りたけど。</p>

<p>いわゆるハッカーマインドを描いた本としていずれも似たような印象を抱きがちだが、実際に読んでみるとスタンスはだいぶ異なる。『ハッカーと画家』はコンピュータについてあまり詳しくない人に対して、ハッカーというのはこういう人種なのだと切々と説いた本であり、故にそれほど挑発的な印象は受けず、すらすらと読み進めていくことができる。もっともこれがハッカー以外に理解できるかというとかなり疑問ではあるが、ハッカーが比較的客観的に自らを解き明かした本として参考にはなる。著者のポール・グレアムのエッセイは<a href="http://practical-scheme.net/wiliki/wiliki.cgi?naoya_t:%E3%83%9D%E3%83%BC%E3%83%AB%E3%83%BB%E3%82%B0%E3%83%AC%E3%82%A2%E3%83%A0%E3%81%AE%E3%82%A8%E3%83%83%E3%82%BB%E3%82%A4%E3%81%A8%E5%92%8C%E8%A8%B3%E4%B8%80%E8%A6%A7">naoya_t氏による和訳</a>がいくらか読めるので、これを読んで興味をそそられたら読んでみるのでもいいかもしれない。あと、Lispめっちゃ推してる。</p>

<p>『UNIXという考え方』は、ハッカー向けにハッカーマインド、というかUNIX哲学を説く本なので、これは3冊の中では最も「読むべき」本だと思った。プログラムの移植性が重要であることだとか、ソフトウェアのレバレッジを効かせて効率性を最大限に高めていくべきだとか、我々がコードを書いたりシステムを作る上で重視すべきことがいくつも盛り込まれている。</p>

<p>『それがぼくには楽しかったから』はまさにエッセイ、リーナス・トーヴァルズの半生を描いたもので、ハッカーマインド云々というよりはだいぶ読み物チック。終盤で著作権やOSSといった概念に対するリーナスの考え方が少し語られるが、ほとんどはLinuxがいかにして生まれたのか？を描いた物語と言っていい。自分はリーナスというハッカーをこれまで詳しくは知らなかったのだが、案外柔軟な人物であるという印象を受けた。OSSの考え方自体は肯定しながらも、それは押し付けるべきではない、具体的に名前を挙げてリチャード・ストールマンのやり方は強引に過ぎるとしていたり、自分は聖人君子ではなく、大金が舞い込んだときには当然喜んでしまったこともあるよなんて語っていたり、彼の人間性がとても良く出ている。まぁとはいえ、自分が否とみなしたものに対しては、それなりに厳しい批判を飛ばす人物ではあると思うが。</p>

<p>こうした本に書かれた「ハッカーマインド」なるものは、我々が仕事をする上で必須のものではないと思うし、行き過ぎるとリーナスが言うような宗教戦争チックにもなりかねない。また技術に傾倒しすぎた単なるオタクが仕事の上でも重要な人物足りえるかというと、そういうわけでもない。リーナス・トーヴァルズは偉大なハッカーの1人であろうが、彼は同時にLinux開発者という立場での活動を行うにあたり、社会性を身につけたりもしてきたわけで。単にGeekであること自体が良いこととも自分は思えない。</p>

<p>とはいえ、まだ生成されてまもなく、業界標準なんてものがあるんだかないのだかもわからない、進化の速いこの業界で仕事をしていくには、多少なりともハッカー的なマインドは必要だとも思うのだ。というか、じゃないと仕事が面白くならないんでは？　惰性で同じ技術をずっと使い続けたり、効率の悪い方法を繰り返したりしていてもお金は入るのだろうけど、それが必ずしも収入に結びつかないとしても、なんかカッコイイことやってみたいとか、楽しそうな新技術にトライしてみたいだとか、そういう感覚がないとエンジニアをやっている意味がないなと思う。エンジニアが会社を選ぶにあたって重要なのは、案外このポイントなのではなかろうか。</p>

<p>残念ながら求人票からハッカーマインドは透けてこないし、転職面接の数分でそれを読み解くことも難しいだろう（自分は以前、面接でArch Linuxの話でたまたま意気投合する機会があったりして、そういう面接が出来たら話が別なのだろうけど）。その点、最近GitHubやQiitaでエンジニアたちが企業名を出して活動していることがあるが、あれは求人票やウェブサイトでは見えにくいその会社のハッカーマインドを、外部に知らしめていく良い手段だと感じる。ビジネス的に何を成して、社会をどう変えたいのかというよりも、エンジニアとしてどういったカタチで技術にコミットしていくかの方が自分には重要だ。そういう視点で仕事をしていけたらどんなにか幸せだろうし、またそれは茨の道でもあるのだろうなと思っている。</p>

<div class="amazlet-box" style="margin-bottom:0px;"><div class="amazlet-image" style="float:left;margin:0px 12px 1px 0px;"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274065979/diary081213-22/ref=nosim/" name="amazletlink" target="_blank"><img src="http://ecx.images-amazon.com/images/I/511SV9NXW2L._SL160_.jpg" alt="ハッカーと画家 コンピュータ時代の創造者たち" style="border: none;" /></a></div><div class="amazlet-info" style="line-height:120%; margin-bottom: 10px"><div class="amazlet-name" style="margin-bottom:10px;line-height:120%"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274065979/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">ハッカーと画家 コンピュータ時代の創造者たち</a><div class="amazlet-powered-date" style="font-size:80%;margin-top:5px;line-height:120%">posted with <a href="http://www.amazlet.com/" title="amazlet" target="_blank">amazlet</a> at 15.08.16</div></div><div class="amazlet-detail">ポール グレアム <br />オーム社 <br />売り上げランキング: 6,887<br /></div><div class="amazlet-sub-info" style="float: left;"><div class="amazlet-link" style="margin-top: 5px"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274065979/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Amazon.co.jpで詳細を見る</a></div></div></div><div class="amazlet-footer" style="clear: left"></div></div>




<div class="amazlet-box" style="margin-bottom:0px;"><div class="amazlet-image" style="float:left;margin:0px 12px 1px 0px;"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274064069/diary081213-22/ref=nosim/" name="amazletlink" target="_blank"><img src="http://ecx.images-amazon.com/images/I/518ME653H3L._SL160_.jpg" alt="UNIXという考え方―その設計思想と哲学" style="border: none;" /></a></div><div class="amazlet-info" style="line-height:120%; margin-bottom: 10px"><div class="amazlet-name" style="margin-bottom:10px;line-height:120%"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274064069/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">UNIXという考え方―その設計思想と哲学</a><div class="amazlet-powered-date" style="font-size:80%;margin-top:5px;line-height:120%">posted with <a href="http://www.amazlet.com/" title="amazlet" target="_blank">amazlet</a> at 15.08.16</div></div><div class="amazlet-detail">Mike Gancarz <br />オーム社 <br />売り上げランキング: 44,838<br /></div><div class="amazlet-sub-info" style="float: left;"><div class="amazlet-link" style="margin-top: 5px"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274064069/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Amazon.co.jpで詳細を見る</a></div></div></div><div class="amazlet-footer" style="clear: left"></div></div>




<div class="amazlet-box" style="margin-bottom:0px;"><div class="amazlet-image" style="float:left;margin:0px 12px 1px 0px;"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4796880011/diary081213-22/ref=nosim/" name="amazletlink" target="_blank"><img src="http://ecx.images-amazon.com/images/I/51WZM2W6ZBL._SL160_.jpg" alt="それがぼくには楽しかったから (小プロ・ブックス)" style="border: none;" /></a></div><div class="amazlet-info" style="line-height:120%; margin-bottom: 10px"><div class="amazlet-name" style="margin-bottom:10px;line-height:120%"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4796880011/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">それがぼくには楽しかったから (小プロ・ブックス)</a><div class="amazlet-powered-date" style="font-size:80%;margin-top:5px;line-height:120%">posted with <a href="http://www.amazlet.com/" title="amazlet" target="_blank">amazlet</a> at 15.08.16</div></div><div class="amazlet-detail">リーナス トーバルズ デビッド ダイヤモンド <br />小学館プロダクション <br />売り上げランキング: 71,563<br /></div><div class="amazlet-sub-info" style="float: left;"><div class="amazlet-link" style="margin-top: 5px"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4796880011/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Amazon.co.jpで詳細を見る</a></div></div></div><div class="amazlet-footer" style="clear: left"></div></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Qiitaを使うということの意義]]></title>
    <link href="http://chroju.github.io/blog/2015/08/09/qiita-commoditization-of-engineer/"/>
    <updated>2015-08-09T23:28:57+09:00</updated>
    <id>http://chroju.github.io/blog/2015/08/09/qiita-commoditization-of-engineer</id>
    <content type="html"><![CDATA[<p><a href="http://qiita.com/chroju/">Qiitaにいくつか記事を上げてみて</a>思ったことを。</p>

<h1>承認欲求が満たしやすい</h1>

<p>ブログのような個人の場ではないのに承認欲求がってのもどうなんだという話はあるが、反応を得やすい。Qiitaでは各エントリーに必ずタグを設定することになり、ユーザーは興味のあるタグを登録して新着記事をチェックするわけだが、記事が上がってくるスピードは1日に数えられる程ではあるので、上げればほぼ必ず誰かしらの目には留まる状態にある。なので自分が上げたのは基礎的な記事ばかりだという思いはあるのだが、それでもすべて漏れなくストックされていた。</p>

<p>もちろん、100ストックなどを目指すとハードルはぐっと上がってくるわけだが、こういった個人ブログで誰が見てくれているかわからない状態と比べて、記事投稿へのモチベーションは保ちやすいように感じた。なお、はてなでも同様のエコシステムは働いていて、例えばこのブログもはてな時代はそこそこブクマされていたわけだが、github.io化した後のブクマは見事にゼロである。</p>

<h1>誤り修正と議論の活性化</h1>

<p>ほぼすべての記事が誰かしらの目に触れるということで、（自分は未経験だが）コメントにより間違いの修正が入ることも多い。特に特定のタグに関してはその道の有名な方がだいぶ監視しているっぽいなぁという場合もあり、ちょこちょこコメントが付いている。</p>

<p>またコメントで長々と議論が続くのもよく見かける。単なるハウツーよりは何らかの設計思想を書いた記事に多いように思うが、派生した内容として興味深く追えることも多い。</p>

<h1>技術のコモディティ化</h1>

<p>で、ここからが本題なのだが、QiitaによってIT技術者の知識というのはある程度コモディティ化されそうだなぁと思う。</p>

<p>Qiita以前ははてななどがエンジニアのアウトプットがよくストックされる場所ではあったが、Qiitaほど体系だってまとめられていたわけではない。Qiitaでは「タグ」を追うことで、その分野の新しい話題も古い話題も、基礎も応用も知っていくことができる。逆に言えば、Qiitaに書いてあることぐらいは誰だってすぐ追って身につけられる状態にある。</p>

<p>技術書のような網羅性の高い知識パッケージとはさすがに性質を異にはするが、先に上げたコメントなどによって適宜内容が改訂され、より正しい状態に近づいていき、また必要な情報、新たな情報が次々と追加されるという意味では、動的な知識パッケージとして果たす役割は大きいのではないか。
まぁ要はブログやSNSの黎明期に言われたようなことが、Qiitaという専門性の高い1サービス内で圧縮的に再現されているというだけの話ではあるのだが、「Qiitaをやっている」というレッテルが、ある一定の知識レベルを有することと同義になる日も来そうだなという思いがする。問題点としてはQiita外と同様、やはりWeb系、OSS系の知識に内容が偏っていて、有償製品等のノウハウはそれほど多くないことだろうか。これはQiitaの問題ではないのだけど。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kaminariの実装をしてみた]]></title>
    <link href="http://chroju.github.io/blog/2015/08/08/exhibi-update/"/>
    <updated>2015-08-08T19:47:30+09:00</updated>
    <id>http://chroju.github.io/blog/2015/08/08/exhibi-update</id>
    <content type="html"><![CDATA[<p>久しぶりに稼働させている<a href="http://chroju.net/exhibi">ExhiBi</a>というサービスの機能を少し更新した。といってもそれほど大した話ではないですが、一応書き留め。</p>

<h1>kaminari</h1>

<p>ページネーションでデファクトスタンダード状態であるkaminariを使ってみました。</p>

<iframe class="bookmarklet hatena-embed" src="http://hatenablog.com/embed?url=http%3A%2F%2Fgithub.com%2Famatsuda%2Fkaminari" title="amatsuda/kaminari" style="border:none;display:block;margin:0 0 1.7rem;overflow:hidden;height:155px;width:100%;max-width:100%;"><a href="https://github.com/amatsuda/kaminari" target="_blank">amatsuda/kaminari</a></iframe>


<p>bundlerでインストールすればほぼ設定とかなくても使えます。最初のローンチのときに入れなかったので、viewを結構いじらなくちゃいけなくて大変かなーと思っていたのだけど、そんなことはなかった。主に変更は2点で、まずは<code>controller</code>で<code>#index</code>のようなリソースを拾ってくるアクションに<code>.page</code>をかましてやるようにします。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1"># もともとはExhibition.all.order...</span>
</span><span class='line'><span class="k">def</span> <span class="nf">index</span>
</span><span class='line'>  <span class="vi">@exhibitions</span> <span class="o">=</span> <span class="no">Exhibition</span><span class="o">.</span><span class="n">page</span><span class="p">(</span><span class="n">params</span><span class="o">[</span><span class="ss">:page</span><span class="o">]</span><span class="p">)</span><span class="o">.</span><span class="n">order</span><span class="p">(</span><span class="s2">&quot;start_date DESC&quot;</span><span class="p">)</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>あとは<code>view</code>でページネーションを表示するためのヘルパーを1行追加すれば終わり。以下はslimの場合。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='slim'><span class='line'><span class="p">=</span> <span class="n">paginate</span> <span class="vi">@exhibitions</span>
</span></code></pre></td></tr></table></div></figure>


<p>なお、実装当初は<code>undefined method 'deep_symbolize_keys'</code>などというちょっと関係ねーだろこれって感じのエラーが出たりして焦ったのは秘密です。原因は<code>config/locales/ja.yml</code>が一切インデントされてなかったことなんですけど、そんなのがここに波及するんですね。。。てかyamlの書き方よくわかってねーわ。</p>

<p>もちろん、1ページあたりの表示数とかページャーの表示の仕方だとか、いろいろ細かく設定はできますが、とりあえずこれだけでページャーは実装されます。あーこりゃデファクトスタンダードになるわなという簡単さ。早く入れればよかった。なお、本当にまだ入れただけなのでCSSとかぜんぜん調整してないです。</p>

<h1>id以外の要素でmodle#showにアクセスする</h1>

<p>例えばExhiBiの場合は美術館ごとのページにアクセスするには、これまでmuseums/2みたいなURLになっていたわけですが、カッコ悪いし使い勝手も悪いのでmuseums/motなど、英名でアクセスできるよう変えました。参考にしたのは以下ページ。</p>

<iframe class="bookmarklet hatena-embed" src="http://hatenablog.com/embed?url=http%3A%2F%2Fqiita.com%2Fawakia%2Fitems%2Fc2c790dc51e5b084af10" title="Railsで、URLにIDでなく名前を入力して、アクセスする方法 - Qiita" style="border:none;display:block;margin:0 0 1.7rem;overflow:hidden;height:155px;width:100%;max-width:100%;"><a href="http://qiita.com/awakia/items/c2c790dc51e5b084af10" target="_blank">Railsで、URLにIDでなく名前を入力して、アクセスする方法 - Qiita</a></iframe>


<p>やってることはなんともシンプルで、<code>Museum.find(n)</code>で呼んでいたところを<code>Museum.find_by_name_en_or_id(hoge)</code>と出来るようにしただけですね。<code>#to_param</code>でサービス内のリンクもすべて英名表記URLに変更できています。こういう柔軟さはRailsやっぱりいいですね。</p>

<p>ただ自分の場合ちょっと問題があったのは、これまでテーブルに英名表記のカラムを入れてなかったので、新たに追加する必要がありました。まぁ普通に<code>bundle exec rake g migration</code>してから<code>rake db:migrate</code>するだけなんですけど、ローカルで開発しているときに何故かこれが通らず、一旦<code>rake db:migrate:reset</code>してから改めて打つハメになったりした。このへんの話は以下記事がちょっと詳しかったり。</p>

<iframe class="bookmarklet hatena-embed" src="http://hatenablog.com/embed?url=http%3A%2F%2Feasyramble.com%2Fdifference-bettween-rake-db-migrate-reset.html" title="rake db:reset と rake db:migrate:reset の違い | EasyRamble" style="border:none;display:block;margin:0 0 1.7rem;overflow:hidden;height:155px;width:100%;max-width:100%;"><a href="http://easyramble.com/difference-bettween-rake-db-migrate-reset.html" target="_blank">rake db:reset と rake db:migrate:reset の違い | EasyRamble</a></iframe>


<p>自分はインフラエンジニアなので、Railsを実務で使うってことはほとんどこの先皆無だとは思うんですけど、自己表現手段としてやっぱりRailsぐらい使えておくと良さそうだなと改めて思います。例えばインフラの勉強でサーバー運用してみようとなっても、上で何か動いてないとあんまり勉強にならなかったり。自分がどんなことをしているのか？を外にアッピルする意味では、こういうの1つぐらい持っとくといいのだろうなと思います。yamlの勉強しなきゃとか、今回そういう派生効果もありましたので。近々作れたらもう1個サービス作ってみようと思ってます。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Qiitaはじめました]]></title>
    <link href="http://chroju.github.io/blog/2015/07/25/start-qiita/"/>
    <updated>2015-07-25T11:07:38+09:00</updated>
    <id>http://chroju.github.io/blog/2015/07/25/start-qiita</id>
    <content type="html"><![CDATA[<iframe class="bookmarklet hatena-embed" src="http://hatenablog.com/embed?url=http%3A%2F%2Fqiita.com%2Fchroju" title="chroju - Qiita" style="border:none;display:block;margin:0 0 1.7rem;overflow:hidden;height:155px;width:100%;max-width:100%;"><a href="http://qiita.com/chroju" target="_blank">chroju - Qiita</a></iframe>


<p>気分でQiitaはじめてみた。Kobitoをちらちら使って簡単なメモを残していたりしたのだけど、そこから一発で上げられるのはやっぱ楽かなと思って。あと先日の<a href="http://chroju.github.io/blog/2015/07/20/encryption-hash-at-first/">暗号化に関する記事</a>みたいなまとめ記事、tips系はやはりQiitaの方がフットワーク軽くて使いやすいような気がする。更新した場合にも履歴が残るし。</p>

<p>ブログとの使い分けが難しそうな気はするが、いわゆる勉強メモみたいな頻繁に見返すものをQiitaに上げて、ブログの方はもっとガッチリとした長文、たとえば勉強会の記録だとか技術に対する考え、あるいは何かを作った系の記事などを上げたらいいのではと思っている。まぁこのへんはあまり縛られず、あくまで中心に据えているのは自分用メモとしての役割なので、自分が使いやすいようなやり方でやれればいいかなと思っている。</p>

<p>ブログは多くとも週2回程度の更新だったが、Qiitaはもっと高い頻度でいろいろ貯めこんでいきたいし、そうできるような仕事をしていきたい所存。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[暗号化とハッシュ化に関する基本的な事柄まとめ]]></title>
    <link href="http://chroju.github.io/blog/2015/07/20/encryption-hash-at-first/"/>
    <updated>2015-07-20T16:56:06+09:00</updated>
    <id>http://chroju.github.io/blog/2015/07/20/encryption-hash-at-first</id>
    <content type="html"><![CDATA[<p>セキュリティスペシャリスト持ってるはずなのに曖昧な理解で誤魔化してたので自分用まとめ。また書き足すかも。なんか書き足し書き足ししていくようなノートの整理には、編集履歴が見られるQiitaの方が便利なのかなとか思うけど。</p>

<ul>
<li>暗号化とハッシュ化は違う。暗号化はデータの秘匿を目的としており、適切な鍵を用いることで復号が可能。ハッシュ化はデータの置換がそもそもの目的であり、ハッシュ関数により一定のフォーマットへ不可逆の変換を行う。</li>
<li>ただし、衝突耐性を持つことなどにより、セキュリティ用途に適する「暗号学的ハッシュ関数」というものもあるらしい。デジタル署名やメッセージ認証符号への使用を目的とされており、逆にチェックサム等に使用するには計算が「重い」。</li>
</ul>


<h1>暗号</h1>

<p>主なアルゴリズムをざっと。</p>

<h2>RSA</h2>

<ul>
<li>公開鍵暗号。素因数分解の計算難度を根拠としたもの。サマウォで解いてたアレもたぶん素因数分解暗号だが、暗算で解かれたらたまったものではない。</li>
<li>SSHログイン時の鍵認証やSSL認証など、広く使われる。</li>
<li>秘密鍵生成コマンドとして<code>openssl genrsa</code>がある。SSH鍵認証では<code>ssh-keygen</code>を用いる。</li>
</ul>


<h2>DES</h2>

<ul>
<li>共通鍵暗号。鍵長54bitのブロック暗号。</li>
<li>鍵長が短すぎるため、現在では安全ではないとされるが、暗号化復号化処理を3回実行するトリプルDESという形で主に実用されている。</li>
<li><code>openssl genrsa</code>での秘密鍵生成時に、パスフレーズによるトリプルDESでの暗号化を施すため、<code>-des3</code>オプションが用いられる。</li>
</ul>


<h2>AES</h2>

<ul>
<li>共通鍵暗号。DESの安全性低下に伴い開発された、鍵長128bit超のブロック暗号。</li>
</ul>


<h1>ハッシュ</h1>

<h2>ソルト</h2>

<p>ハッシュ化前に対象文字列に付加するランダムな文字列。同一文字列のハッシュ化時に衝突が防げる、レインボーテーブルによる探索に対する妨害になる、といった利点がある。</p>

<h2>フィンガープリント</h2>

<p>SSH初回ログインで表示されるやつ。公開鍵のハッシュ値。<code>~/.ssh/known_hosts</code>に記述され、次回以降のログインで公開鍵の変更有無の確認に使われる。変更があると、サーバーなりすましの危険性もあるため警告が表示される。<code>ssh-keygen -lf</code>でも表示可能。</p>

<h2>md5</h2>

<ul>
<li>出力128bitのハッシュアルゴリズム。ファイル配布時のチェックサムなどに用いられる。</li>
<li>安全性は高くないことが判明しているため、日米ともにSHAの使用が推奨されている。</li>
<li>コマンドは<code>md5sum</code>あるいは<code>openssl md5</code>を使用する。</li>
<li>なおパスワードハッシュ化でよく用いられる<code>openssl passwd</code>はmd5による実装。</li>
</ul>


<h2>sha</h2>

<ul>
<li>Secure Hash Algorithm。暗号学的ハッシュ関数の一つ。</li>
<li>SSL、SSH等で用いられる暗号化アルゴリズム。</li>
<li>SHA-0,1,2,3が存在しており、SHA-1には脆弱性が存在するため、SSL証明書はSHA-2への全面移行が進められている。すでにGoogle ChromeではSHA-1による証明書に対して警告が表示される。</li>
<li>SHA-2は鍵長によりSHA-224、SHA-256、SHA-384、SHA-512といったバリエーションが存在する。</li>
<li>上述の通り<code>openssl passwd</code>はSHA非対応だが、<code>grub-crypt</code>がSHA-2によるハッシュ化に使える模様。
参考: <a href="http://heroween.hateblo.jp/entry/2014/07/28/133713">CentOS6.5でランダムSalt付きSHA-512のシャドウパスワードを生成する - ひろうぃんの雑記</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AnsibleとDigitalOceanでどこでも使える開発環境を作る]]></title>
    <link href="http://chroju.github.io/blog/2015/07/20/ansible-digitalocean-vps-dev-env/"/>
    <updated>2015-07-20T14:50:28+09:00</updated>
    <id>http://chroju.github.io/blog/2015/07/20/ansible-digitalocean-vps-dev-env</id>
    <content type="html"><![CDATA[<p>個人開発環境としては自宅にiMac 2010Mid、モバイルでVAIO Pro 11に入れたArch Linuxを使っているのだが、メインとしてはiMacの方を利用していて、デプロイしたりなんだりは自宅からしか出来ない状態にある。じゃあVAIOに移せばいいやんとも思うのだが、こちらも会社PC（なぜかこちらもVAIO Pro 11）と二重になってしまうので始終持ち歩きたくはなく、平日フラフラしてるときにサッとbash入りたいなみたいのが出来ずにいた。</p>

<p>結論としてVPSを開発環境として扱い、最悪iPad miniからいつでもSSH接続してbash叩けるだけでも幸せかなというところに至った。これまで<a href="http://chroju.net">http://chroju.net</a>をさくらVPSで運営していたので、特に考えずさくらをもう1台追加したりもしたのだが、ちょっと調べてみると<a href="https://www.digitalocean.com/">DigitalOcean</a>が最近流行りつつあるようだったので、他社サービスも使ってみると面白そうだってことで新規契約してみた。</p>

<h2>DigitalOcean</h2>

<p>すでに他所で言われてはいるが、利点としてはこんなところかと思う。</p>

<ul>
<li>月額課金ではなく時間課金なので、使いたいだけ払えばOK</li>
<li>安い</li>
<li>アプリケーションやSSH鍵が最初から組み込まれたイメージを作れる</li>
<li>REST APIでだいたいのVPS操作ができる</li>
</ul>


<p>要するに使いたいときに使いたい環境をバチコンと作れちゃうというのが一番のメリットなので、今回のような永続的に使う開発環境より、一時的なテストなんかに使った方が良いのだと思う。とはいえ時間課金上限が月あたりで定められており、現状最安プランだと月5ドルが上限になっていたりもするので、永続的にマシンを上げておく分にも安いのは確か。なお、課金はイメージを作った時点で開始されるので、不要なマシンはhaltではなくdestroyしておく必要がある。まぁ無料のスナップショット機能もあるから、リカバリできると思えばdestroyしてしまうこともそこまで難しくはないかなと。</p>

<p>REST API提供ということで、CLIから落としたり上げたり壊したりなんだりも全部できるのだが、だったらひょっとして誰かがアプリとか作ってんじゃねーかなと思ったら、やっぱりすでにあった。</p>

<div class="bookmarklet bookmarklet-gp" itemscope itemtype="http://schema.org/MobileApplication" style="clear:both;min-height:165px;width:100%;max-width:468px;overflow:hidden;padding:12px;border:1px solid;border-color:#eaeaea #ddd #d0d0d0;-moz-box-sizing:border-box;box-sizing:border-box;border-radius:5px;"><dl class="bookmarklet-gp-info" style="margin:0;"><dt class="bookmarklet-gp-title" style="border-bottom:1px solid;border-color:#eaeaea #ddd #d0d0d0;font-weight:bold;margin:0 0 .5em 0;padding:0 0 .5em 0;"><img alt="Google play" class="favicon" style="vertical-align:middle;border:0;" src="//ssl.gstatic.com/android/market_images/web/favicon.ico" /> <span itemprop="name">DigitalOcean Swimmer Android</span></dt><dd class="bookmarklet-gp-desc" style="font-size:.9em;margin:0;"><div class="bookmarklet-gp-thumb" style="float:left;"><img src="https://lh3.ggpht.com/HXBZyHdspPh5MFgaC-rOXAZIZc8D9uM4KrQsL-gqoB1_9ZuBhthaWYLRoYJYNUY9Ytg=w300" alt="DigitalOcean Swimmer Android" itemprop="image" style="height:120px;width:120px;max-width:100%;vertical-align:middle;border:0;margin:0 1em 0 0;"></div><div class="supplier" itemscope itemtype="http://schema.org/Organization">制作: <span itemprop="name">Hannoun Yassir</span></div><div class="review" itemtype="http://schema.org/AggregateRating" itemscope itemprop="aggregateRating">評価: <span itemprop="ratingValue">4.4</span> / 5段階中</div><div class="price" itemtype="http://schema.org/Offer" itemscope itemprop="offers">価格: <meta itemprop="price" content="0">無料<small> (2015/7/11 時点)</small><br /></div><a href="https://play.google.com/store/apps/details?id=com.yassirh.digitalocean&hl=ja" target="_blank" title="DigitalOcean Swimmer Android" itemprop="url" style="float:right;"><img src="//dl.dropboxusercontent.com/u/540358/ja_generic_rgb_wo_45.png" alt="ダウンロード" style="border:0;display:inline-block;height:auto;vertical-align: middle;"/></a><small>posted by: <a target="_blank" href="http://hayashikejinan.com/?p=818">AndroidHTML v3.1</a></small></dd></dl></div>


<p>このアプリさえあればGUI操作はほぼ全部できる。</p>

<p>ちなみにこんなことでハマる人はほとんどいないだろうと思うが、自分がハマったポイントとして<code>authorized_keys</code>の件がある。Digital OceanではあらかじめWeb GUIで公開鍵を上げておき、VPSをcreateするときに最初から任意の鍵を入れておくことができるのだが、当初は<code>root</code>以外のユーザーがいないため、当然ながら<code>authorized_keys</code>のパスも<code>/root/.ssh/</code>配下となる。構築用には別のユーザーを設けることになると思うが、その際には<code>authorized_keys</code>を<code>/home/user</code>配下へ持ってきて、アクセス権の適切な設定などもしなくてはssh接続できないので注意。</p>

<h2>Ansibleによる初期構築</h2>

<p>巷ではVagrantと連携して、<code>vagrant up</code>でDigitalOceanにマシンを上げるのが流行ってるらしい。</p>

<ul>
<li><a href="http://qiita.com/msykiino/items/d45cab7f520a3288862a">vagrantではじめるクラウド開発環境（DigitalOcean編） - Qiita</a></li>
<li><a href="http://blog.glidenote.com/blog/2013/12/05/digital-ocean-with-vagrant/">VagrantとSSDなVPS(Digital Ocean)で1時間1円の使い捨て高速サーバ環境を構築する - Glide Note - グライドノート</a></li>
</ul>


<p>とはいえ自分は冒頭に書いた通り、最悪iPad miniでもいいので外から繋ぐという運用をしたかったので、Vagrantからの起動は使えない。なので初期構築には最近学び始めたAnsibleを使ってみた。</p>

<p>インフラ管理系のツール、使ったことがあるのはChefぐらいで、Puppetは概念だけ知ってはいるが、Ansibleの特色はやはりハードルの低さ、学習コストの低さだと思う。エージェントレス、<code>knife</code>のような特殊なコマンドもほとんど覚える必要がなく、<code>ansible-playbook</code>コマンドさえ覚えておけばとりあえずなんとかなってしまう。</p>

<ul>
<li>エージェントレスなのでpipで手元のマシンにansibleを入れればすぐ使える。</li>
<li>設定はyamlによるplaybookに書き出すので、文法も比較的容易。</li>
<li>1個1個のタスクは定められたモジュールを用いて書くことになるが、やりたいことを公式Docsの<a href="http://docs.ansible.com/modules_by_category.html">Module Index</a>で探ればわりとなんとかなる。</li>
<li>ディレクトリ掘ったり<code>knife</code>みたいなコマンドいっぱい覚えなくても、とりあえずyaml1つとコマンド1つあれば始められる。</li>
</ul>


<p>pip経由でのインストールが必要なので非pythonista的には若干戸惑いもありましたが、学習コストの低さはハンパないのでインストールから1時間もあれば一旦サーバー建てられました。ノウハウもQiitaはじめ随所に落ちてはいるけれど、正直公式ドキュメントがかなり充実していて、<a href="http://docs.ansible.com/YAMLSyntax.html">YAMLのシンタックスガイド</a>まで付いていたりするので、下手にググってやるよりもドキュメントちゃんと読んだ方がいいと思う。まぁ、Ansibleにかぎらずなんだってそうではあるが。ただ、複数台管理だとかアプリのデプロイだとかをやろうとすると当然ディレクトリ構成も複雑になって、既存のプラクティスが必要になってくるので、あくまで「導入の学習コストが低い」という感じだが。</p>

<p>書いたPlaybookはとりあえずGitHubに上げた。<a href="http://akiyoko.hatenablog.jp/entry/2013/12/16/020529">こちら</a>を参考に、いわゆるVPS作るときの初期設定だけまとめている。ただしわりと俺用（dotfiles引っ張ってきたりとか）。Ansibleについてはまた別の記事でまとめようと思う。</p>

<p><a href="https://github.com/chroju/ansible">chroju/ansible</a></p>

<h2>iPadからのSSH接続</h2>

<p>クライアントソフトがいろいろあるのは知っていたが、ここまでのレベルと思わんかったなーというのが<a href="https://panic.com/jp/prompt/">Prompt2</a>。</p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/chroju/19822940536" title="prompt_with_digitalocean"><img src="https://farm1.staticflickr.com/541/19822940536_5f6201ca53_z.jpg" width="640" height="480" alt="prompt_with_digitalocean"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>vim-lightlineもきちんと表示してくれるし日本語も可だし、外付けキーボードの煩わしささえ考慮しなければかなり快適である。当然ながら鍵認証も使えるし、ぶっちゃけWindowsのラップトップ持ち歩くぐらいならこっちの方がSSHはストレスないんじゃないかというぐらい。つないでちょこちょこっと使えればいいかなぐらいの思いだったが、嬉しい誤算だった。さすがに有料ではあるけど。</p>

<p>おかげさまで場所を選ばず開発環境につながるようになったので、ちょっと試したいツールがTLに上がってきたりしたらおもむろにiPadを取り出して試したりとかできる。すぐ復元したいのであれば、先のAndroidアプリで予めスナップショットを取ったりもできるし、楽すぎて笑える。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Windows開発環境を整える話と、メモアプリとして最強であるwasaviの話]]></title>
    <link href="http://chroju.github.io/blog/2015/07/04/development-environment-for-windows/"/>
    <updated>2015-07-04T20:24:32+09:00</updated>
    <id>http://chroju.github.io/blog/2015/07/04/development-environment-for-windows</id>
    <content type="html"><![CDATA[<p>職場のWindows PC、いろいろと開発用に整備を進めてはいるが、やはりWindowsだとツラミある。</p>

<h2>Chocolatey</h2>

<p>Windowsでのパッケージ管理。不可欠かというとそうでもないとは思うのだが、アップデート含め一括管理が可能なので、精神衛生上良さそうだという意味で使ってみている。どうでもいいが名前がかわいい。</p>

<p>インストール自体はPowershellからワンライナーを叩くだけなので難しくはないのだが、よくわからないエラーで止まることが多くて、現状使い切れてない。Proxyの設定はしたし、powershellの権限も<code>RemoteSigned</code>にしたのだけど、何がいけないのか。。。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> Unable to index into an object of type System.IO.FileInfo.
</span><span class='line'> 発生場所 C:\ProgramData\chocolatey\helpers\functions\Write-ChocolateyFailure.ps
</span><span class='line'> 1:24 文字:8
</span><span class='line'> +   throw &lt;&lt;&lt;&lt;  "$failureMessage"
</span><span class='line'>     + CategoryInfo          : OperationStopped: (Unable to index...em.IO.FileI
</span><span class='line'>    nfo.:String) []、RuntimeException
</span><span class='line'>     + FullyQualifiedErrorId : Unable to index into an object of type System.IO
</span><span class='line'>    .FileInfo.
</span><span class='line'>The install of clover was NOT successful.
</span><span class='line'>Error while running 'C:\ProgramData\chocolatey\lib\Clover\tools\chocolateyInstall.ps1'.
</span><span class='line'> See log for details.</span></code></pre></td></tr></table></div></figure>


<h3>参考</h3>

<p><a href="http://qiita.com/himinato/items/11f4dc9a23afebbc242c">windowsの開発環境は一瞬で整うwith chocolatey - Qiita</a></p>

<h2>コンソール</h2>

<p>cmdだと貧弱貧弱ゥ！なので、とか、bashコマンド試し打ちしたい場合が多いとか、そういう理由でコンソールは入れ直す。</p>

<p>Gitを入れると自動的にGit bashが入るので、コマンド環境としてはこれを使っている。ターミナルアプリは最近ちょっと話題になっていたのでConEmuを入れてみた。もちろんChocolateyで。</p>

<ul>
<li>Font charsetを「Shiftjis」に設定</li>
<li>フォントは<a href="http://github.com/yascentur/RictyDiminished">Ricty Diminished</a>を利用</li>
<li>lsで日本語が化けるので<code>~/.bashrc</code>に<code>alias ls='ls --show-control-chars --colors'</code>を設定</li>
</ul>


<h3>参考</h3>

<p><a href="http://astra.digi2.jp/a/e/setup-conemu-as-japanese-cmd.html">ConEmuの初期設定(日本語表示環境を構築) - Diary on wind @astra.dat</a>
<a href="http://qiita.com/ironsand/items/ec0675644a55a69855d6">Ruby - 【無理】WindowsのコンソールでUnicodeを使いたい - Qiita</a></p>

<p>Windowsで開発する場合の最大のネックは、CLIの貧弱さ以上にcp932にあると思うの。</p>

<h2>AutoHotkey</h2>

<p>キーバインド変えたいことが多いので愛用。とりあえず<code>&lt;ESC&gt;</code>と間違えて隣の<code>F1</code>押してヘルプ出てしまうことが多いので、<code>F1</code>は潰している。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='autohotkey'><span class='line'><span class="nl">F1::</span><span class="n">Return</span>
</span></code></pre></td></tr></table></div></figure>


<p>あとOutlookの使い勝手があまり好きではないので、配布されていたGmailライクなキーバインドを実現する設定を使わせていただいている。しかしOutlook2013、差出人名の表示がやたらでかかったり、フォルダのツリー表示が文字だけ（アイコンとかツリーを表す罫線がない）になっていて見づらかったり、UI面で難がありすぎる。。。</p>

<h3>参考</h3>

<p><a href="http://www.autohotkey.com/board/topic/102227-gmailkeys-for-outlook-2013/">GmailKeys for Outlook 2013 - Scripts and Functions - AutoHotkey Community</a></p>

<h2>メモアプリ</h2>

<p>技術的なことをやってるとどうしてもメモを取る必要性が出てくるのだが、いろんなところに書き散らしていると後から見返せないのでそれなりの整理はしておきたいと常々思う。</p>

<p>元々は自宅だとDropbox + QFixHowm(Vim)、会社だと（あまり技術的な話が多くなかったので＆クラウド系アプリは使えなかったので）別個の環境で同様にQFixHowmを使っていたのだが、比較的技術的なノウハウをとりためることも増えたので、可能なら自宅からも参照できるメモ環境を会社でも作りたいなと思い直している。</p>

<p>個人的に理想としているのはこんな感じ。</p>

<ul>
<li>クラウド同期が取れる、可能ならDropboxがいい</li>
<li>全文検索ができる</li>
<li>（可能なら）vimキーバインドが使える</li>
<li>（可能なら）Markdownプレビューができる</li>
</ul>


<p>いろいろ検証はしてみたが、どれもしっくり来ていない。なんかないものか。</p>

<h3>Kobito</h3>

<ul>
<li>Markdownエディタとしては優秀。ハイライトも綺麗。</li>
<li>vimモードがあってそこそこ快適。若干表示がズレることがあるが、設定いじれば修正は可能かも。</li>
<li>クラウド同期はできない。あとファイル実体見れないのがなんとなく気持ち悪い。</li>
</ul>


<h3>Evernote</h3>

<ul>
<li>Markdownエディタとしては論外。</li>
<li>アカウントは持っているが、すでにプライベートメモがどっさり入ってるので会社で開きにくい。</li>
</ul>


<h3>GistBox</h3>

<ul>
<li>Markdownエディタではないし、フォーム入力なので編集は貧弱。</li>
<li>GitHub経由で同期取れる点は魅力。</li>
<li>Gistはスニペット置き場のイメージが強く、文章の保存はしっくりこない。</li>
</ul>


<h3>Wri.pe</h3>

<ul>
<li>今のところ最良と思われる。</li>
<li>フォーム入力型の編集にはなってしまうが、<a href="https://github.com/akahuku/wasavi">Wasavi</a>使うことでVimっぽくできる。</li>
<li>ログインすれば自宅からでもメモは見られるので一応同期可能。</li>
<li>Dropbox連携はあるが、あくまでバックアップをzipでストックさせるだけなので、家ではVimで編集します、とかはスムーズにできなくて微妙。</li>
</ul>


<h3>Cirrus Editor</h3>

<ul>
<li>Dropbox内のtxtファイルをブラウザで直接編集できるのは今のところこれぐらいしか見つからない。</li>
<li>新規ファイルの追加ができないので、メモ環境としては使えない。</li>
</ul>


<p>ひとまずWri.pe使ってますけどだいぶ辛さあります。今日日はやっぱりKobito使ってるエンジニアが多いんだろうか。あるいはメモなんていらない？ うーん。。。</p>

<p><strong>……と思ってたらWasaviがDropbox連携機能もってた！！！</strong></p>

<iframe class="bookmarklet hatena-embed" src="http://hatenablog.com/embed?url=http%3A%2F%2Fappsweets.net%2Fwasavi%2F" title="wasavi - appsweets akahuku labs." style="border:none;display:block;margin:0 0 1.7rem;overflow:hidden;height:155px;width:100%;max-width:100%;"><a href="http://appsweets.net/wasavi/" target="_blank">wasavi - appsweets akahuku labs.</a></iframe>


<ul>
<li>連携すると<code>:write</code>や<code>:edit</code>がWasavi上で使えるようになる。

<ul>
<li>つまりWri.peをWasaviで編集していて、Dropboxにツッコみたくなったら<code>:write hoge.txt</code>すればよい。</li>
<li>逆にDropboxのテキストをWri.peに持ってきたければ<code>:edit fuga.txt</code>とすればよい。</li>
</ul>
</li>
<li>さらに<code>http://qasavi.appsweets.net</code>につなぐと単独でWasaviをブラウザエディタとして使える。Dropboxのオンラインエディタになる。</li>
</ul>


<p>ヤバイだろうこれ。。。highlightはさすがに無理とか、Dropbox使えると言っても<code>ls</code>は使えないのでファイラとしては微妙とか、そういうのはもろもろあるとは言え、Dropboxのファイルを直接ブラウザ上でVimライクな編集できるってのは恐ろしく便利。単なるVimのエミュレートに留まらず、ブラウザとDropboxのシームレスな連携ができるという点が肝だと思う。Dropboxで書きためていたブログの下書きを、はてなブログの編集画面上で直接呼び出すこともできるわけだ。ちなみにGoogle DriveとOne Note連携もあるので、そちらがお好みであればそちらでも。</p>

<p>これまでぜんぜん見たこともないソフトだったけど、これだいぶいいものなのでは？？？</p>

<h2>その他アプリケーション</h2>

<ul>
<li><a href="http://www.forest.impress.co.jp/library/software/clover/">Clover</a> エクスプローラーのタブ化</li>
<li>chrome全盛になりつつある気はするが、Vimp使いたくてFirefox</li>
<li>VirtualBoxにVagrantはもはや定番</li>
<li>Outlookの予定表使いづらすぎて辛いんだけど、Exchangeと同期できるアプリでなんか良い代替ないッスか。。。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[すべての障害対応を、生まれる前に消し去りたい！ #障害対応きにならNight]]></title>
    <link href="http://chroju.github.io/blog/2015/07/03/how-about-your-troubleshooting/"/>
    <updated>2015-07-03T00:20:52+09:00</updated>
    <id>http://chroju.github.io/blog/2015/07/03/how-about-your-troubleshooting</id>
    <content type="html"><![CDATA[<p><a href="http://www.zusaar.com/event/6147005">エンジニア交流会〜他社の障害対応きにならNight!〜 on Zusaar</a></p>

<p>改めて見るとすげー名前のイベント……行ってきた。</p>

<p>障害対応は嫌いです。ていうか好きな人がいるならお目にかかってみたいもんですが、しかしシステムを動かす以上障害は避けられないし、それならばなるべく負担を軽減したいというのが人の、いやエンジニアの性。つわけでよりよいソリューションを探す目的で行ってきたイベントだったんですが、結局のところ <strong>より深い闇を知るだけの結果に終わった。</strong></p>

<p>世の中闇だらけですわ。闇しかないですわ。自分なんかぜんぜん甘いなっていうか闇とすら呼べないんじゃないかっていう。詳しくは書けませんけど世の中運用者って苦労してんなって認識新たにしました。まぁだからって闇を甘受していいわけじゃなくて、だからこそやることあるんだけどさ。</p>

<p>得た知見をザクっとまとめちゃいますけど、</p>

<ul>
<li>明文化と記録は何事も大事。顧客との契約にせよ、手順や構成にせよ、障害記録にせよ。</li>
<li>ただ記録するんじゃなくて探しやすいようにとか考えないと意味ない(Wikiに書き散らしても役には立たない)</li>
<li>日頃からの点検などによる障害の抑止も重要。障害訓練とか。</li>
<li>スーパーエンジニアだから治せるって状態は脱したいのでスキルの底上げは必要。</li>
<li>電話かかってくるのウザいけど必要。確実に対応しなきゃならない障害なら絶対電話。別にTwilioとかでいいので。</li>
</ul>


<p>障害対応って辛くないはずはないのだが、だったらより辛くない方法を探さねばなと思う。アラートの対象は極力絞ったり、自動復旧でイケる事象はスクリプト組んでおいたり。</p>

<p>あと自分はもともと金融系SEで、運用に用いてたのもJP1やTivoliみたいな商用製品が多かった故、会場で交聞いたnagiosやらcactiやらCloudWatchやらを学ばねばというところ。顧客とビジネスモデルが変わっただけで、見える技術領域もほんとに変わるものだと思う。</p>

<p>こういうopsやインフラに絞ったイベント、なかなかない気がするので良いですね。</p>
]]></content>
  </entry>
  
</feed>
