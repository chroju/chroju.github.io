<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[the world as code]]></title>
  <link href="http://chroju.github.io//atom.xml" rel="self"/>
  <link href="http://chroju.github.io//"/>
  <updated>2015-12-14T22:16:31+09:00</updated>
  <id>http://chroju.github.io//</id>
  <author>
    <name><![CDATA[chroju]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[『Team Geek』読了]]></title>
    <link href="http://chroju.github.io//blog/2015/12/14/review-team-geek/"/>
    <updated>2015-12-14T22:14:29+09:00</updated>
    <id>http://chroju.github.io//blog/2015/12/14/review-team-geek</id>
    <content type="html"><![CDATA[<div class="amazlet-box" style="margin-bottom:0px;"><div class="amazlet-image" style="float:left;margin:0px 12px 1px 0px;"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873116309/diary081213-22/ref=nosim/" name="amazletlink" target="_blank"><img src="http://ecx.images-amazon.com/images/I/41SlY0zvpKL._SL160_.jpg" alt="Team Geek ―Googleのギークたちはいかにしてチームを作るのか" style="border: none;" /></a></div><div class="amazlet-info" style="line-height:120%; margin-bottom: 10px"><div class="amazlet-name" style="margin-bottom:10px;line-height:120%"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873116309/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Team Geek ―Googleのギークたちはいかにしてチームを作るのか</a><div class="amazlet-powered-date" style="font-size:80%;margin-top:5px;line-height:120%">posted with <a href="http://www.amazlet.com/" title="amazlet" target="_blank">amazlet</a> at 15.12.14</div></div><div class="amazlet-detail">Brian W. Fitzpatrick Ben Collins-Sussman <br />オライリージャパン <br />売り上げランキング: 18,890<br /></div><div class="amazlet-sub-info" style="float: left;"><div class="amazlet-link" style="margin-top: 5px"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873116309/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Amazon.co.jpで詳細を見る</a></div></div></div><div class="amazlet-footer" style="clear: left"></div></div>


<p>ひたすら技術ドリブンに仕事できるのであればそれはそれで良いような気はするが、現実にはちゃんとコミュニケーション取る必要はあって、何かやりたいことがあればいわゆる政治的な課題に悩まされることになったりもする。本を読むときはつい技術系のものや個人のハッカーマインドに関するものを読みがちだけど、歳も歳だし組織論もかじろうかということで読んだ。元々読むつもりはあったが、紀伊國屋書店新宿本店でオライリーカレンダーのプレゼントやってたので背中押された。</p>

<p>とても元も子もないまとめ方をしてしまうと、<a href="http://blog.glidenote.com/blog/2015/08/17/move-to-akamai/">KAIZEN Platform, Inc. のエンジニア行動指針</a>がだいぶ本書に影響を受けたと思われるものになっていて、これに全社員がコミットできている状態というのは理想的なのだろうなと思ったりした。本書の内容にはとても賛同できるのだが、「組織論」である以上は自分だけが納得していても仕方なくて、社内でこの内容を文化として定着させなくてはならない。そこのハードルがなかなかに高い。</p>

<p>本書でもそのあたりの話には「組織的操作の技法」として第5章をまるまる当てて触れられていて、例えば「道がないなら道を作る」＝草の根からツールの導入などを始めていく、「許可を求めるより寛容を求めるほうが簡単」、「安全なポジションまで昇進する」といったことが書かれている。結局はできることからやっていく、しかなくなってしまうのかもしれない。</p>

<p>個人のマインドに関する話は大変参考になって、HRT（謙虚、尊敬、信頼）を軸として、「コードの価値を自分の価値と同一視するな」というあたりもだいぶクるものがあった。技術職としては技術的価値の優劣が極めて大きな価値をもっていて、ともすれば「モヒカン」だとか「マサカリ」といった言葉が表すような事態になりかねないのだが、チームが円滑に動くためにはそういったものは障壁となりかねない。技術的に未熟であるメンバーについても、謙虚に対応していくべきだし、また自分の技術は粛々と磨いていくことが必要なんだろうなと。</p>

<p>こういう本は一人で読んでもやっぱり仕方がないところがあるので、チームで買ってシェアしたりもアリかもしれません。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dockerファーストインプレッション]]></title>
    <link href="http://chroju.github.io//blog/2015/12/04/docker-first-impression/"/>
    <updated>2015-12-04T20:48:49+09:00</updated>
    <id>http://chroju.github.io//blog/2015/12/04/docker-first-impression</id>
    <content type="html"><![CDATA[<p>前回上げたインフラCIを試みた際、CircleCIを利用する中で初めてDockerに触れたので、今更ながらのファーストインプレッション。</p>

<h2>「仮想マシン」と考えるとDockerは理解しづらい</h2>

<p>Dockerを「仮想マシン」と称する文章も随所で見かけていたが、これを仮想マシンとして捉えると理解からは遠のく。自分自身、Dockerの概念的な理解にはかなり手こずっていて、OSがないのにどうやって「マシン」が動くのかわからなかったし、 <code>chroot</code> のようにファイルシステム上に仮想的なディレクトリツリーを設けるものなのかと思っていた。</p>

<p>Dockerは隔絶された名前空間上で展開されるプロセスに過ぎない。確かにコンテナはOSのような振る舞いを見せるが、そこにいわゆるVMwareやXenのような仮想「マシン」はない。あくまでホストOSの一部リソースを切り出して、仮想的に扱う技術に過ぎない。</p>

<h2>Vagrantの代替？</h2>

<p>一度理解して、 <code>docker run</code> を叩けるようになると利便性は即座に理解できる。OSをブートさせるわけではないのでコンテナの起動は従来の「仮想マシン」と比べて格段に速く、CircleCIで使われている用途同様、テスト用にまっさらな環境が即席で欲しいときには大変重宝する。こういう用途にはもともとVagrantが適していたのだと思うが、本当にすぐ使い捨ててしまいたいようなOS環境であれば、Dockerを使ったほうが遥かに手軽に起動も破棄もこなせる。</p>

<p>ただあまりに簡単に起動、破棄ができるものの、作成したコンテナのイメージはコンテナ終了後も基本的に残存するので、調子に乗っているうちにいつの間にかディスクがかなり消費されていることが何度かあった。コンテナライフサイクルの把握と運用整備はマスト。</p>

<h2>ポータブルなインフラストラクチャー</h2>

<p>Dockerを実用できる一例として、先日Traildashを採用する機会があった。</p>

<p><a href="https://github.com/AppliedTrust/traildash">AppliedTrust/traildash</a></p>

<p>CloudTrailという、AWS APIへのアクセスログをjsonで吐いてくれるAWSサービスがあるのだが、それをElasticsearchで集計してKibanaでブラウザ表示してくれるツール。このツールはDockerイメージで配布されていて、自分のサーバー上にpullしてきて、AWS APIへアクセスするための環境変数をいくつか設定するだけで使えるようになる。自分はElasticsearchの運用経験はないのだが、実質的に <code>docker run</code> コマンド一発だけでそれが使えてしまう。（そのことの是非は置いておくとして）Dockerがアプリケーションサイドで実現することってこういうことなんだろうと。herokuが出たとき、ローカルからインターネットへのサービスのポータビリティが劇的に向上したわけだが、Dockerは稼働先を問わないわけで、ポータビリティはさらに拡大する。</p>

<p>これはインフラ側としても嬉しいところで、今までnginxやらDBやらというミドル的な部分はアプリとしての要求もあり、インフラとしての要求もあり、双方の要件がガッシリ絡んでしまっていて、設定を後から見返すと「これなにゆえにこうなったんだっけ？」ってことが少なくなかったり、構築分担が面倒だったりというのがあって。コンテナとしてアプリをデプロイするとなると、サーバーとコンテナが明確に分離される。疎結合になる。ミドルの調整はコンテナ内だけを気にして行えばよいので、サーバーはとりあえずDocker動いてくれればいいやみたいな状態になる。雑だけど楽だろうなという気がぼんやりしている。</p>

<h2>Dockerの運用</h2>

<p>とりあえず前述のTraildashはDockerによる本番運用（外に出すものではないので本番といえるか微妙ではあるが）の発端にはなりそうなものの、いわゆるアプリ、サービスを本番稼働させるのがどんなもんなのかってところは自分自身見えてない。これをきちんと本番で扱うには可用性やら信頼性やらを担保しなくてはならないわけで、クラスタ構成に用いる<a href="https://docs.docker.com/swarm/">Docker Swarm</a>を導入するだとか、いわゆるインフラとしてのお仕事はやっぱり必要になる。そのへんどこかで試せればなぁとは思うので、ひとまずは自分の http;//chroju.net をDocker化しようかなどと。この前OSCでさくらのクラウド2万円クーポンもらったし、Dockerによる個人PaaS的なものでも作ってみようか。</p>

<p>テストとしての利用には申し分のないところで、先日記事で上げたが<a href="http://chroju.github.io/blog/2015/11/18/ansible-serverspec-circle-ci/">AnsibleとServerspecのテスト</a>に使えるまっさらなOS環境としてDockerは重宝している。Infra as Codeと大変相性がよくて、よくこのタイミングで出てきてくれたなという感じがする。時代の要請なのだろうか。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansible + Serverspec + Docker + circle ci によるインフラCI]]></title>
    <link href="http://chroju.github.io//blog/2015/11/18/ansible-serverspec-circle-ci/"/>
    <updated>2015-11-18T22:13:25+09:00</updated>
    <id>http://chroju.github.io//blog/2015/11/18/ansible-serverspec-circle-ci</id>
    <content type="html"><![CDATA[<p><a href="http://blog.kenjiskywalker.org/blog/2014/11/13/circleci-docker-ansible-serverspec/">CircleCIでDockerコンテナに対してansibleを実行しserverspecでテストをする - さよならインターネット</a></p>

<p>この記事に書かれている内容を実際にやってみた。Ansibleを一旦は触ってみたところから、Circle.CIどころかCI経験が一切ない、ServerspecとDockerも使ったことがないという出発点だったので、得られるものはだいぶ大きい経験だった。完了したレポジトリは以下。</p>

<p><a href="https://github.com/chroju/ansible-ruby-devs">chroju/ansible-ruby-devs</a></p>

<h1>Ansibleにテストは必要か？</h1>

<p>AnsibleはPlaybookに書かれた設定通りにサーバーをセッティングしてくれるツールなのだから、傍証としてのテストは必要ないし、そもそもそれはAnsibleに対する信頼の問題だという話がある。（かのオライリーのServerspec本でも「Serverspecの必要性」を状況に応じて説明した章がある）が、自分は以下の理由からAnsible実行後のテストは必要と考えている。</p>

<h2>1. Playbookの書き方が間違っている</h2>

<p>確かにPlaybookに書いた内容通りにサーバーは組まれるのだが、そもそもPlaybookの書き方がおかしくて、想定通りの実行結果にならない可能性はある。そのレベルであればコードレビューで気付くべきではないかという話もあるが、こういう趣味の個人開発では難しかったり、レビューで漏れがあったりというのも有り得るわけで、自動テストに任せられるならその方が確かかとは思う。</p>

<h2>2. 冪等性の問題</h2>

<p>特にshellモジュールを用いたときなどは冪等性が維持されない可能性があり、複数回の実行で想定外のサーバー状態になる可能性はある。</p>

<h1>テストツールの選定</h1>

<p>普通にServerspec。Ansibleで定義したインベントリファイルやrolesをServerspecと共有してくれる<a href="http://qiita.com/volanja/items/5e97432d6b231dbb31c1">ansible_spec</a>というツールもあり、当初はこちらを使おうとしていた。が、前述した「Ansibleの書き方自体が間違っている可能性」をテストするとなると、できるだけAnsibleとテストツールは疎結合とするべきと考え、ファイルや設定は一切共有しない形でServerspecを使っている。</p>

<h1>Circle CIの利用</h1>

<p>繰り返しになるが初である。インフラエンジニアがCIをすることはまぁない（なかった）。そんな頻繁に設定を変えるわけでもなし。インフラCIが可能かつ必要となったのは、Infrastructure as Codeの台頭と、クラウドネイティブ化によりImmutableかつ極めて速いライフサイクルでサーバーインフラが更新されるようになったことによるもの。</p>

<p>で、Circle CIでググってもそんなに使い方みたいな初歩的な記事は出ない。どうもCIツールの使い方なんてのはJenkins登場の頃に身につけてて当然だろって感じの扱いっぽい。実際使いながら自分なりに理解したのは「レポジトリをpushすると、それを使って自動的にテストやデプロイを回してくれる」ツールということで、Circle CIについてはこんな感じに認識してるんだがあってんのかなぁ。</p>

<ul>
<li>レポジトリの使用言語やファイル構成を見て良きに計らって勝手にテストしてくれる。</li>
<li>もちろん自分でテストコマンドを書いてもOKで、Circle CIにやってほしいことは <code>circle.yml</code> というYAMLファイルに書いてレポジトリの第一階層に置いておく。</li>
<li>GitHub連携を前提としており、連携したレポジトリの <code>push</code> をトリガーとして動作する。</li>
<li>動作としてはCircle CI上でDockerコンテナ（ubuntuベース）を起動→レポジトリを <code>git clone</code> →circle.ymlを読んで実行</li>
</ul>


<h1>実装</h1>

<p>実際のcircle.ymlはこうなった（といってもほぼ丸のまま冒頭記事のものを使っているが）。Dockerイメージのキャッシュには以下の記事も参考にした。</p>

<p><a href="http://stormcat.hatenablog.com/entry/2015/02/04/004227">CircleCIでDockerイメージをキャッシュするのに、実はちょっとした工夫が必要な件 - tehepero note(・ω&lt;)</a></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">machine</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">timezone</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">Asia/Tokyo</span>
</span><span class='line'>  <span class="l-Scalar-Plain">services</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">docker</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">dependencies</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">pre</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">if [[ -e ~/docker/docker_ansible_image.tar ]]; then docker load --input ~/docker/docker_ansible_image.tar ; else docker build -t centos_ansible ~/ansible-ruby-devs/ ; mkdir -p ~/docker ; docker save -o ~/docker/docker_ansible_image.tar centos_ansible ; fi</span>
</span><span class='line'>
</span><span class='line'>  <span class="l-Scalar-Plain">cache_directories</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="s">&quot;~/docker&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">test</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">override</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">docker run -v `pwd`/ansible:/ansible centos_ansible /bin/sh -c &#39;ansible-playbook /ansible/ci_site.yml -i /ansible/ci_hosts -c local &amp;&amp; cd /ansible/spec &amp;&amp; /home/develop/.rbenv/bin/rbenv exec bundle install &amp;&amp; /home/develop/.rbenv/bin/rbenv exec bundle exec rake spec&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>この方法の肝はAnsibleとServerspecのフォルダを<code>docker run</code>の<code>-v</code>オプションでコンテナにマウントさせてしまって、ローカルでいずれも実行させている点だと思う。Dockerコンテナに対してSSHで外から処理を行うことももちろん可能ではあるが、ちょこちょこと小細工は必要だし、CI上の処理であればミニマムに済ませたいところ。</p>

<p>テストにおいてはインベントリファイルも<code>site.yml</code>もテスト用の設定値となるので、CI用のファイルを置いている。ただ、これらはレポジトリにとっては余分なファイルでしかないので、本来であれば取り除きたいような気もする。妙案は浮かばない。Dockerコンテナは2回目以降の実行だと<code>load</code>するだけで済むし、AnsibleとServerspecはローカル実行なので、処理時間はだいぶ速い。</p>

<p>実行結果はslackの個人チャンネルに流している。GtiHubに上げるだけで勝手にテストして結果も自動通知されるというのはとても楽しい。やれることの自由度が広すぎて夢が広がる。</p>

<h1>つまずいた点</h1>

<ul>
<li>Dockerfile初挑戦につき、結構戸惑った。Ansibleでsshd_configを編集させていたのだが、コンテナにそもそもsshが入ってなくてコケたりした。</li>
<li>Circle CIでのカレントディレクトリの扱いがわからず、しばらく <code>circle.yml</code> で指定するファイルパスに悩まされた。クローンしたレポジトリの中にいる状態で始まるっぽい？</li>
<li><code>docker run</code> に <code>&amp;&amp;</code> 付きでコマンド渡すときに <code>/bin/sh -c</code> が必要だとしばらく気付かなかった。</li>
<li>Dockerコンテナを <code>save</code> して <code>load</code> してるので、Dockerfile書き換えたら当然ながらCircle CIを「without cache」で実行しないとダメです。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[オープンソースカンファレンス2015 Tokyo/Fall行ってきた]]></title>
    <link href="http://chroju.github.io//blog/2015/10/25/osc-2015-tokyo-fall/"/>
    <updated>2015-10-25T21:42:59+09:00</updated>
    <id>http://chroju.github.io//blog/2015/10/25/osc-2015-tokyo-fall</id>
    <content type="html"><![CDATA[<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/chroju/22273557670/in/dateposted-public/" title="このはちゃんかわいい"><img src="https://farm1.staticflickr.com/630/22273557670_c7c51c391b_z.jpg" width="640" height="640" alt="このはちゃんかわいい"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>戦利品、ConoHaちゃんかわええ。</p>

<p>オープンソースカンファレンスに初めて行ってみた。2015 Tokyo/Fallです。だいぶ奥地の方でやってるなぁという印象があってなかなか行きづらかったのだが、実際行ってみると自然に囲まれて静かで建物綺麗で過ごしやすそうないい大学ですね。ちょっぴり休憩でもくもくしたりしてみたけどだいぶ捗ったし、もう少し近所なら作業環境に使いたい感じが（）</p>

<p>ぼっち参戦かつ初参戦かつコミュ障な故、ブースがんがん回ってがんがん自分から話しかけるみたいな度胸はなく、だいたいセッション聴いてました。ので、セッションごとにちょっとまとめる。</p>

<h1>はじめてのオープンソース・ライセンス</h1>

<p>オープンソース自体の考え方だとかは知ってはいたのだが、ライセンスがMITとかApacheとかそういういろいろがあるのがよくわかってなかったので。話の中で教えていただいた<a href="http://www.catch.jp/oss-license/2013/09/10/github/">Githubによる、オープンソースライセンスの選び方 | オープンソース・ライセンスの談話室</a>というページが確かに詳しそうなので後で読まなければなと思った。ギッハブ使ってるのに全然これ理解してなかった。</p>

<h1>実録！Hinemos導入経験者が語る、実運用でのあるある話</h1>

<p>最近実務でHinemosを使っているもので。監視設定をグループ（スコープ）単位で作ってしまうと静観するときに設定変更がしんどいだとかっていう本当にあるあるな話と、<a href="http://www.hinemos.info/option/utility">Hinemos Utility</a>が便利だという話など。Hinemos Utility、設定のインポートエクスポートがあるので、GUIポチポチの面倒臭さから救われそうな気はした。あるある話の方は他の監視ツールでもわりと似たところあるので、結局アーキテクチャーってどんなツールでも大して変わらんのかなぁ、そのへんどうにかしたツールないかなぁとか思った。</p>

<p>そういえばセッションはTISの主催だったのだが、同社といえば<a href="http://thinkit.co.jp/author/3519">Zabbixの池田氏</a>の印象が強いので、Zabbixと比較して同社としてどう考えてるのかってあたりも聞きたかった。</p>

<h1>[飲食OK]（発表者募集中！）1日目-ライトニングトーク（by OSCスポンサー）</h1>

<p>なかなかカオスにライトニングトーク。飲食OKでしたけど学食せっかくなので使いたかったので無飲食で。言及してるとキリがないので割愛。</p>

<h1>Ubuntuの最新情報</h1>

<p>Ubuntu使ってない。てかDebian系ほとんど触った経験ないんで触らなきゃなと思いました。</p>

<h1>ZabbixでDockerも監視してみよう</h1>

<p>最後の質疑で出た話で、新陳代謝の高いコンテナの監視に既存ツールの分単位での監視感覚が役に立つのか？っていうのがあったのだけど、わりとそれに同意した。自分はコンテナを実サービスで運用した経験がないのでアレなのだが、その性質からして既存サーバーより速いスピードで起動停止を繰り返すことは有り得ると思うし、むしろアーキテクチャーの考え方がスピーディーなものに変わるためには監視ツールの在り方も変わんなきゃならないんじゃないかなぁと思った。答えは出てないけど。</p>

<h1>コンテナ(Docker)時代のインフラ技術・運用管理に迫る！</h1>

<p>Docker最新事情という感じで、Dockerの概要もそこそこに周辺ツールや開発状況をいろいろ舐めていく感じのセッション。Docker触り始めたばかりの自分にはとてもありがたかった。Docker machine、Docker Swarm、docker-composeだとかなかなかにワクワクする話。</p>

<h1>aozorahackの今までとこれから ～インターネット電子図書館「青空文庫」をエンジニアリングで支える～</h1>

<p>ここから2日目。春に<a href="https://atnd.org/events/66230">青空文庫アイディアソン</a>が開かれて話題になりましたが、そのときから興味があったので話を聞いてみた。青空文庫の誕生が1997年、オープンソースという言葉が生まれたのが1998年ということで、オープンソースより古い歴史を持つ青空文庫がOSSライクな発想をしていたはずもない！という出発点だったようなのだが、それを変えていこうという試み。もともとサードパーティ的にビューアやコンバータを作る動きは周辺にあったわけで、それをまとめて今風の開発をしていくとなると面白そうだなと思う。自分は業務エンジニア＋趣味エンジニアでしかないけど、こういうボランティアというか、自らの意志で参画していくエンジニアリング活動というのがOSSの在り方なんだとここで初めて腑に落ちた気がした。</p>

<h1>Solaris ZoneとPuppet、Serverspecでインフラ CI</h1>

<p>Solarisわからないけどインフラ周りの知識手広くしたいなということで行ってはみたがやっぱりわからなかった。知識って広くて浅いか狭くて深いかの二択だと勝手に思ってたけど、実際それなりに出来るエンジニアってそこそこ手広く平均点取れる人が多い気がしていて、例えばこのセッションであればUNIX（Solaris）の知識にコンテナ（Zone）の知識、んでPuppetはRubyだし、ServerspecもRubyというかRSpecなんですよね。エンジニアとしての幅、ちょっと見直したいなと思わされたセッション。</p>

<h1>【パネルディスカッション】今こそ語るエンジニアの幸せな未来 ～OSC東京編～</h1>

<p>春に行ったJAWS DAYSでも同様のパネディスを聴いてはいたので実質第二回というか。こういう話題が定期的に持ち上がるようになったのって、さくらインターネットが15周年迎えたこともあるようにエンジニアの高齢化（家庭環境の変化）があるような気はする。働き方はライフステージによっても、世の中の技術動向やビジネス動向によっても変わるので、結局時間と金銭的余裕のあるうちに勉強して、常に自分が働きやすい場所にいられるようバリューを磨いておくしかないのだろうなと思う。そういう話でした。</p>

<p>以上、9セッション。知識のザッピングとしてこういうセッション形式のイベントはやはり良いなと。いわゆる勉強会だとだいたいが自分の興味関心のあることだけに集中してしまうのだが、こういう機会だとせっかくなのでってことで脇道に逸れたりしやすいので、知識の幅増やす機会にはなりやすいですね。OSS、TISのようにビジネスとして取り扱っている人たちもいれば、aozorahackのような草の根の動きもあったり、有り様はいろいろであって、んでGitHubで取りあえずソース読むところからいつでも手を付けられる時代にあるので、何かしらやってみると面白いのかもしれない。尻込みしてるのではなく。</p>

<blockquote class="twitter-tweet" lang="ja"><p lang="ja" dir="ltr">テロ <a href="https://twitter.com/hashtag/osc15tk?src=hash">#osc15tk</a> <a href="https://t.co/OEa2JYMezY">pic.twitter.com/OEa2JYMezY</a></p>&mdash; T.Kabu (@disco_v8) <a href="https://twitter.com/disco_v8/status/657855359357337600">2015, 10月 24</a></blockquote>


<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>懇親会、<a href="https://twitter.com/chroju/status/657852424502276096">TRIGGER ANIMATION EXPO</a>に行けるチャンスがここしかなかったのと、200人という大所帯にぼっち参戦する勇気がないのと（あと、さすがに薄い話しかできなさそうであまり意味はないかなと思った）で行かなかったんだけど、生ハム原木はうらやましかった。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[インフラエンジニアの幸福論]]></title>
    <link href="http://chroju.github.io//blog/2015/10/20/eudaemonics-of-infrastructure-engineer/"/>
    <updated>2015-10-20T23:35:46+09:00</updated>
    <id>http://chroju.github.io//blog/2015/10/20/eudaemonics-of-infrastructure-engineer</id>
    <content type="html"><![CDATA[<p>1年前、<a href="http://yapcasia.org/2014/talk/show/df196eac-fb65-11e3-b7e8-e4a96aeab6a4">インフラエンジニアは死んだ</a>。</p>

<p>遅れにも遅れをとって今年からAWSに触れているけど、これは触れれば触れるほどインフラエンジニアとしての自分の価値に疑問を抱かせてくれるサービスで、インフラエンジニアとして今後自分はどのように幸せになれるのかなんて考えたくなってくる。</p>

<p>どうもLambdaが出たあたりから<a href="http://blog.takuros.net/entry/2015/10/19/081349">サーバーレスアーキテクチャ</a>という言葉が取り沙汰されてきているようで、アプリやDBを動かすための基盤としてサーバーが必要だという前提はすでに崩れている。AWSを触れる前はVPSを触っていたので、どうもAWS＝EC2というイメージから抜け出せずにいたが、実際には<a href="http://i-think-it.net/how-to-aws">「EC2を使ったら負け」</a>なんて言葉も目にする時代にある。ここ最近Circle CIを触ってみていても、テストの実行基盤となるサーバーなんて考え方をする必要はなくて、テスト用の環境はyamlで書けてしまうし、別のインスタンスが欲しければDockerで済ませられる。まぁherokuあたりからすでにそういう風潮だったよなという気もするが、単純にアプリをデプロイしてしまって実行基盤は全部お任せという状態から、LambdaとS3とCognitoを組み合わせて云々みたいな柔軟なアーキテクチャを採用できる状態にまで変化してきている。</p>

<p>AWSを管理する人間が旧来のインフラエンジニアである必要性を当人としてはあまり感じていないし、実際に昨今のWeb企業あたりだとアプリエンジニアがAWSエンジニアを兼ねている場合も少なくないとは思う。規模が大きくなれば構成設計にインフラエンジニアの視点が必要になったりもするのかもしれないが、そこで必要とされるスキルは必ずしも旧来のインフラスキルとは直結していない。1000万円のLBとCiscoのスイッチとDELLのサーバーを買ってきて配線して起動して設定していくスキルと、ブラウザ上でELBやEC2のセキュリティグループを設定するスキルは明らかに異なるもので、故に2015年におけるインフラ＝AWSの領域においては、旧来のインフラエンジニアと非インフラエンジニアが同じ土俵で戦えなくもなかったりする（さすがに言い過ぎ感あるか）。これまで培ってきたインフラスキルというものは、必ずしも2015年に戦える武器にはなっていない。</p>

<p>もちろん一方でEC2もオンプレの環境もまだ健在ではあるし、これが10年後に撤廃されるかというと、現状のMFのように残り続けるとは思う。特に金融のような特殊領域ではどうしてもクラウド移行が難しいということもある。だから旧来のインフラエンジニアが死に絶えることはないのだろうが、それでもパイが小さくなることは事実だし、物理環境の障害だとか5年ごとのリプレースだとか、テンションの上がらない類の仕事に携わり続けることを余儀なくされる。</p>

<p>テンションの上がる仕事がしたいと言うと軽薄になってしまうが、誰だって夜中にタクシーでデータセンターに駆け付ける機会は極力少なくしたいと思うわけで、これまで注力していたいわゆる「オープン系」の需要が狭まる中で、インフラエンジニアの「幸福論」のようなものは求められつつある気がする。より少なくなる、かつ結構しんどい椅子に座り続けるのは個人的に嫌なので、Docker、ServerSpec、Ansibleあたりの領域でガッツリ存在感を示せるようになるか、あるいはそれらを生み出す側、より下のレイヤーで技術的に研ぎ澄まされていくかの二択なのかなと最近は思いつつある。とはいえ後者はどう考えても狭き門であり、現実的には前者を日常的な業務としつつ、要はRubyエンジニアがgem書くような感覚でツール作ったりOSSにイッチョカミしたりもたまにやれるぐらいの力があるといいのだろうなと思う。</p>

<p>何はともあれやはり「勉強する」以外に道がないことは今も昔も変わってないし、ある意味で過渡期にある技術として、いまインフラは面白いところにあるとは思っている。これについていけるかついていけないかっていうシンプルな問いでもあって、自分の希望としてはついていきたい。今からアプリに鞍替えする気はなく、カーネル書けるかって言えば書けないだろうし、かといって今のまま障害対応で夜に起こされるのを続けるわけにもいかない。だったら2015年におけるインフラというものを学んでいくしかないわけで、幸いなことに、学べば「物理ハードウェアからの開放」というある程度の報酬が待ち受けていることは確実になっている。どれだけ頑張ってもサーバーのファームウェアのバグで泣かされるような時代ではなく、ある意味でインフラエンジニアが「インフラを学び直す」ことは美味しい選択肢ではある。また場合によっては、インフラエンジニアとしてより良い環境へ適時シフトしていく（惰性でずっとオンプレ使う方針の会社との喧嘩は早々に諦める）こともまた必要になるのだと思っている。</p>

<p>とかなんとか書きながら考えていたら、<a href="http://blog.hifumi.info/2015/02/23/wakateinfra/">若手インフラエンジニア現状確認会</a>とやらで似たような話が上がっていた。個人的な実感としてはITエンジニア100人の企業であれば5～9人ぐらいがインフラかなと思うので、若手インフラが少ないというよりは全体的にインフラエンジニアが少ないのだと思っているが、その分情報交換とか大切にしなきゃなと思う。エンジニア仲間増やしたい。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[個人開発環境にGithub Flowを適用する]]></title>
    <link href="http://chroju.github.io//blog/2015/10/04/individual-github-flow/"/>
    <updated>2015-10-04T14:00:05+09:00</updated>
    <id>http://chroju.github.io//blog/2015/10/04/individual-github-flow</id>
    <content type="html"><![CDATA[<p>Github、<a href="https://github.com/chroju">joinしたのは2013年</a>で作ったものは軒並みちゃんと突っ込んではいるんだけど、単に一区切りついたらadd => commit => pushしているだけでちゃんと使っていなかったので、個人開発ではあるがGithub Flowを取り入れてみた。</p>

<h1>What is Github flow ?</h1>

<p>Githubを用いた開発作業を進めるにあたっての指針みたいなものです。基本的にはmasterブランチ上では作業せず、作業工程ごとにブランチ作って、終わったらプルリクしてmasterにマージしてもらうことでデプロイとしましょうね、というものだと理解している。至ってシンプルではあるけど、これを取り入れるだけで従来やっちゃってた「masterで作業してるのでデプロイしても動かないレポジトリがGithub上にある」みたいな状態が防げて良さそうだと思った。</p>

<p>ちなみにGit-flowというのもあるようだけど、こちらは全然別個のツールらしく理解していない。Git-flowの問題解決としてGithub Flowが提唱されたようだが、そもそも開発工程の制御のためだけにツールを追加したくはないなと思ったのでGithub Flowを採用した。</p>

<p>Github Flowの理解にはこの文章が良さそう。なお、dotfilesのような大した更新のないレポジトリにはさすがに適用していない。</p>

<p><a href="https://gist.github.com/Gab-km/3705015">GitHub Flow (Japanese translation)</a></p>

<h1>実際の開発工程</h1>

<p>あくまでGithub Flowに沿う形という程度なので、そのままそっくり適用できてはないとは思うが。</p>

<h2>開発開始</h2>

<p>ブランチを切る。ブランチ名は機能追加等の開発要件であれば<code>dev_hoge</code>、バグフィックスであれば<code>hotfix_hoge</code>とする。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>git checkout -b dev_hoge
</span></code></pre></td></tr></table></div></figure>


<h2>開発中</h2>

<p>普通であればレビューを依頼するタイミングなど、開発の切りがついたところで<code>push</code>していくのだろうが、分散して開発しているわけではないので、1日の開発が終わる段階で<code>push</code>している。そもそも開発に使っている環境が複数あるので、Github上のdevelopブランチも常に最新化していつどこでも<code>fetch</code>可能にしたいなという思いがある。従来はDropboxで各環境間の同期を取っていたが、プラグインの有無やbundleなどで度々不具合もあったので改めた。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>git add -A
</span><span class='line'><span class="nv">$ </span>git commit -m <span class="err">&quot;</span>
</span><span class='line'>...
</span><span class='line'><span class="nv">$ </span>git push origin dev_hoge
</span></code></pre></td></tr></table></div></figure>


<p><code>git add .</code>ではなく<code>-A</code>なのは、そちらじゃないと<code>git rm</code>したファイル等が含まれないと<a href="http://qiita.com/otukutun/items/9feb513c596418e94fc6">こちらの記事</a>に書いてあったゆえ。</p>

<h2>開発終了</h2>

<p>開発が終わり、masterへのマージを必要とする段階に来たらプルリクを出す。プルリクって別のコミッターからしか不可なのかと思っていたが、自分のレポジトリに自分で出すことも可能だったのでそうしている。本来であればテストツール等走らせるべきではあるのだろうが、今のところはプルリクに対して特にレビュー等なく（自分のコードだし）そのままマージしている。</p>

<p>後述するがバグや開発課題の管理にはGithub issueを用いているので、マージの際はissueのナンバーをコメントに入れている。これでGithub上のリンクとして働いてくれるので便利。</p>

<p><a data-flickr-embed="true"  href="https://www.flickr.com/photos/chroju/21903884486/" title="スクリーンショット 2015-10-04 14.19.25"><img src="https://farm1.staticflickr.com/735/21903884486_cae2057f70_z.jpg" width="640" height="576" alt="スクリーンショット 2015-10-04 14.19.25"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>参考：<a href="http://rochefort.hatenablog.com/entry/2015/09/05/090000">Gitコミットメッセージの7大原則 - rochefort&rsquo;s blog</a></p>

<h2>マージ後</h2>

<p>作業ブランチを消して、ローカルのmasterを最新化する。</p>

<p>マージには<code>git merge</code>を使用し、<code>git rebase</code>は使わないことにしている。そもそも<code>rebase</code>完全に理解してないというのもあるが、要するに歴史改変にあたるような操作があまり好めないというのが強い。個人の開発においては作業ブランチの変更中にmasterに更新が入ることは少ないので、このやり方でおそらく不都合はしないと思っている。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>git checkout master
</span><span class='line'><span class="nv">$ </span>git branch -a
</span><span class='line'><span class="nv">$ </span>git branch -d dev_hoge
</span><span class='line'><span class="nv">$ </span>git push --delete origin dev_hoge
</span><span class='line'><span class="nv">$ </span>git fetch
</span><span class='line'><span class="nv">$ </span>git marge origin/master
</span></code></pre></td></tr></table></div></figure>


<p>参考
<a href="http://dev.classmethod.jp/tool/git/development-flow-with-branch-and-rebase-by-git/">GitのRebaseによるBranchの運用 ｜ Developers.IO</a>
<a href="http://kray.jp/blog/git-pull-rebase/">git pull と git pull –rebase の違いって？図を交えて説明します！ | KRAY Inc</a></p>

<h2>コンフリクトした場合</h2>

<p><code>git ls-files -u</code>でコンフリクトしたファイルが一覧化されるとのことなので、確認の上で開いて直す。もしローカルかリモートのいずれかを全面採用するのであれば、<code>git checkout</code>の<code>--ours</code>と<code>--theirs</code>オプションを使う。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git ls-files -u
</span><span class='line'>git checkout --ours hoge
</span><span class='line'>git checkout --theris hoge
</span></code></pre></td></tr></table></div></figure>


<p>参考：<a href="http://d.hatena.ne.jp/sinsoku/20110831/1314720280">Gitでコンフリクトした時のための備忘録 - アジャイルSEを目指すブログ</a></p>

<h2>リモートのmasterがローカルより先に行っている場合</h2>

<p>ローカル環境が複数あるので、このような場合は多々ありえる。そういうときは基本的にはmergeすればいいだけではあるが。masterはリモートレポジトリの最新化が原則となるので、コンフリクトした場合は99%リモートを優先させる。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git show-branch --all --color
</span><span class='line'>git fetch origin
</span><span class='line'>git diff origin/master
</span><span class='line'>git merge origin/master
</span></code></pre></td></tr></table></div></figure>


<p>参考：<a href="http://qiita.com/yuyuchu3333/items/a30387bdd6a0afc1185c">gitのリモートリポジトリの更新を確認する - Qiita</a></p>

<h2>バグ、開発課題の発生</h2>

<p>先に少し触れたが、開発すべきTODOはすべてGithub issueで管理することにした。今までどうしていたかというと特に管理はしておらず、思いつくままに開発してしまっていたのだが、これでGithubに開発に必要なものはすべて集約できるのではないかと思う。個人でのGithub issue運営には下記の記事を参考にさせてもらっているが、特に難しいことはせず、タスク管理ツールのような形で使っている。</p>

<p>参考：<a href="http://azu.github.io/slide/udonjs/github-issue.html#3">一人で使えるGithub Issue</a></p>

<h1>覚えられない</h1>

<p>Github Flowは便利なのだが、Gitのコマンド体系がどうにも覚えづらくて仕方がない。どうにもならんのでaliasを駆使してなるべく覚える内容を少なくしようと努めているが、あとは慣れるしかないのかなぁと。Githubのコマンドは本当に多い。体系自体を学ぶのであれば<a href="https://progit-ja.github.io/">Pro Git</a>がわかりやすく、epubの配布もあるのでKindleでいつでも読めて最高なのだが、数多あるコマンドを網羅しようとか思うとこれだけではつらい。Qiitaでまとめ記事が上がるたびに覗いてみて、今の自分のキャパで使えそうなのをつまみ食いしていく形で覚えればいいのかなと思っている。</p>

<p>今のalias設定はこんなの。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="o">[</span><span class="nb">alias</span><span class="o">]</span>
</span><span class='line'>  <span class="nv">a</span>  <span class="o">=</span> add
</span><span class='line'>  <span class="nv">aa</span> <span class="o">=</span> add --all
</span><span class='line'>  <span class="nv">br</span> <span class="o">=</span> branch
</span><span class='line'>  <span class="nv">bra</span> <span class="o">=</span> branch -a
</span><span class='line'>  <span class="nv">brd</span> <span class="o">=</span> branch -d
</span><span class='line'>  <span class="nv">co</span> <span class="o">=</span> checkout
</span><span class='line'>  <span class="nv">cob</span> <span class="o">=</span> checkout -b
</span><span class='line'>  <span class="nv">coo</span> <span class="o">=</span> checkout --ours
</span><span class='line'>  <span class="nv">cot</span> <span class="o">=</span> checkout --theirs
</span><span class='line'>  <span class="nv">cl</span> <span class="o">=</span> clone
</span><span class='line'>  <span class="nv">clr</span> <span class="o">=</span> clone --recursive
</span><span class='line'>  <span class="nv">cm</span> <span class="o">=</span> commit
</span><span class='line'>  <span class="nv">cmm</span> <span class="o">=</span> commit -m
</span><span class='line'>  <span class="nv">d</span>  <span class="o">=</span> diff
</span><span class='line'>  <span class="nv">f</span>  <span class="o">=</span> fetch
</span><span class='line'>  <span class="nv">lg</span> <span class="o">=</span> log
</span><span class='line'>  <span class="nv">lga</span> <span class="o">=</span> log --graph --decorate --online
</span><span class='line'>  <span class="nv">lgp</span> <span class="o">=</span> log -p
</span><span class='line'>  <span class="nv">mg</span> <span class="o">=</span> merge
</span><span class='line'>  <span class="nv">mgn</span> <span class="o">=</span> merge --no-ff
</span><span class='line'>  <span class="nv">ps</span> <span class="o">=</span> push
</span><span class='line'>  <span class="nv">psd</span> <span class="o">=</span> push --delete origin
</span><span class='line'>  <span class="nv">pso</span> <span class="o">=</span> push origin
</span><span class='line'>  <span class="nv">psm</span> <span class="o">=</span> push origin master
</span><span class='line'>  <span class="nv">pl</span> <span class="o">=</span> pull
</span><span class='line'>  <span class="nv">s</span>  <span class="o">=</span> status -s
</span><span class='line'>  <span class="nv">sb</span> <span class="o">=</span> status -s --branch
</span><span class='line'>  <span class="nv">ss</span> <span class="o">=</span> status
</span><span class='line'>  <span class="nv">sh</span> <span class="o">=</span> show
</span><span class='line'>  <span class="nv">sba</span> <span class="o">=</span> show-branch --all
</span></code></pre></td></tr></table></div></figure>


<h1>今後</h1>

<p>やりたいこととしてはCI。Circle CIとかと連動させて自動テストしたりというところまで組み込めたら、個人開発としてだいぶ理想的な状態かなと思う。そのままデプロイまで自動化できれば最高か。またGitの理解がやはりどうにも覚束ない部分があり、まだまだ使いこなせているとは言いがたいので、aliasをカンペ代わりに育てつつ、ガンガン覚えていきたい。特にミスったときの<code>reset</code>系コマンドがあまりに多くてなぁ……。</p>

<h1>その他参考記事</h1>

<ul>
<li><a href="http://keijinsonyaban.blogspot.jp/2011/05/git.html?m=1">見えないチカラ: 【翻訳】Gitをボトムアップから理解する</a></li>
<li><a href="http://postd.cc/git-command-line-shortcuts/">Gitコマンドラインショートカット | プログラミング | POSTD</a></li>
<li><a href="http://yuroyoro.hatenablog.com/entry/20101008/1286531851">.gitconfigに設定してるaliasなどのまとめ - ( ꒪⌓꒪) ゆるよろ日記</a></li>
<li><a href="http://d.hatena.ne.jp/sinsoku/20111025/1319497900">図で分かるgit-mergeの&ndash;ff, &ndash;no-ff, &ndash;squashの違い - アジャイルSEを目指すブログ</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[開発環境のためのansibleを出来るだけベストプラクティスでまとめた]]></title>
    <link href="http://chroju.github.io//blog/2015/09/24/ansible-in-nearly-best-practice/"/>
    <updated>2015-09-24T19:37:08+09:00</updated>
    <id>http://chroju.github.io//blog/2015/09/24/ansible-in-nearly-best-practice</id>
    <content type="html"><![CDATA[<p>自分は今まで開発に使うマシンとして家では据え置きのiMac Mid 2010（古い）を、出先ではVAIO Proに入れたArch Linuxを使っていて、レポジトリの同期にはあろうことかDropboxを使っていたのだが、インストールされているツールが微妙に違っていたり、Dropboxで<code>bundle</code>とかまで同期してしまうのはあまりよろしくなさそうだなというのもあったりして、EC2上に開発環境を置いて各端末からはSSHでつなぐことにしてみた。で、せっかくなのでと思いansbileで環境構築を行っている。</p>

<h2>なぜEC2？</h2>

<p>少し前に<a href="http://chroju.github.io/blog/2015/07/20/ansible-digitalocean-vps-dev-env/">開発環境としてDigitalOceanを使うことを勧める記事</a>を書いたことがあったが、仮想マシンを停止しても課金が発生してしまうのが少々つらいのと、リージョンがすべて国外で、開発に使うにはさすがにレイテンシーが厳しいので断念した。EC2であれば停止中は課金されないので、常時起動が必要ない開発環境として使う分には課金額は少なくなりそうかなと考えている。今は自分のアカウントだとまだ無料期間にあたるので、t2.microを無料で使える状態にあり、実際の課金額がどうなるかは確かめていない。</p>

<h2>ベストプラクティス構成の意識</h2>

<p>出来上がったplaybooks（という言い方でいいのか？）はGitHubに上げてある。</p>

<p><a href="https://github.com/chroju/ansible">chroju/ansible</a></p>

<p>あらゆるサーバーで共通の<code>common</code>というロールと、開発環境用の<code>develop</code>というロールを用意している。現状、開発言語がRubyでシェルにはzshを使っているので、完全に自分仕様のplaybookにはなっている。dotfilesも自分のレポジトリから<code>git clone</code>しているし。</p>

<p>ansibleには公式ドキュメントに<a href="http://docs.ansible.com/ansible/playbooks_best_practices.html">ディレクトリ構成のベストプラクティス</a>が上がっていて、なるべくこれに沿うようには作っている。が、完全に当てはめてしまうには開発環境1サーバーだけのためのansibleには荷が重すぎるので、あくまで部分適用ではある。自分の解釈ではベストプラクティスの考え方はこんなところかと。</p>

<ul>
<li>playbooksは同時に実行すべきtaskをroleとして分割する</li>
<li>ansibleの適用対象サーバーはWeb、DB等の役割ごとにグループで分割する</li>
<li>グループごとに実行するroleと変数（group_vars）を紐つける</li>
</ul>


<p>taskはroleに分割され、それらroleをwebservers.ymlやdbservers.ymlがincludeし、さらにsite.ymlがすべての*servers.ymlをincludeするというのが公式の勧めです。確かにこれなら全体に適用したい場合は<code>ansible-playbook site.yml</code>でよいし、一部グループだけに適用したいなら<code>ansible-playbook *servers.yml</code>とすれば良いのだから合理的。さらにインベントリファイルもstagingとproductionに分けて、それぞれにwebserversとdbserversのグループを作っているのだから、stagingとproductonで別々に適用することも可能になると。またtagをtaskにつけておけば特定のtask群だけ実行することも容易になる。。。とまぁ、とにかくいろんな手段を使って分割実行できるようにしているわけですな。</p>

<p>なのでそこまで大規模な構成管理をしないのであれば、このあたりどこまで取り入れるのは自由ではないかと。自分の場合はサーバー1台が今のところは相手ということもあり、*servers.ymlにあたるインベントリファイルは作っていないし、tagも個々のtaskに対しては設定していない。今後さらに範囲を広げるようであれば、後付で設定していけばよいかと思っている。</p>

<p>ただ、少なくともroleに関しては分けておくべきと個人的には推しておきたい。普通にアプリケーション用のコード書くときにも関数やメソッドは分割しますよね？ってことで、全体の見通しを良くする意味でもroleへの分割は必須と思う。</p>

<p>ansible、ファーストインプレッションはとにかく<a href="http://chroju.github.io/blog/2015/06/25/hika-labo-ansible/">「楽そう」</a>だったんだけど、複雑なことをやろうとすればするほどドツボにはまっていきそうな気もする。ある程度早い段階でベストプラクティスに目を通したうえで、自分が使うときにはどういったディレクトリ構成が最も有効であるかを模索した方がよい。自分も理解できるまでは少し苦労したけど、一度やり方をハメてしまうと今後長く使えそうで満足感がある。</p>

<h2>このレポジトリでやっていること</h2>

<p>ソース読んでもらえればわかる話ではありますが。</p>

<ul>
<li>common

<ul>
<li>hostname設定</li>
<li>localeとtimezone設定</li>
<li>sshd_config設定</li>
<li>authorized keys設定</li>
<li>/etc/aliasesの設定</li>
<li>DenyHostsインストール</li>
<li>logwatchインストール</li>
<li>iptables設定</li>
</ul>
</li>
<li>develop

<ul>
<li>development tools、zsh、git、vim、jqのインストール</li>
<li>dotfilesの配置</li>
<li>デフォルトシェルをzshに変更</li>
<li>rbenvの設定</li>
</ul>
</li>
</ul>


<p>もっとも苦労したのはrbenv周りで、<code>git clone</code>直後はpathが通ってない<code>~/.rbenv/bin</code>配下のコマンドをどう実行すべきかとか、それなりに悩んだ。当初インベントリファイルで<code>sudo: yes</code>としてしまっていたので、rbenv関連のタスクも全部root権限で実行されて、軒並みフォルダやファイルがrootの所有になってしまうという事故があったのだが、<code>sudo:</code>ないし<code>become:</code>の設定はタスク単位で考えたほうが良いと思う。また本来であれば<code>~/.bash_profile</code>あたりにrbenvのpath追加等の設定を書き込むところまでタスク化すべきかと思うが、自分の場合はdotfilesにすでに設定が入っているので、そのタスクは作っていない。</p>

<p>もうひとつの悩みとしては、いずれのroleもsudo権限のある開発用ユーザーでの実行を前提に考えているのだが、EC2の場合は<code>ec2_user</code>、その他VPSの場合は<code>root</code>がデフォルトのユーザーなので、デフォルトユーザーで一度入って開発用のユーザーを作るところもタスク化すべきかなと言うこと。その場合はそのroleだけ別ユーザーで実行する形になるわけで、そういった構成がそもそも可能なのか？というところからわかってないのだけど。</p>

<h2>その他技術的な話</h2>

<p>細かい技術的なtipsは後ほどQiitaに上げるつもり。現状の疑問中心に一旦取りまとめます。</p>

<ul>
<li>変数名の命名規約。代入は<code>group_vars</code>で行うことになるが、ここに一挙に集めたときにどれがどこで使われているのかわかりにくいので、roleに紐ついた名前とすべきであろうか。。</li>
<li>ntp.confの設定。templatesでいい気はするのだが、どんなサーバーでも共通の設定で問題ないのか勉強不足でわかっていない。</li>
<li>EC2には開発ツールがないので<code>Development tools</code>でまとめてインストールしてしまったが、本当は個々に切り出したい。</li>
<li>ファイルの一部上書きではなく、追記に良い方法がないものか。下手にやると何度も追記してしまって冪等性がなくなる（現状は一度grepかけて、その内容でtaskの実施要否を分岐してるが汎用性がない）。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ハッカーマインドと3冊のエッセイ]]></title>
    <link href="http://chroju.github.io//blog/2015/08/16/hackers-mind-and-their-essay/"/>
    <updated>2015-08-16T16:02:51+09:00</updated>
    <id>http://chroju.github.io//blog/2015/08/16/hackers-mind-and-their-essay</id>
    <content type="html"><![CDATA[<p>ハッカー3大エッセイとは自分が勝手に呼んでいるだけなのだが、『ハッカーと画家』『UNIXという考え方』『それが僕には楽しかったから』の3冊のことである。しかし『それがぼくには』は重要な一冊だと思うんだけど、なんでまた絶版なんですかね。そんな古い本でもないのに。仕方なく図書館で借りたけど。</p>

<p>いわゆるハッカーマインドを描いた本としていずれも似たような印象を抱きがちだが、実際に読んでみるとスタンスはだいぶ異なる。『ハッカーと画家』はコンピュータについてあまり詳しくない人に対して、ハッカーというのはこういう人種なのだと切々と説いた本であり、故にそれほど挑発的な印象は受けず、すらすらと読み進めていくことができる。もっともこれがハッカー以外に理解できるかというとかなり疑問ではあるが、ハッカーが比較的客観的に自らを解き明かした本として参考にはなる。著者のポール・グレアムのエッセイは<a href="http://practical-scheme.net/wiliki/wiliki.cgi?naoya_t:%E3%83%9D%E3%83%BC%E3%83%AB%E3%83%BB%E3%82%B0%E3%83%AC%E3%82%A2%E3%83%A0%E3%81%AE%E3%82%A8%E3%83%83%E3%82%BB%E3%82%A4%E3%81%A8%E5%92%8C%E8%A8%B3%E4%B8%80%E8%A6%A7">naoya_t氏による和訳</a>がいくらか読めるので、これを読んで興味をそそられたら読んでみるのでもいいかもしれない。あと、Lispめっちゃ推してる。</p>

<p>『UNIXという考え方』は、ハッカー向けにハッカーマインド、というかUNIX哲学を説く本なので、これは3冊の中では最も「読むべき」本だと思った。プログラムの移植性が重要であることだとか、ソフトウェアのレバレッジを効かせて効率性を最大限に高めていくべきだとか、我々がコードを書いたりシステムを作る上で重視すべきことがいくつも盛り込まれている。</p>

<p>『それがぼくには楽しかったから』はまさにエッセイ、リーナス・トーヴァルズの半生を描いたもので、ハッカーマインド云々というよりはだいぶ読み物チック。終盤で著作権やOSSといった概念に対するリーナスの考え方が少し語られるが、ほとんどはLinuxがいかにして生まれたのか？を描いた物語と言っていい。自分はリーナスというハッカーをこれまで詳しくは知らなかったのだが、案外柔軟な人物であるという印象を受けた。OSSの考え方自体は肯定しながらも、それは押し付けるべきではない、具体的に名前を挙げてリチャード・ストールマンのやり方は強引に過ぎるとしていたり、自分は聖人君子ではなく、大金が舞い込んだときには当然喜んでしまったこともあるよなんて語っていたり、彼の人間性がとても良く出ている。まぁとはいえ、自分が否とみなしたものに対しては、それなりに厳しい批判を飛ばす人物ではあると思うが。</p>

<p>こうした本に書かれた「ハッカーマインド」なるものは、我々が仕事をする上で必須のものではないと思うし、行き過ぎるとリーナスが言うような宗教戦争チックにもなりかねない。また技術に傾倒しすぎた単なるオタクが仕事の上でも重要な人物足りえるかというと、そういうわけでもない。リーナス・トーヴァルズは偉大なハッカーの1人であろうが、彼は同時にLinux開発者という立場での活動を行うにあたり、社会性を身につけたりもしてきたわけで。単にGeekであること自体が良いこととも自分は思えない。</p>

<p>とはいえ、まだ生成されてまもなく、業界標準なんてものがあるんだかないのだかもわからない、進化の速いこの業界で仕事をしていくには、多少なりともハッカー的なマインドは必要だとも思うのだ。というか、じゃないと仕事が面白くならないんでは？　惰性で同じ技術をずっと使い続けたり、効率の悪い方法を繰り返したりしていてもお金は入るのだろうけど、それが必ずしも収入に結びつかないとしても、なんかカッコイイことやってみたいとか、楽しそうな新技術にトライしてみたいだとか、そういう感覚がないとエンジニアをやっている意味がないなと思う。エンジニアが会社を選ぶにあたって重要なのは、案外このポイントなのではなかろうか。</p>

<p>残念ながら求人票からハッカーマインドは透けてこないし、転職面接の数分でそれを読み解くことも難しいだろう（自分は以前、面接でArch Linuxの話でたまたま意気投合する機会があったりして、そういう面接が出来たら話が別なのだろうけど）。その点、最近GitHubやQiitaでエンジニアたちが企業名を出して活動していることがあるが、あれは求人票やウェブサイトでは見えにくいその会社のハッカーマインドを、外部に知らしめていく良い手段だと感じる。ビジネス的に何を成して、社会をどう変えたいのかというよりも、エンジニアとしてどういったカタチで技術にコミットしていくかの方が自分には重要だ。そういう視点で仕事をしていけたらどんなにか幸せだろうし、またそれは茨の道でもあるのだろうなと思っている。</p>

<div class="amazlet-box" style="margin-bottom:0px;"><div class="amazlet-image" style="float:left;margin:0px 12px 1px 0px;"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274065979/diary081213-22/ref=nosim/" name="amazletlink" target="_blank"><img src="http://ecx.images-amazon.com/images/I/511SV9NXW2L._SL160_.jpg" alt="ハッカーと画家 コンピュータ時代の創造者たち" style="border: none;" /></a></div><div class="amazlet-info" style="line-height:120%; margin-bottom: 10px"><div class="amazlet-name" style="margin-bottom:10px;line-height:120%"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274065979/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">ハッカーと画家 コンピュータ時代の創造者たち</a><div class="amazlet-powered-date" style="font-size:80%;margin-top:5px;line-height:120%">posted with <a href="http://www.amazlet.com/" title="amazlet" target="_blank">amazlet</a> at 15.08.16</div></div><div class="amazlet-detail">ポール グレアム <br />オーム社 <br />売り上げランキング: 6,887<br /></div><div class="amazlet-sub-info" style="float: left;"><div class="amazlet-link" style="margin-top: 5px"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274065979/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Amazon.co.jpで詳細を見る</a></div></div></div><div class="amazlet-footer" style="clear: left"></div></div>




<div class="amazlet-box" style="margin-bottom:0px;"><div class="amazlet-image" style="float:left;margin:0px 12px 1px 0px;"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274064069/diary081213-22/ref=nosim/" name="amazletlink" target="_blank"><img src="http://ecx.images-amazon.com/images/I/518ME653H3L._SL160_.jpg" alt="UNIXという考え方―その設計思想と哲学" style="border: none;" /></a></div><div class="amazlet-info" style="line-height:120%; margin-bottom: 10px"><div class="amazlet-name" style="margin-bottom:10px;line-height:120%"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274064069/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">UNIXという考え方―その設計思想と哲学</a><div class="amazlet-powered-date" style="font-size:80%;margin-top:5px;line-height:120%">posted with <a href="http://www.amazlet.com/" title="amazlet" target="_blank">amazlet</a> at 15.08.16</div></div><div class="amazlet-detail">Mike Gancarz <br />オーム社 <br />売り上げランキング: 44,838<br /></div><div class="amazlet-sub-info" style="float: left;"><div class="amazlet-link" style="margin-top: 5px"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274064069/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Amazon.co.jpで詳細を見る</a></div></div></div><div class="amazlet-footer" style="clear: left"></div></div>




<div class="amazlet-box" style="margin-bottom:0px;"><div class="amazlet-image" style="float:left;margin:0px 12px 1px 0px;"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4796880011/diary081213-22/ref=nosim/" name="amazletlink" target="_blank"><img src="http://ecx.images-amazon.com/images/I/51WZM2W6ZBL._SL160_.jpg" alt="それがぼくには楽しかったから (小プロ・ブックス)" style="border: none;" /></a></div><div class="amazlet-info" style="line-height:120%; margin-bottom: 10px"><div class="amazlet-name" style="margin-bottom:10px;line-height:120%"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4796880011/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">それがぼくには楽しかったから (小プロ・ブックス)</a><div class="amazlet-powered-date" style="font-size:80%;margin-top:5px;line-height:120%">posted with <a href="http://www.amazlet.com/" title="amazlet" target="_blank">amazlet</a> at 15.08.16</div></div><div class="amazlet-detail">リーナス トーバルズ デビッド ダイヤモンド <br />小学館プロダクション <br />売り上げランキング: 71,563<br /></div><div class="amazlet-sub-info" style="float: left;"><div class="amazlet-link" style="margin-top: 5px"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4796880011/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Amazon.co.jpで詳細を見る</a></div></div></div><div class="amazlet-footer" style="clear: left"></div></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Qiitaを使うということの意義]]></title>
    <link href="http://chroju.github.io//blog/2015/08/09/qiita-commoditization-of-engineer/"/>
    <updated>2015-08-09T23:28:57+09:00</updated>
    <id>http://chroju.github.io//blog/2015/08/09/qiita-commoditization-of-engineer</id>
    <content type="html"><![CDATA[<p><a href="http://qiita.com/chroju/">Qiitaにいくつか記事を上げてみて</a>思ったことを。</p>

<h1>承認欲求が満たしやすい</h1>

<p>ブログのような個人の場ではないのに承認欲求がってのもどうなんだという話はあるが、反応を得やすい。Qiitaでは各エントリーに必ずタグを設定することになり、ユーザーは興味のあるタグを登録して新着記事をチェックするわけだが、記事が上がってくるスピードは1日に数えられる程ではあるので、上げればほぼ必ず誰かしらの目には留まる状態にある。なので自分が上げたのは基礎的な記事ばかりだという思いはあるのだが、それでもすべて漏れなくストックされていた。</p>

<p>もちろん、100ストックなどを目指すとハードルはぐっと上がってくるわけだが、こういった個人ブログで誰が見てくれているかわからない状態と比べて、記事投稿へのモチベーションは保ちやすいように感じた。なお、はてなでも同様のエコシステムは働いていて、例えばこのブログもはてな時代はそこそこブクマされていたわけだが、github.io化した後のブクマは見事にゼロである。</p>

<h1>誤り修正と議論の活性化</h1>

<p>ほぼすべての記事が誰かしらの目に触れるということで、（自分は未経験だが）コメントにより間違いの修正が入ることも多い。特に特定のタグに関してはその道の有名な方がだいぶ監視しているっぽいなぁという場合もあり、ちょこちょこコメントが付いている。</p>

<p>またコメントで長々と議論が続くのもよく見かける。単なるハウツーよりは何らかの設計思想を書いた記事に多いように思うが、派生した内容として興味深く追えることも多い。</p>

<h1>技術のコモディティ化</h1>

<p>で、ここからが本題なのだが、QiitaによってIT技術者の知識というのはある程度コモディティ化されそうだなぁと思う。</p>

<p>Qiita以前ははてななどがエンジニアのアウトプットがよくストックされる場所ではあったが、Qiitaほど体系だってまとめられていたわけではない。Qiitaでは「タグ」を追うことで、その分野の新しい話題も古い話題も、基礎も応用も知っていくことができる。逆に言えば、Qiitaに書いてあることぐらいは誰だってすぐ追って身につけられる状態にある。</p>

<p>技術書のような網羅性の高い知識パッケージとはさすがに性質を異にはするが、先に上げたコメントなどによって適宜内容が改訂され、より正しい状態に近づいていき、また必要な情報、新たな情報が次々と追加されるという意味では、動的な知識パッケージとして果たす役割は大きいのではないか。
まぁ要はブログやSNSの黎明期に言われたようなことが、Qiitaという専門性の高い1サービス内で圧縮的に再現されているというだけの話ではあるのだが、「Qiitaをやっている」というレッテルが、ある一定の知識レベルを有することと同義になる日も来そうだなという思いがする。問題点としてはQiita外と同様、やはりWeb系、OSS系の知識に内容が偏っていて、有償製品等のノウハウはそれほど多くないことだろうか。これはQiitaの問題ではないのだけど。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kaminariの実装をしてみた]]></title>
    <link href="http://chroju.github.io//blog/2015/08/08/exhibi-update/"/>
    <updated>2015-08-08T19:47:30+09:00</updated>
    <id>http://chroju.github.io//blog/2015/08/08/exhibi-update</id>
    <content type="html"><![CDATA[<p>久しぶりに稼働させている<a href="http://chroju.net/exhibi">ExhiBi</a>というサービスの機能を少し更新した。といってもそれほど大した話ではないですが、一応書き留め。</p>

<h1>kaminari</h1>

<p>ページネーションでデファクトスタンダード状態であるkaminariを使ってみました。</p>

<iframe class="bookmarklet hatena-embed" src="http://hatenablog.com/embed?url=http%3A%2F%2Fgithub.com%2Famatsuda%2Fkaminari" title="amatsuda/kaminari" style="border:none;display:block;margin:0 0 1.7rem;overflow:hidden;height:155px;width:100%;max-width:100%;"><a href="https://github.com/amatsuda/kaminari" target="_blank">amatsuda/kaminari</a></iframe>


<p>bundlerでインストールすればほぼ設定とかなくても使えます。最初のローンチのときに入れなかったので、viewを結構いじらなくちゃいけなくて大変かなーと思っていたのだけど、そんなことはなかった。主に変更は2点で、まずは<code>controller</code>で<code>#index</code>のようなリソースを拾ってくるアクションに<code>.page</code>をかましてやるようにします。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1"># もともとはExhibition.all.order...</span>
</span><span class='line'><span class="k">def</span> <span class="nf">index</span>
</span><span class='line'>  <span class="vi">@exhibitions</span> <span class="o">=</span> <span class="no">Exhibition</span><span class="o">.</span><span class="n">page</span><span class="p">(</span><span class="n">params</span><span class="o">[</span><span class="ss">:page</span><span class="o">]</span><span class="p">)</span><span class="o">.</span><span class="n">order</span><span class="p">(</span><span class="s2">&quot;start_date DESC&quot;</span><span class="p">)</span>
</span><span class='line'><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>あとは<code>view</code>でページネーションを表示するためのヘルパーを1行追加すれば終わり。以下はslimの場合。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='slim'><span class='line'><span class="p">=</span> <span class="n">paginate</span> <span class="vi">@exhibitions</span>
</span></code></pre></td></tr></table></div></figure>


<p>なお、実装当初は<code>undefined method 'deep_symbolize_keys'</code>などというちょっと関係ねーだろこれって感じのエラーが出たりして焦ったのは秘密です。原因は<code>config/locales/ja.yml</code>が一切インデントされてなかったことなんですけど、そんなのがここに波及するんですね。。。てかyamlの書き方よくわかってねーわ。</p>

<p>もちろん、1ページあたりの表示数とかページャーの表示の仕方だとか、いろいろ細かく設定はできますが、とりあえずこれだけでページャーは実装されます。あーこりゃデファクトスタンダードになるわなという簡単さ。早く入れればよかった。なお、本当にまだ入れただけなのでCSSとかぜんぜん調整してないです。</p>

<h1>id以外の要素でmodle#showにアクセスする</h1>

<p>例えばExhiBiの場合は美術館ごとのページにアクセスするには、これまでmuseums/2みたいなURLになっていたわけですが、カッコ悪いし使い勝手も悪いのでmuseums/motなど、英名でアクセスできるよう変えました。参考にしたのは以下ページ。</p>

<iframe class="bookmarklet hatena-embed" src="http://hatenablog.com/embed?url=http%3A%2F%2Fqiita.com%2Fawakia%2Fitems%2Fc2c790dc51e5b084af10" title="Railsで、URLにIDでなく名前を入力して、アクセスする方法 - Qiita" style="border:none;display:block;margin:0 0 1.7rem;overflow:hidden;height:155px;width:100%;max-width:100%;"><a href="http://qiita.com/awakia/items/c2c790dc51e5b084af10" target="_blank">Railsで、URLにIDでなく名前を入力して、アクセスする方法 - Qiita</a></iframe>


<p>やってることはなんともシンプルで、<code>Museum.find(n)</code>で呼んでいたところを<code>Museum.find_by_name_en_or_id(hoge)</code>と出来るようにしただけですね。<code>#to_param</code>でサービス内のリンクもすべて英名表記URLに変更できています。こういう柔軟さはRailsやっぱりいいですね。</p>

<p>ただ自分の場合ちょっと問題があったのは、これまでテーブルに英名表記のカラムを入れてなかったので、新たに追加する必要がありました。まぁ普通に<code>bundle exec rake g migration</code>してから<code>rake db:migrate</code>するだけなんですけど、ローカルで開発しているときに何故かこれが通らず、一旦<code>rake db:migrate:reset</code>してから改めて打つハメになったりした。このへんの話は以下記事がちょっと詳しかったり。</p>

<iframe class="bookmarklet hatena-embed" src="http://hatenablog.com/embed?url=http%3A%2F%2Feasyramble.com%2Fdifference-bettween-rake-db-migrate-reset.html" title="rake db:reset と rake db:migrate:reset の違い | EasyRamble" style="border:none;display:block;margin:0 0 1.7rem;overflow:hidden;height:155px;width:100%;max-width:100%;"><a href="http://easyramble.com/difference-bettween-rake-db-migrate-reset.html" target="_blank">rake db:reset と rake db:migrate:reset の違い | EasyRamble</a></iframe>


<p>自分はインフラエンジニアなので、Railsを実務で使うってことはほとんどこの先皆無だとは思うんですけど、自己表現手段としてやっぱりRailsぐらい使えておくと良さそうだなと改めて思います。例えばインフラの勉強でサーバー運用してみようとなっても、上で何か動いてないとあんまり勉強にならなかったり。自分がどんなことをしているのか？を外にアッピルする意味では、こういうの1つぐらい持っとくといいのだろうなと思います。yamlの勉強しなきゃとか、今回そういう派生効果もありましたので。近々作れたらもう1個サービス作ってみようと思ってます。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Qiitaはじめました]]></title>
    <link href="http://chroju.github.io//blog/2015/07/25/start-qiita/"/>
    <updated>2015-07-25T11:07:38+09:00</updated>
    <id>http://chroju.github.io//blog/2015/07/25/start-qiita</id>
    <content type="html"><![CDATA[<iframe class="bookmarklet hatena-embed" src="http://hatenablog.com/embed?url=http%3A%2F%2Fqiita.com%2Fchroju" title="chroju - Qiita" style="border:none;display:block;margin:0 0 1.7rem;overflow:hidden;height:155px;width:100%;max-width:100%;"><a href="http://qiita.com/chroju" target="_blank">chroju - Qiita</a></iframe>


<p>気分でQiitaはじめてみた。Kobitoをちらちら使って簡単なメモを残していたりしたのだけど、そこから一発で上げられるのはやっぱ楽かなと思って。あと先日の<a href="http://chroju.github.io/blog/2015/07/20/encryption-hash-at-first/">暗号化に関する記事</a>みたいなまとめ記事、tips系はやはりQiitaの方がフットワーク軽くて使いやすいような気がする。更新した場合にも履歴が残るし。</p>

<p>ブログとの使い分けが難しそうな気はするが、いわゆる勉強メモみたいな頻繁に見返すものをQiitaに上げて、ブログの方はもっとガッチリとした長文、たとえば勉強会の記録だとか技術に対する考え、あるいは何かを作った系の記事などを上げたらいいのではと思っている。まぁこのへんはあまり縛られず、あくまで中心に据えているのは自分用メモとしての役割なので、自分が使いやすいようなやり方でやれればいいかなと思っている。</p>

<p>ブログは多くとも週2回程度の更新だったが、Qiitaはもっと高い頻度でいろいろ貯めこんでいきたいし、そうできるような仕事をしていきたい所存。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[暗号化とハッシュ化に関する基本的な事柄まとめ]]></title>
    <link href="http://chroju.github.io//blog/2015/07/20/encryption-hash-at-first/"/>
    <updated>2015-07-20T16:56:06+09:00</updated>
    <id>http://chroju.github.io//blog/2015/07/20/encryption-hash-at-first</id>
    <content type="html"><![CDATA[<p>セキュリティスペシャリスト持ってるはずなのに曖昧な理解で誤魔化してたので自分用まとめ。また書き足すかも。なんか書き足し書き足ししていくようなノートの整理には、編集履歴が見られるQiitaの方が便利なのかなとか思うけど。</p>

<ul>
<li>暗号化とハッシュ化は違う。暗号化はデータの秘匿を目的としており、適切な鍵を用いることで復号が可能。ハッシュ化はデータの置換がそもそもの目的であり、ハッシュ関数により一定のフォーマットへ不可逆の変換を行う。</li>
<li>ただし、衝突耐性を持つことなどにより、セキュリティ用途に適する「暗号学的ハッシュ関数」というものもあるらしい。デジタル署名やメッセージ認証符号への使用を目的とされており、逆にチェックサム等に使用するには計算が「重い」。</li>
</ul>


<h1>暗号</h1>

<p>主なアルゴリズムをざっと。</p>

<h2>RSA</h2>

<ul>
<li>公開鍵暗号。素因数分解の計算難度を根拠としたもの。サマウォで解いてたアレもたぶん素因数分解暗号だが、暗算で解かれたらたまったものではない。</li>
<li>SSHログイン時の鍵認証やSSL認証など、広く使われる。</li>
<li>秘密鍵生成コマンドとして<code>openssl genrsa</code>がある。SSH鍵認証では<code>ssh-keygen</code>を用いる。</li>
</ul>


<h2>DES</h2>

<ul>
<li>共通鍵暗号。鍵長54bitのブロック暗号。</li>
<li>鍵長が短すぎるため、現在では安全ではないとされるが、暗号化復号化処理を3回実行するトリプルDESという形で主に実用されている。</li>
<li><code>openssl genrsa</code>での秘密鍵生成時に、パスフレーズによるトリプルDESでの暗号化を施すため、<code>-des3</code>オプションが用いられる。</li>
</ul>


<h2>AES</h2>

<ul>
<li>共通鍵暗号。DESの安全性低下に伴い開発された、鍵長128bit超のブロック暗号。</li>
</ul>


<h1>ハッシュ</h1>

<h2>ソルト</h2>

<p>ハッシュ化前に対象文字列に付加するランダムな文字列。同一文字列のハッシュ化時に衝突が防げる、レインボーテーブルによる探索に対する妨害になる、といった利点がある。</p>

<h2>フィンガープリント</h2>

<p>SSH初回ログインで表示されるやつ。公開鍵のハッシュ値。<code>~/.ssh/known_hosts</code>に記述され、次回以降のログインで公開鍵の変更有無の確認に使われる。変更があると、サーバーなりすましの危険性もあるため警告が表示される。<code>ssh-keygen -lf</code>でも表示可能。</p>

<h2>md5</h2>

<ul>
<li>出力128bitのハッシュアルゴリズム。ファイル配布時のチェックサムなどに用いられる。</li>
<li>安全性は高くないことが判明しているため、日米ともにSHAの使用が推奨されている。</li>
<li>コマンドは<code>md5sum</code>あるいは<code>openssl md5</code>を使用する。</li>
<li>なおパスワードハッシュ化でよく用いられる<code>openssl passwd</code>はmd5による実装。</li>
</ul>


<h2>sha</h2>

<ul>
<li>Secure Hash Algorithm。暗号学的ハッシュ関数の一つ。</li>
<li>SSL、SSH等で用いられる暗号化アルゴリズム。</li>
<li>SHA-0,1,2,3が存在しており、SHA-1には脆弱性が存在するため、SSL証明書はSHA-2への全面移行が進められている。すでにGoogle ChromeではSHA-1による証明書に対して警告が表示される。</li>
<li>SHA-2は鍵長によりSHA-224、SHA-256、SHA-384、SHA-512といったバリエーションが存在する。</li>
<li>上述の通り<code>openssl passwd</code>はSHA非対応だが、<code>grub-crypt</code>がSHA-2によるハッシュ化に使える模様。
参考: <a href="http://heroween.hateblo.jp/entry/2014/07/28/133713">CentOS6.5でランダムSalt付きSHA-512のシャドウパスワードを生成する - ひろうぃんの雑記</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AnsibleとDigitalOceanでどこでも使える開発環境を作る]]></title>
    <link href="http://chroju.github.io//blog/2015/07/20/ansible-digitalocean-vps-dev-env/"/>
    <updated>2015-07-20T14:50:28+09:00</updated>
    <id>http://chroju.github.io//blog/2015/07/20/ansible-digitalocean-vps-dev-env</id>
    <content type="html"><![CDATA[<p>個人開発環境としては自宅にiMac 2010Mid、モバイルでVAIO Pro 11に入れたArch Linuxを使っているのだが、メインとしてはiMacの方を利用していて、デプロイしたりなんだりは自宅からしか出来ない状態にある。じゃあVAIOに移せばいいやんとも思うのだが、こちらも会社PC（なぜかこちらもVAIO Pro 11）と二重になってしまうので始終持ち歩きたくはなく、平日フラフラしてるときにサッとbash入りたいなみたいのが出来ずにいた。</p>

<p>結論としてVPSを開発環境として扱い、最悪iPad miniからいつでもSSH接続してbash叩けるだけでも幸せかなというところに至った。これまで<a href="http://chroju.net">http://chroju.net</a>をさくらVPSで運営していたので、特に考えずさくらをもう1台追加したりもしたのだが、ちょっと調べてみると<a href="https://www.digitalocean.com/">DigitalOcean</a>が最近流行りつつあるようだったので、他社サービスも使ってみると面白そうだってことで新規契約してみた。</p>

<h2>DigitalOcean</h2>

<p>すでに他所で言われてはいるが、利点としてはこんなところかと思う。</p>

<ul>
<li>月額課金ではなく時間課金なので、使いたいだけ払えばOK</li>
<li>安い</li>
<li>アプリケーションやSSH鍵が最初から組み込まれたイメージを作れる</li>
<li>REST APIでだいたいのVPS操作ができる</li>
</ul>


<p>要するに使いたいときに使いたい環境をバチコンと作れちゃうというのが一番のメリットなので、今回のような永続的に使う開発環境より、一時的なテストなんかに使った方が良いのだと思う。とはいえ時間課金上限が月あたりで定められており、現状最安プランだと月5ドルが上限になっていたりもするので、永続的にマシンを上げておく分にも安いのは確か。なお、課金はイメージを作った時点で開始されるので、不要なマシンはhaltではなくdestroyしておく必要がある。まぁ無料のスナップショット機能もあるから、リカバリできると思えばdestroyしてしまうこともそこまで難しくはないかなと。</p>

<p>REST API提供ということで、CLIから落としたり上げたり壊したりなんだりも全部できるのだが、だったらひょっとして誰かがアプリとか作ってんじゃねーかなと思ったら、やっぱりすでにあった。</p>

<div class="bookmarklet bookmarklet-gp" itemscope itemtype="http://schema.org/MobileApplication" style="clear:both;min-height:165px;width:100%;max-width:468px;overflow:hidden;padding:12px;border:1px solid;border-color:#eaeaea #ddd #d0d0d0;-moz-box-sizing:border-box;box-sizing:border-box;border-radius:5px;"><dl class="bookmarklet-gp-info" style="margin:0;"><dt class="bookmarklet-gp-title" style="border-bottom:1px solid;border-color:#eaeaea #ddd #d0d0d0;font-weight:bold;margin:0 0 .5em 0;padding:0 0 .5em 0;"><img alt="Google play" class="favicon" style="vertical-align:middle;border:0;" src="//ssl.gstatic.com/android/market_images/web/favicon.ico" /> <span itemprop="name">DigitalOcean Swimmer Android</span></dt><dd class="bookmarklet-gp-desc" style="font-size:.9em;margin:0;"><div class="bookmarklet-gp-thumb" style="float:left;"><img src="https://lh3.ggpht.com/HXBZyHdspPh5MFgaC-rOXAZIZc8D9uM4KrQsL-gqoB1_9ZuBhthaWYLRoYJYNUY9Ytg=w300" alt="DigitalOcean Swimmer Android" itemprop="image" style="height:120px;width:120px;max-width:100%;vertical-align:middle;border:0;margin:0 1em 0 0;"></div><div class="supplier" itemscope itemtype="http://schema.org/Organization">制作: <span itemprop="name">Hannoun Yassir</span></div><div class="review" itemtype="http://schema.org/AggregateRating" itemscope itemprop="aggregateRating">評価: <span itemprop="ratingValue">4.4</span> / 5段階中</div><div class="price" itemtype="http://schema.org/Offer" itemscope itemprop="offers">価格: <meta itemprop="price" content="0">無料<small> (2015/7/11 時点)</small><br /></div><a href="https://play.google.com/store/apps/details?id=com.yassirh.digitalocean&hl=ja" target="_blank" title="DigitalOcean Swimmer Android" itemprop="url" style="float:right;"><img src="//dl.dropboxusercontent.com/u/540358/ja_generic_rgb_wo_45.png" alt="ダウンロード" style="border:0;display:inline-block;height:auto;vertical-align: middle;"/></a><small>posted by: <a target="_blank" href="http://hayashikejinan.com/?p=818">AndroidHTML v3.1</a></small></dd></dl></div>


<p>このアプリさえあればGUI操作はほぼ全部できる。</p>

<p>ちなみにこんなことでハマる人はほとんどいないだろうと思うが、自分がハマったポイントとして<code>authorized_keys</code>の件がある。Digital OceanではあらかじめWeb GUIで公開鍵を上げておき、VPSをcreateするときに最初から任意の鍵を入れておくことができるのだが、当初は<code>root</code>以外のユーザーがいないため、当然ながら<code>authorized_keys</code>のパスも<code>/root/.ssh/</code>配下となる。構築用には別のユーザーを設けることになると思うが、その際には<code>authorized_keys</code>を<code>/home/user</code>配下へ持ってきて、アクセス権の適切な設定などもしなくてはssh接続できないので注意。</p>

<h2>Ansibleによる初期構築</h2>

<p>巷ではVagrantと連携して、<code>vagrant up</code>でDigitalOceanにマシンを上げるのが流行ってるらしい。</p>

<ul>
<li><a href="http://qiita.com/msykiino/items/d45cab7f520a3288862a">vagrantではじめるクラウド開発環境（DigitalOcean編） - Qiita</a></li>
<li><a href="http://blog.glidenote.com/blog/2013/12/05/digital-ocean-with-vagrant/">VagrantとSSDなVPS(Digital Ocean)で1時間1円の使い捨て高速サーバ環境を構築する - Glide Note - グライドノート</a></li>
</ul>


<p>とはいえ自分は冒頭に書いた通り、最悪iPad miniでもいいので外から繋ぐという運用をしたかったので、Vagrantからの起動は使えない。なので初期構築には最近学び始めたAnsibleを使ってみた。</p>

<p>インフラ管理系のツール、使ったことがあるのはChefぐらいで、Puppetは概念だけ知ってはいるが、Ansibleの特色はやはりハードルの低さ、学習コストの低さだと思う。エージェントレス、<code>knife</code>のような特殊なコマンドもほとんど覚える必要がなく、<code>ansible-playbook</code>コマンドさえ覚えておけばとりあえずなんとかなってしまう。</p>

<ul>
<li>エージェントレスなのでpipで手元のマシンにansibleを入れればすぐ使える。</li>
<li>設定はyamlによるplaybookに書き出すので、文法も比較的容易。</li>
<li>1個1個のタスクは定められたモジュールを用いて書くことになるが、やりたいことを公式Docsの<a href="http://docs.ansible.com/modules_by_category.html">Module Index</a>で探ればわりとなんとかなる。</li>
<li>ディレクトリ掘ったり<code>knife</code>みたいなコマンドいっぱい覚えなくても、とりあえずyaml1つとコマンド1つあれば始められる。</li>
</ul>


<p>pip経由でのインストールが必要なので非pythonista的には若干戸惑いもありましたが、学習コストの低さはハンパないのでインストールから1時間もあれば一旦サーバー建てられました。ノウハウもQiitaはじめ随所に落ちてはいるけれど、正直公式ドキュメントがかなり充実していて、<a href="http://docs.ansible.com/YAMLSyntax.html">YAMLのシンタックスガイド</a>まで付いていたりするので、下手にググってやるよりもドキュメントちゃんと読んだ方がいいと思う。まぁ、Ansibleにかぎらずなんだってそうではあるが。ただ、複数台管理だとかアプリのデプロイだとかをやろうとすると当然ディレクトリ構成も複雑になって、既存のプラクティスが必要になってくるので、あくまで「導入の学習コストが低い」という感じだが。</p>

<p>書いたPlaybookはとりあえずGitHubに上げた。<a href="http://akiyoko.hatenablog.jp/entry/2013/12/16/020529">こちら</a>を参考に、いわゆるVPS作るときの初期設定だけまとめている。ただしわりと俺用（dotfiles引っ張ってきたりとか）。Ansibleについてはまた別の記事でまとめようと思う。</p>

<p><a href="https://github.com/chroju/ansible">chroju/ansible</a></p>

<h2>iPadからのSSH接続</h2>

<p>クライアントソフトがいろいろあるのは知っていたが、ここまでのレベルと思わんかったなーというのが<a href="https://panic.com/jp/prompt/">Prompt2</a>。</p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/chroju/19822940536" title="prompt_with_digitalocean"><img src="https://farm1.staticflickr.com/541/19822940536_5f6201ca53_z.jpg" width="640" height="480" alt="prompt_with_digitalocean"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>vim-lightlineもきちんと表示してくれるし日本語も可だし、外付けキーボードの煩わしささえ考慮しなければかなり快適である。当然ながら鍵認証も使えるし、ぶっちゃけWindowsのラップトップ持ち歩くぐらいならこっちの方がSSHはストレスないんじゃないかというぐらい。つないでちょこちょこっと使えればいいかなぐらいの思いだったが、嬉しい誤算だった。さすがに有料ではあるけど。</p>

<p>おかげさまで場所を選ばず開発環境につながるようになったので、ちょっと試したいツールがTLに上がってきたりしたらおもむろにiPadを取り出して試したりとかできる。すぐ復元したいのであれば、先のAndroidアプリで予めスナップショットを取ったりもできるし、楽すぎて笑える。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Windows開発環境を整える話と、メモアプリとして最強であるwasaviの話]]></title>
    <link href="http://chroju.github.io//blog/2015/07/04/development-environment-for-windows/"/>
    <updated>2015-07-04T20:24:32+09:00</updated>
    <id>http://chroju.github.io//blog/2015/07/04/development-environment-for-windows</id>
    <content type="html"><![CDATA[<p>職場のWindows PC、いろいろと開発用に整備を進めてはいるが、やはりWindowsだとツラミある。</p>

<h2>Chocolatey</h2>

<p>Windowsでのパッケージ管理。不可欠かというとそうでもないとは思うのだが、アップデート含め一括管理が可能なので、精神衛生上良さそうだという意味で使ってみている。どうでもいいが名前がかわいい。</p>

<p>インストール自体はPowershellからワンライナーを叩くだけなので難しくはないのだが、よくわからないエラーで止まることが多くて、現状使い切れてない。Proxyの設定はしたし、powershellの権限も<code>RemoteSigned</code>にしたのだけど、何がいけないのか。。。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> Unable to index into an object of type System.IO.FileInfo.
</span><span class='line'> 発生場所 C:\ProgramData\chocolatey\helpers\functions\Write-ChocolateyFailure.ps
</span><span class='line'> 1:24 文字:8
</span><span class='line'> +   throw &lt;&lt;&lt;&lt;  "$failureMessage"
</span><span class='line'>     + CategoryInfo          : OperationStopped: (Unable to index...em.IO.FileI
</span><span class='line'>    nfo.:String) []、RuntimeException
</span><span class='line'>     + FullyQualifiedErrorId : Unable to index into an object of type System.IO
</span><span class='line'>    .FileInfo.
</span><span class='line'>The install of clover was NOT successful.
</span><span class='line'>Error while running 'C:\ProgramData\chocolatey\lib\Clover\tools\chocolateyInstall.ps1'.
</span><span class='line'> See log for details.</span></code></pre></td></tr></table></div></figure>


<h3>参考</h3>

<p><a href="http://qiita.com/himinato/items/11f4dc9a23afebbc242c">windowsの開発環境は一瞬で整うwith chocolatey - Qiita</a></p>

<h2>コンソール</h2>

<p>cmdだと貧弱貧弱ゥ！なので、とか、bashコマンド試し打ちしたい場合が多いとか、そういう理由でコンソールは入れ直す。</p>

<p>Gitを入れると自動的にGit bashが入るので、コマンド環境としてはこれを使っている。ターミナルアプリは最近ちょっと話題になっていたのでConEmuを入れてみた。もちろんChocolateyで。</p>

<ul>
<li>Font charsetを「Shiftjis」に設定</li>
<li>フォントは<a href="http://github.com/yascentur/RictyDiminished">Ricty Diminished</a>を利用</li>
<li>lsで日本語が化けるので<code>~/.bashrc</code>に<code>alias ls='ls --show-control-chars --colors'</code>を設定</li>
</ul>


<h3>参考</h3>

<p><a href="http://astra.digi2.jp/a/e/setup-conemu-as-japanese-cmd.html">ConEmuの初期設定(日本語表示環境を構築) - Diary on wind @astra.dat</a>
<a href="http://qiita.com/ironsand/items/ec0675644a55a69855d6">Ruby - 【無理】WindowsのコンソールでUnicodeを使いたい - Qiita</a></p>

<p>Windowsで開発する場合の最大のネックは、CLIの貧弱さ以上にcp932にあると思うの。</p>

<h2>AutoHotkey</h2>

<p>キーバインド変えたいことが多いので愛用。とりあえず<code>&lt;ESC&gt;</code>と間違えて隣の<code>F1</code>押してヘルプ出てしまうことが多いので、<code>F1</code>は潰している。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='autohotkey'><span class='line'><span class="nl">F1::</span><span class="n">Return</span>
</span></code></pre></td></tr></table></div></figure>


<p>あとOutlookの使い勝手があまり好きではないので、配布されていたGmailライクなキーバインドを実現する設定を使わせていただいている。しかしOutlook2013、差出人名の表示がやたらでかかったり、フォルダのツリー表示が文字だけ（アイコンとかツリーを表す罫線がない）になっていて見づらかったり、UI面で難がありすぎる。。。</p>

<h3>参考</h3>

<p><a href="http://www.autohotkey.com/board/topic/102227-gmailkeys-for-outlook-2013/">GmailKeys for Outlook 2013 - Scripts and Functions - AutoHotkey Community</a></p>

<h2>メモアプリ</h2>

<p>技術的なことをやってるとどうしてもメモを取る必要性が出てくるのだが、いろんなところに書き散らしていると後から見返せないのでそれなりの整理はしておきたいと常々思う。</p>

<p>元々は自宅だとDropbox + QFixHowm(Vim)、会社だと（あまり技術的な話が多くなかったので＆クラウド系アプリは使えなかったので）別個の環境で同様にQFixHowmを使っていたのだが、比較的技術的なノウハウをとりためることも増えたので、可能なら自宅からも参照できるメモ環境を会社でも作りたいなと思い直している。</p>

<p>個人的に理想としているのはこんな感じ。</p>

<ul>
<li>クラウド同期が取れる、可能ならDropboxがいい</li>
<li>全文検索ができる</li>
<li>（可能なら）vimキーバインドが使える</li>
<li>（可能なら）Markdownプレビューができる</li>
</ul>


<p>いろいろ検証はしてみたが、どれもしっくり来ていない。なんかないものか。</p>

<h3>Kobito</h3>

<ul>
<li>Markdownエディタとしては優秀。ハイライトも綺麗。</li>
<li>vimモードがあってそこそこ快適。若干表示がズレることがあるが、設定いじれば修正は可能かも。</li>
<li>クラウド同期はできない。あとファイル実体見れないのがなんとなく気持ち悪い。</li>
</ul>


<h3>Evernote</h3>

<ul>
<li>Markdownエディタとしては論外。</li>
<li>アカウントは持っているが、すでにプライベートメモがどっさり入ってるので会社で開きにくい。</li>
</ul>


<h3>GistBox</h3>

<ul>
<li>Markdownエディタではないし、フォーム入力なので編集は貧弱。</li>
<li>GitHub経由で同期取れる点は魅力。</li>
<li>Gistはスニペット置き場のイメージが強く、文章の保存はしっくりこない。</li>
</ul>


<h3>Wri.pe</h3>

<ul>
<li>今のところ最良と思われる。</li>
<li>フォーム入力型の編集にはなってしまうが、<a href="https://github.com/akahuku/wasavi">Wasavi</a>使うことでVimっぽくできる。</li>
<li>ログインすれば自宅からでもメモは見られるので一応同期可能。</li>
<li>Dropbox連携はあるが、あくまでバックアップをzipでストックさせるだけなので、家ではVimで編集します、とかはスムーズにできなくて微妙。</li>
</ul>


<h3>Cirrus Editor</h3>

<ul>
<li>Dropbox内のtxtファイルをブラウザで直接編集できるのは今のところこれぐらいしか見つからない。</li>
<li>新規ファイルの追加ができないので、メモ環境としては使えない。</li>
</ul>


<p>ひとまずWri.pe使ってますけどだいぶ辛さあります。今日日はやっぱりKobito使ってるエンジニアが多いんだろうか。あるいはメモなんていらない？ うーん。。。</p>

<p><strong>……と思ってたらWasaviがDropbox連携機能もってた！！！</strong></p>

<iframe class="bookmarklet hatena-embed" src="http://hatenablog.com/embed?url=http%3A%2F%2Fappsweets.net%2Fwasavi%2F" title="wasavi - appsweets akahuku labs." style="border:none;display:block;margin:0 0 1.7rem;overflow:hidden;height:155px;width:100%;max-width:100%;"><a href="http://appsweets.net/wasavi/" target="_blank">wasavi - appsweets akahuku labs.</a></iframe>


<ul>
<li>連携すると<code>:write</code>や<code>:edit</code>がWasavi上で使えるようになる。

<ul>
<li>つまりWri.peをWasaviで編集していて、Dropboxにツッコみたくなったら<code>:write hoge.txt</code>すればよい。</li>
<li>逆にDropboxのテキストをWri.peに持ってきたければ<code>:edit fuga.txt</code>とすればよい。</li>
</ul>
</li>
<li>さらに<code>http://qasavi.appsweets.net</code>につなぐと単独でWasaviをブラウザエディタとして使える。Dropboxのオンラインエディタになる。</li>
</ul>


<p>ヤバイだろうこれ。。。highlightはさすがに無理とか、Dropbox使えると言っても<code>ls</code>は使えないのでファイラとしては微妙とか、そういうのはもろもろあるとは言え、Dropboxのファイルを直接ブラウザ上でVimライクな編集できるってのは恐ろしく便利。単なるVimのエミュレートに留まらず、ブラウザとDropboxのシームレスな連携ができるという点が肝だと思う。Dropboxで書きためていたブログの下書きを、はてなブログの編集画面上で直接呼び出すこともできるわけだ。ちなみにGoogle DriveとOne Note連携もあるので、そちらがお好みであればそちらでも。</p>

<p>これまでぜんぜん見たこともないソフトだったけど、これだいぶいいものなのでは？？？</p>

<h2>その他アプリケーション</h2>

<ul>
<li><a href="http://www.forest.impress.co.jp/library/software/clover/">Clover</a> エクスプローラーのタブ化</li>
<li>chrome全盛になりつつある気はするが、Vimp使いたくてFirefox</li>
<li>VirtualBoxにVagrantはもはや定番</li>
<li>Outlookの予定表使いづらすぎて辛いんだけど、Exchangeと同期できるアプリでなんか良い代替ないッスか。。。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[すべての障害対応を、生まれる前に消し去りたい！ #障害対応きにならNight]]></title>
    <link href="http://chroju.github.io//blog/2015/07/03/how-about-your-troubleshooting/"/>
    <updated>2015-07-03T00:20:52+09:00</updated>
    <id>http://chroju.github.io//blog/2015/07/03/how-about-your-troubleshooting</id>
    <content type="html"><![CDATA[<p><a href="http://www.zusaar.com/event/6147005">エンジニア交流会〜他社の障害対応きにならNight!〜 on Zusaar</a></p>

<p>改めて見るとすげー名前のイベント……行ってきた。</p>

<p>障害対応は嫌いです。ていうか好きな人がいるならお目にかかってみたいもんですが、しかしシステムを動かす以上障害は避けられないし、それならばなるべく負担を軽減したいというのが人の、いやエンジニアの性。つわけでよりよいソリューションを探す目的で行ってきたイベントだったんですが、結局のところ <strong>より深い闇を知るだけの結果に終わった。</strong></p>

<p>世の中闇だらけですわ。闇しかないですわ。自分なんかぜんぜん甘いなっていうか闇とすら呼べないんじゃないかっていう。詳しくは書けませんけど世の中運用者って苦労してんなって認識新たにしました。まぁだからって闇を甘受していいわけじゃなくて、だからこそやることあるんだけどさ。</p>

<p>得た知見をザクっとまとめちゃいますけど、</p>

<ul>
<li>明文化と記録は何事も大事。顧客との契約にせよ、手順や構成にせよ、障害記録にせよ。</li>
<li>ただ記録するんじゃなくて探しやすいようにとか考えないと意味ない(Wikiに書き散らしても役には立たない)</li>
<li>日頃からの点検などによる障害の抑止も重要。障害訓練とか。</li>
<li>スーパーエンジニアだから治せるって状態は脱したいのでスキルの底上げは必要。</li>
<li>電話かかってくるのウザいけど必要。確実に対応しなきゃならない障害なら絶対電話。別にTwilioとかでいいので。</li>
</ul>


<p>障害対応って辛くないはずはないのだが、だったらより辛くない方法を探さねばなと思う。アラートの対象は極力絞ったり、自動復旧でイケる事象はスクリプト組んでおいたり。</p>

<p>あと自分はもともと金融系SEで、運用に用いてたのもJP1やTivoliみたいな商用製品が多かった故、会場で交聞いたnagiosやらcactiやらCloudWatchやらを学ばねばというところ。顧客とビジネスモデルが変わっただけで、見える技術領域もほんとに変わるものだと思う。</p>

<p>こういうopsやインフラに絞ったイベント、なかなかない気がするので良いですね。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SIerからサービス系の会社に転職して1か月]]></title>
    <link href="http://chroju.github.io//blog/2015/06/28/one-month-from-job-changing/"/>
    <updated>2015-06-28T22:00:14+09:00</updated>
    <id>http://chroju.github.io//blog/2015/06/28/one-month-from-job-changing</id>
    <content type="html"><![CDATA[<p>SIerからサービス提供型の会社に転職して1か月ぐらい経ったので、感想とか今後のこととかまとめておく。立ち位置としてはインフラエンジニア、まぁ要は運用担当者になるのだが、BtoB、BtoCで動いている提供サービスすべてと、社内インフラまでひっくるめたありとあらゆるインフラの運用管理を受け持っている。なのでそれこそ雑用めいた仕事から構築にイッチョカミしてサーバー立てたりAWSいじったりみたいなところまで、見渡すべき範囲はアホほど広い感じ。</p>

<h2>日常のストレスは減った</h2>

<p>とはいえストレスは減った。だいーぶ減った。受託開発だと当然ながら顧客側のシステムポリシーだとか会社方針が第一にあり、それが要件になって、マネージャー同士での合意、契約に流れ、そこから上司の指示のもとで設計構築というように自分の動き方を規定するピラミッドがでっかくそびえるのだが、これがごっそりなくなった。インフラ関連で必要な設定作業や修正があれば誰かがRedmineにチケット上げるので、それを期日の早いものからパカパカと片付けていく感じ。もちろん粒度のデカすぎるチケットなんかは上位者が分割して割り振りをするわけだが、制約がんじがらめの中で仕事をこなしている状態からはだいぶ脱している。</p>

<p>とはいえ当然ながら責任とのトレードオフではあるわけで、チケット内の課題解決のためにスクリプト組んで実装するのか、ワークアラウンドでどうにかしちゃうのかはエンジニアの技量次第になったりするし（もちろん後者だと後から追及される可能性があるが）、そもそもスキル範囲外の話はチケット拾えなくて仕事できないとかご迷惑な場合も多々あり、なんとかせねばなという感じがある。</p>

<h2>綺麗な運用ってどこに落ちてるんだろう</h2>

<p>10年程度存続している企業なので、まぁ必要悪と言っていいのか、属人化してたりブラックボックス化してたり暗黙知化していたりなんて部分は様々見られ、アカンやろなと思うし、またそういう意識がチーム全体の根底にも流れてはいる。前職でもこの辺の課題はあったのだが、逆に綺麗で整った運用ってどんな会社がしているのか興味ある。というかそういう会社の話を聞いてみたいなと。</p>

<p>暗黙知化しているものについては手順化したりスクリプト化したりしていきたい。私は「すべての手作業を生まれる前に消し去りたい」と「人間は信頼性の面でコンピュータに劣る」をモットーとして掲げている人間なので、じゃかじゃかコンピュータ殿が勝手にやってくれる運用に切り替えていこうかなと思う。何年この会社にいるかなんて正直わからないけど、いなくなるまでにそれができれば本望かなと。</p>

<p>ただインフラエンジニアが運用エンジニアになっていく現状に対して疑問をもたなくもない。Infrastructure as Codeなんざの流れもあり、インフラ構築も含めたDevはすべてアプリ開発者が担えるようになりつつあり、一方でOpsはインフラエンジニアが担うというような流れにあるが、本当にOps以外にやることないんですかねえ？っていう。DevOpsはバズワードとして聞き流していた節があるので、昨今の潮流とかきちんと押さえて反映しようと思う。</p>

<h2>エンジニアの就労環境って</h2>

<p>旧来のIT企業と新進気鋭のところとで何が一番違うか？ってこれだと思うんだけど、弊社の場合もよくある事例ではあるがアーロンチェアが支給されていたり、開発運用に必要な物品はそれなりに気前よく買ってもらえたり、お菓子や飲み物が豊富に用意されていたり、オフィスがなんかシャレオツだったりみたいな感じである。旧来のSIerなんかでこういうの導入している会社はほとんどないのではないかと思うのだが、エンジニアを大事にしているか否かってことになるのだろうか。正直とても助かるし、転職の条件としては今後ちゃんと考えるようにしたい。</p>

<p>あと晴れて例の関東IT健保に入れたので、どっかで寿司食いには行きたいと思う。</p>

<h2>やろうと思えば仕事は多いけど思わないとない</h2>

<p>利益をあげる方法って売上増やすかコスト下げるかだと思うんだが、運用エンジニアの仕事って基本的に後者である。ただ当然ながらサービスとして稼いでいる前者の仕事がそもそも必要なので、後者、要するに効率化だとか運用改善の部分に上手いこと手が回らず、効率の悪い運用をいつまでも続けている、なんてことには陥りやすい。</p>

<p>前者、売上を上げるべき仕事というのは黙ってても降ってくるので、仕事はある。でもエンジニアとしてそれでいいんですか？というと、やっぱり良くないよねというか、エンジニアリングしてこそだよねと思うので、売上増やすためのタスクはさっさと終わらせて、改善や効率化にじゃんじゃん時間割きたい。そのために試行錯誤している時間ってそんなにはないので、手持ちの武器を増やす方向で進めていければと思う。取り急ぎシェルスクリプトとAWSかなぁと。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ansibleの入門イベント聞いてきた話]]></title>
    <link href="http://chroju.github.io//blog/2015/06/25/hika-labo-ansible/"/>
    <updated>2015-06-25T00:21:58+09:00</updated>
    <id>http://chroju.github.io//blog/2015/06/25/hika-labo-ansible</id>
    <content type="html"><![CDATA[<p><a href="https://atnd.org/events/66419">これ</a>行ってきた。ざくっと感想を箇条書きで。</p>

<ul>
<li>ChefやPuppetに相当するインフラの設定管理ツールだと勝手に思い込んでいたが、対象範囲はそれらより広い。要はCapistranoがやるようなことまでまかなえる。</li>
<li>それどころかHomebrewの管理あたりも可。一時期brewfileとか流行ってたけど、冪等性とか考えるとAnsible管理の方がいいかも。

<ul>
<li>最近そんな記事がちょうど上がってた。→ <a href="http://dev.classmethod.jp/tool/osxc-ansible-configuration-for-mac/">【要するに】osxcでMacの環境の構成を記述管理する【MacでAnsible】 ｜ Developers.IO</a></li>
</ul>
</li>
<li>一番のポイントはエージェントレス、だと個人的にも思う。導入ハードルが低い。個人のVPSとかならChef-Zeroとかよりも気楽で良い。</li>
<li>yamlだからインフラ担当者でも読みやすいって点はそれほど惹かれないというか、Rubyぐらいインフラ屋でも昨今は読み書きできるべきではって気がする。

<ul>
<li>あとRubyの方がぶっちゃけ処理ベタ書きしちゃえるって点で安心感はある。Ansibleで細かいとこに手が届かないとき、どういうワークアラウンドがあるかはわかってないが。</li>
</ul>
</li>
<li>しかし、とはいえやっぱ楽そう。Vagrantと組み合わせて開発環境立てるみたいな小さなことからやってみて、イケると思ったら本番展開ってのもアリかもしれない。かも。</li>
<li>この手のツールが出たときに「こんなこともできる！すごい！」ってなりがちなんだけど、実は再発明された車輪で成り立ってる部分もあって、それshでできるよ？ってなることは結構ある（brewfileがわりとその気配あった）ので、その点に関してはきちんと見極めがしたい。</li>
<li>あとやっぱり構成管理ツールはインフラエンジニアから完全にdevを奪いにかかるツールではあるので、インフラ屋はスケーリングとかネットワークとか（そういえばネットワーク周りのas codeなかなか流行りませんね）障害対策とか、本気でops特化が求められるのかもなとか思った。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ファッション無職になった]]></title>
    <link href="http://chroju.github.io//blog/2015/05/16/i-am-neet-now/"/>
    <updated>2015-05-16T23:28:21+09:00</updated>
    <id>http://chroju.github.io//blog/2015/05/16/i-am-neet-now</id>
    <content type="html"><![CDATA[<p>退職エントリーに対して「で、誰？」っていうレスが付くのがもはや定番化しているような気もするけど、ブログなんてだいたいはチラ裏なんだから「誰？」なんて退職エントリーに限らずなんだってそうやんけ、と思ったりはしてます。誰だかわかんない人の文章読むのがネットの醍醐味なんだから、あえて煽らなくてもいいじゃんねー？というネタにマジレス。</p>

<p>というわけで退職、自体は実際にはまだなのだが、すでに現職はフェードアウトしてファッション無職期間に入っていたりする。半月以上の休暇なんて大学以来だからちょっとワクワクしてるし、大学4年の春休みに「こんなに休めることはもうないんやで」とか言われたのは嘘だったんだなーとも思ってる。んで、インフラ系SEを辞めて、来月からSaaS事業者でインフラエンジニアをすることになる。転職にあたってそもそも何がきっかけになったのか、忘れないよう書き留めておく。</p>

<ul>
<li>自分は技術的な素養がまだ乏しいと感じているのに、会社側はマネジメントラインへ自分を進ませようとしており、方針の違いが大きくなってきていた。 => もっと技術畑でやっていきたい。</li>
<li>下請け、外注、アプリとインフラでの分割受注等により、システム全体像が見えないことが多く、システム設計や運用設計の上で歯がゆいことが多かった。 => 自社開発を重視したい。</li>
<li>怠惰に流れやすい。リスク回避の意味で「変わらない」ことが是とされることが多い。 => もっと革新的な方針の会社で働きたい。</li>
<li>趣味的に追っている技術動向のスピードと、自分が業務で携わる技術変化のスピードの乖離が激しすぎる。 => 世の動向をきちんとキャッチアップできるエンジニアでありたい。</li>
<li>というか率直に言ってインフラエンジニアとしての武器を増やしたい。</li>
</ul>


<p>こんなところか。一言で言えば「焦り」である。就職から4年経ってなお、自分がインフラエンジニアとして技術的に成長できてない、と思う焦り。それを社内でやりくりしてどうにかすることも多分できたと思うし、それを上司に掛け合わないわけではなかったのだが、異動のタイミングは半年に一度しかなかったし、それを4回近く却下されたりしてきたので、じゃあもう自分で動いてしまった方がいいかなと思うに至った。年齢的には27歳で、まだ自由が効くと言えるところでもあったし。</p>

<p>と、いうわけで、今後は今まで以上にインフラ寄りにお勉強を深めていきたい所存。先日のJAWS-UGへの参加なんかも是非とも続けていきたいところでござんす。</p>

<div class="amazlet-box" style="margin-bottom:0px;"><div class="amazlet-image" style="float:left;margin:0px 12px 1px 0px;"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4840144265/diary081213-22/ref=nosim/" name="amazletlink" target="_blank"><img src="http://ecx.images-amazon.com/images/I/41aEGDjXwAL._SL160_.jpg" alt="34歳無職さん 1 (MFコミックス フラッパーシリーズ)" style="border: none;" /></a></div><div class="amazlet-info" style="line-height:120%; margin-bottom: 10px"><div class="amazlet-name" style="margin-bottom:10px;line-height:120%"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4840144265/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">34歳無職さん 1 (MFコミックス フラッパーシリーズ)</a><div class="amazlet-powered-date" style="font-size:80%;margin-top:5px;line-height:120%">posted with <a href="http://www.amazlet.com/" title="amazlet" target="_blank">amazlet</a> at 15.05.16</div></div><div class="amazlet-detail">いけだ たかし <br />メディアファクトリー (2012-02-23)<br />売り上げランキング: 15,860<br /></div><div class="amazlet-sub-info" style="float: left;"><div class="amazlet-link" style="margin-top: 5px"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4840144265/diary081213-22/ref=nosim/" name="amazletlink" target="_blank">Amazon.co.jpで詳細を見る</a></div></div></div><div class="amazlet-footer" style="clear: left"></div></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JAWS-UG初心者支部の立ち上げに行ってきた #jawsug_bgnr]]></title>
    <link href="http://chroju.github.io//blog/2015/05/15/jaws-ug-for-beginners-at-first/"/>
    <updated>2015-05-15T00:40:09+09:00</updated>
    <id>http://chroju.github.io//blog/2015/05/15/jaws-ug-for-beginners-at-first</id>
    <content type="html"><![CDATA[<p><a href="https://jawsug-beginner.doorkeeper.jp/events/22161">JAWS-UG初心者支部【第1回】2015年5月14日(木) - JAWS-UG初心者支部 | Doorkeeper</a></p>

<p>AWS初心者具合がどれぐらいかと言うと、先日のJAWS DAYS 2015のハンズオンセッションでアカウント作り、それっきり一度もログインしていないぐらいの初心者なんですが、今回JAWS-UGの初心者支部というのが出来ると聞いたので飛び込むにはちょうどいいと思い行ってきました。しかし会場の内田洋行さん、初めて行ったけど大変ナウいオフィスでびっくりした。横に長い会場だったけど、6面スクリーン同時投影でどの席でも見やすいとかハンパない。</p>

<h2>AWSは入口が山のようにある</h2>

<p>初心者と口で言うのは簡単ですが、それを脱する手段も実は山のようにあるのがAWSで。そもそもがマウスでポチポチやればサーバー立ち上がっちゃうっていうサービス自体の簡易性を反映してなのかなんなのか知りませんが、入口といえる部分は非常に多いです。今回の勉強会では「入口」の紹介に非常に時間を割いていたなという印象。</p>

<p>自分が特に印象深かったのは<a href="http://aws.amazon.com/jp/training/self-paced-labs/">セルフペースラボ</a>と<a href="http://aws.amazon.com/jp/webinar-flow/">Webiner</a>。前者はウェブ上で無料で（有料コースもあり）使える実践的なラボ空間で、自学自習でAWSの使い方が学べるとのこと。自分はVMwareを今専門としているのだが、VMwareでも同様の<a href="http://labs.hol.vmware.com/HOL/catalogs/">Hands on Labs</a>があったりして、使えるもん使わなきゃ損だなと。後者はオンライン・セミナーで、毎週開催されているそうです。火曜日18:00からが初心者向け、水曜日18:00からがBlack Belt Tech、すなわち「黒帯」ですので中級者向けのセミナー。</p>

<p>他にも技術書の読み方や推薦があったり、ちょっと上級者向けな気はしたけどRe:Inventの紹介があったり（まーこういうのは早いうちから知っておいて、アンテナ高めといた方が良いのだろう）。とにかく勉強しようと思ったらいくらでもAWSを知るための入口はあるし、しかもかなり敷居の低いところから始めることもできるので、やらないで指くわえてたらどんどん置いていかれてしまうだけだなと。</p>

<h2>人と会うこと</h2>

<p>勉強会界隈ではよく言われる話で、本番は懇親会ってのがあります。まぁこの集まり自体が「Users Group」であることからもわかる通り、エンジニア同士の会社の枠を超えたつながりってすごく重視されていて、今日のなかでも何度も話に出ました。というか「隣の人と話してみましょう」なワークセッションが設けられていたぐらいの。これはあれですね。勉強会自体の初心者が多いことも見越してのことだったんでしょうね。</p>

<p>自分はもうとにかくコミュ障というか人と話さず済むならそれが一番って感じの人間なんですけど、ここまで言われると話さないわけにもいかないんじゃないかなと思いつつあるし、てか勉強会参加の第一の目的が「コミュ障脱却」になってくるのではないかという話も。。</p>

<p>これまでの勉強会で他の参加者と話したことは皆無ではなくて、んでやっぱり社外のエンジニアだと技術との向き合い方だとか、会社環境における技術選択の方式だとかが全然違うことが多くて、そういうの聞いてるだけで確かに楽しいのは知ってるんですよね。んでユーザーグループとなるとそのつながりがずっと続いていくわけで、絶えず情報交換しながら自分の会社に持ち帰って試してみて、また勉強会に課題を持ってくるみたいなサイクルが出来てくるわけじゃないですか。会社内だとなかなか解決できないことを外に出すこともできるわけで、閉塞感を打破する矛先を持っておくことってすごい重要なんじゃないかって気がします。近所にもJAWSの支部あるっぽいんで、そっちにも顔出してみたい……ですね、なんとか。あー、初心者向けならコミュ障のための勉強会参加法も教えてほしいなぁ。</p>

<h2>初心者の中での隔絶</h2>

<p>セッションを聞きながらTwitterでハッシュタグ追っていたのですが、結構レベル高くないか？難しいよ？みたいな声もちょこちょこ聞こえていて、「初心者」とひとえに言ってもレベルの差があるのだと気付いた次第。</p>

<p>それを言ってしまうと多分自分は「なんちゃって初心者」です。オンプレミスのインフラエンジニアとしては数年の業務経験がありますし、VPS使ってるしAWSもアカウントは持ってるしで、完全な初心者かと言うとそうではない。一方で本当に「AWSってよく聞くけどなんなの？ 導入したらおいしいの？」ぐらいの人もいるのだし、敷居をどこまで下げていくかって案外むずかしい話なのかもしれないなと。初心者向けを謳っているのに「いやいや難しいでしょ」で人が離れてしまったら悲しいし、そこへのフォローってどうしたらいいのかなとか。</p>

<p>あと「わからないことを取りあえずスルーする力」ってのも必要な気がした。今日のセッションって結構具体的なAWSのサービス名も出たりして、自分も全然わからない言葉は少なくなかったんですけど、一つ一つの単語や一部の話はわからなくとも、全体として何を言っているのか掴めれば取りあえずOKってことも多いし、わからない部分にこだわりすぎず、ある程度スルーする力って必要だと思うのです。でもこれって日々「わからないこと」と向き合っているエンジニアならではの特性っていう部分もあると思うので、そうじゃない人も入ってくる可能性のあるこの初心者支部では課題になりそうとも思った。</p>

<p>やろうと思えばいくらでもやることあるし、やらないと置いて行かれるだけだってのが理解できたので、できることからガツガツやっていきたい所存。とはいえ「目的のない勉強」は行き詰まりやすいので、AWSで何ができるのか、自分は何をしたいのかをちょっと考えてみようかなと。とりあえず「紫本」買ってみるか。。。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hash与えるとGoogleスプレッドシートに入力してくれるRubyスクリプト]]></title>
    <link href="http://chroju.github.io//blog/2015/05/03/google-spread-sheet-update-via-ruby/"/>
    <updated>2015-05-03T19:52:10+09:00</updated>
    <id>http://chroju.github.io//blog/2015/05/03/google-spread-sheet-update-via-ruby</id>
    <content type="html"><![CDATA[<script src="https://gist.github.com/chroju/7b9d422732f1a0ddd45e.js"></script>


<p>つくった。動きとしては、項目名と入力値からなるハッシュを引数で与えてやることで、該当スプレッドシートの2列目に符合するキーがある場合、その値を一番右側の列に入力してくれる。符合するキーがない場合は、メッセージを吐いた上で最下行に新しい項目として追加する。</p>

<p>用途としては非常に個人的なもので、各種オンラインバンクの残高をスクレイピングしてハッシュで返してくれるスクリプトをいくつか作ってあったので、その戻り値を使ってオートで家計簿作れたらいいなーという思いによるものです。ハッシュのキーをそのままスプレッドシート内の項目名として使っているので、シンボルではなく文字列をキーとして使ってしまっているのがあまりよろしくないのかなぁとは思うのだが、いつか改善するってーことで、とりあえず動くものを作ることを優先させた。んで、これって結構汎用的に使えそうなスクリプトかもなと思って公開した次第。</p>

<p>Googleスプレッドシートをいじるのには<code>google-drive-ruby</code>というGemを使ってます。Githubは<a href="https://github.com/gimite/google-drive-ruby">ここ</a>。<code>def initialize</code>内の処理は、このGemの初期設定によるものなので、Gemの方のReadme読んでもらえればよいかと。単純な話、GoogleのOAuth API使っているだけの話です。ただ、このコードだと叩くたびにブラウザからAPI使用許可を与えてやって、success codeをコピーしてコマンドラインで入力してやらなくちゃならないっていう手間があって、そこまで省く方法なにかありそうだけどまだ調べてない。あと気になっている点としては、このGemでセルの値を取ると、表示値しか取れないこと。式を入れているセルについては、式を取るか表示値を取るか選べるといいなぁと思ったんだけど、そこまではできないらしい。しかしまぁ、とにかくGoogleスプレッドシートという、APIで叩けるクラウドの表計算ソフトがあるというのは本当に便利なことですね、って感じ。</p>

<h2>参考</h2>

<ul>
<li><a href="http://qiita.com/inokappa/items/2566b21f4b1deac6f95b">RubyからGoogle SpreadSheet をいじるメモ - Qiita</a></li>
<li><a href="http://qiita.com/yumiyon/items/d7c370b3b8582431a3de">Google DriveのスプレッドシートにRubyでアクセスする方法 - Qiita</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
